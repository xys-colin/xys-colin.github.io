<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Docker常用命令</title>
    <url>/2022/05/19/Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="Docker常用命令"><a href="#Docker常用命令" class="headerlink" title="Docker常用命令"></a>Docker常用命令</h2><h3 id="帮助启动类命令"><a href="#帮助启动类命令" class="headerlink" title="帮助启动类命令"></a>帮助启动类命令</h3><ul>
<li>启动docker</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>

<ul>
<li>停止docker </li>
</ul>
<span id="more"></span>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl stop docker</span><br></pre></td></tr></table></figure>

<ul>
<li>查看docker状态：</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">systemctl status docker</span><br></pre></td></tr></table></figure>

<ul>
<li>开机启动</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure>

<ul>
<li>查看docker概要信息</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker info</span><br></pre></td></tr></table></figure>

<ul>
<li>查看docker总体帮助文档</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<ul>
<li>查看docker命令帮助文档</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker 具体命令 --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>

<h3 id="镜像命令"><a href="#镜像命令" class="headerlink" title="镜像命令"></a>镜像命令</h3><ul>
<li>列出本地主机上的镜像</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure>

<ul>
<li>查询远程仓库是否有某个镜像名字</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker search 镜像名称</span><br></pre></td></tr></table></figure>

<ul>
<li>下载镜像</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker pull 镜像名称[:TAG]</span><br></pre></td></tr></table></figure>

<ul>
<li>查看镜像/容器/数据卷所占的空间</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker system df</span><br></pre></td></tr></table></figure>

<ul>
<li>删除镜像</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker rmi -f 镜像id [镜像名称]</span><br></pre></td></tr></table></figure>

<ul>
<li>删除全部镜像</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker rmi -f $(docker images -qa)</span><br></pre></td></tr></table></figure>

<h3 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a>容器命令</h3><ul>
<li>新建+启动容器</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker run [OPTIONS] 镜像名称 [COMMAND] [ARG...]</span><br><span class="line">OPTIONS说明（常用）：有些是一个减号，有些是两个减号</span><br><span class="line">--name=<span class="string">&quot;容器新名字&quot;</span>       为容器指定一个名称；</span><br><span class="line">-d: 后台运行容器并返回容器ID，也即启动守护式容器(后台运行)；</span><br><span class="line">-i：以交互模式运行容器，通常与 -t 同时使用；</span><br><span class="line">-t：为容器重新分配一个伪输入终端，通常与 -i 同时使用；也即启动交互式容器(前台有伪终端，等待交互)；</span><br><span class="line">-P: 随机端口映射，大写P</span><br><span class="line">-p: 指定端口映射，小写p</span><br></pre></td></tr></table></figure>

<ul>
<li>列出当前所有正在运行的容器</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker ps [option]</span><br><span class="line">OPTIONS说明（常用）：</span><br><span class="line">-a :列出当前所有正在运行的容器+历史上运行过的</span><br><span class="line">-l :显示最近创建的容器。</span><br><span class="line">-n：显示最近n个创建的容器。</span><br><span class="line">-q :静默模式，只显示容器编号。</span><br></pre></td></tr></table></figure>

<ul>
<li>退出容器</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">exit</span>（退出容器停止）</span><br><span class="line">ctrl+p+q （退出容器不停止）</span><br></pre></td></tr></table></figure>

<ul>
<li>启动已停止运行的容器</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker start 容器ID或容器名</span><br></pre></td></tr></table></figure>

<ul>
<li>重启容器</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker restart 容器ID或者容器名</span><br></pre></td></tr></table></figure>

<ul>
<li>停止容器</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker stop 容器ID或者容器名</span><br></pre></td></tr></table></figure>

<ul>
<li>强制停止容器</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">kill</span> 容器ID或者容器名</span><br></pre></td></tr></table></figure>

<ul>
<li>删除已停止的容器</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker rm 容器ID</span><br></pre></td></tr></table></figure>

<ul>
<li>启动守护式容器（后台服务器）</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker run -d 镜像名</span><br></pre></td></tr></table></figure>

<ul>
<li>查看容器日志</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker logs 容器ID</span><br></pre></td></tr></table></figure>

<ul>
<li>查看容器内运行的进程</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker top 容器ID</span><br></pre></td></tr></table></figure>

<ul>
<li>查看容器内的细节</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker inspect 容器ID</span><br></pre></td></tr></table></figure>

<ul>
<li>进入正在运行的容器以命令行交互</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it 容器ID [bash]</span><br><span class="line">docker attach 容器ID</span><br></pre></td></tr></table></figure>

<p>​        exec是在容器中打开新的终端，并且可以启动新的进程用exit退出，不会导致容器的停止。</p>
<p>​        attach直接进入容器启动命令的终端，不会启动新的进程，用exit退出，会导致容器的停止</p>
<ul>
<li>从容器内拷贝文件到主机上</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker cp 容器ID:源资源路径 目的主机路径</span><br></pre></td></tr></table></figure>

<ul>
<li><p>导入和导出容器</p>
<ul>
<li> export导出容器的内容留作为一个tar归档文件，tar包默认在主机当前目录下</li>
<li> import从tar包中的内容创建一个新的文件系统再导入为镜像</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">export</span> 容器ID &gt; 文件名.tar</span><br><span class="line">cat 文件名.tar | docker import -镜像用户/镜像名:镜像版本号</span><br></pre></td></tr></table></figure></li>
<li><p>镜像生成</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">docker commit -m=<span class="string">&quot;提交描述信息&quot;</span> -a=<span class="string">&quot;作者&quot;</span> 容器ID 要创建的目标镜像名:[标签名]</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>ES接口操作</title>
    <url>/2021/10/28/ES%E6%8E%A5%E5%8F%A3%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<p>Java-API操作ES和Spring Boot整合ES代码实战, GitHub地址: <a href="https://github.com/xys-colin/es-practice">https://github.com/xys-colin/es-practice</a></p>
<h2 id="一-索引操作"><a href="#一-索引操作" class="headerlink" title="一. 索引操作"></a>一. 索引操作</h2><h3 id="1-1-创建索引"><a href="#1-1-创建索引" class="headerlink" title="1.1 创建索引"></a>1.1 创建索引</h3><p>对比关系型数据库，创建索引就等同于创建数据库。如创建一个shopping索引：向ES服务器发<strong>PUT请求</strong>：<a href="http://localhost:9200/shopping">http://localhost:9200/shopping</a> , 创建成功的响应体：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;acknowledged&quot;</span>: <span class="literal">true</span>,<span class="comment">//响应结果</span></span><br><span class="line">    <span class="attr">&quot;shards_acknowledged&quot;</span>: <span class="literal">true</span>,<span class="comment">//分片结果</span></span><br><span class="line">    <span class="attr">&quot;index&quot;</span>: <span class="string">&quot;shopping&quot;</span><span class="comment">//索引名称</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h3 id="1-2-查询索引"><a href="#1-2-查询索引" class="headerlink" title="1.2 查询索引"></a>1.2 查询索引</h3><h4 id="1-2-1-查询所有索引："><a href="#1-2-1-查询所有索引：" class="headerlink" title="1.2.1 查询所有索引："></a>1.2.1 查询所有索引：</h4><p>向ES服务器发送GET请求：<a href="http://127.0.0.1:9200/_cat/indices?v">http://127.0.0.1:9200/_cat/indices?v</a></p>
<p>这里请求路径中的_cat 表示查看的意思， indices 表示索引，所以整体含义就是查看当前 ES服务器中的所有索引，就好像 MySQL 中的 show tables 的感觉，服务器响应结果如下 :</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">yellow open   shopping V5K1kTlTQ4i1OUnwv0zUzA   1   1          0            0       208b           208b</span><br></pre></td></tr></table></figure>

<h4 id="1-2-2-查看单个索引"><a href="#1-2-2-查看单个索引" class="headerlink" title="1.2.2 查看单个索引"></a>1.2.2 查看单个索引</h4><p>发 GET 请求 ： <a href="http://127.0.0.1:9200/shopping">http://127.0.0.1:9200/shopping</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;shopping&quot;</span>: &#123;<span class="comment">//索引名</span></span><br><span class="line">        <span class="attr">&quot;aliases&quot;</span>: &#123;&#125;,<span class="comment">//别名</span></span><br><span class="line">        <span class="attr">&quot;mappings&quot;</span>: &#123;&#125;,<span class="comment">//映射</span></span><br><span class="line">        <span class="attr">&quot;settings&quot;</span>: &#123;<span class="comment">//设置</span></span><br><span class="line">            <span class="attr">&quot;index&quot;</span>: &#123;<span class="comment">//设置 - 索引</span></span><br><span class="line">                <span class="attr">&quot;creation_date&quot;</span>: <span class="string">&quot;1617861426847&quot;</span>,<span class="comment">//设置 - 索引 - 创建时间</span></span><br><span class="line">                <span class="attr">&quot;number_of_shards&quot;</span>: <span class="string">&quot;1&quot;</span>,<span class="comment">//设置 - 索引 - 主分片数量</span></span><br><span class="line">                <span class="attr">&quot;number_of_replicas&quot;</span>: <span class="string">&quot;1&quot;</span>,<span class="comment">//设置 - 索引 - 副分片数量</span></span><br><span class="line">                <span class="attr">&quot;uuid&quot;</span>: <span class="string">&quot;J0WlEhh4R7aDrfIc3AkwWQ&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;version&quot;</span>: &#123;</span><br><span class="line">                    <span class="attr">&quot;created&quot;</span>: <span class="string">&quot;7080099&quot;</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">&quot;provided_name&quot;</span>: <span class="string">&quot;shopping&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="1-3-删除索引"><a href="#1-3-删除索引" class="headerlink" title="1.3 删除索引"></a>1.3 删除索引</h3><p>发 DELETE 请求 ： <a href="http://127.0.0.1:9200/shopping">http://127.0.0.1:9200/shopping</a></p>
<p>返回结果如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;acknowledged&quot;</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="二-数据操作"><a href="#二-数据操作" class="headerlink" title="二. 数据操作"></a>二. 数据操作</h2><p>假设索引已经创建好了，接下来我们来创建文档，并添加数据。这里的文档可以类比为关系型数据库中的表数据，添加的数据格式为 JSON 格式</p>
<h3 id="2-1-文档创建"><a href="#2-1-文档创建" class="headerlink" title="2.1 文档创建"></a>2.1 文档创建</h3><p>向 ES 服务器发 POST 请求 ： <a href="http://127.0.0.1:9200/shopping/_doc%EF%BC%8C%E8%AF%B7%E6%B1%82%E4%BD%93JSON%E5%86%85%E5%AE%B9%E4%B8%BA%EF%BC%9A">http://127.0.0.1:9200/shopping/_doc，请求体JSON内容为：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;title&quot;</span>:<span class="string">&quot;小米手机&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;category&quot;</span>:<span class="string">&quot;小米&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;images&quot;</span>:<span class="string">&quot;http://www.gulixueyuan.com/xm.jpg&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;price&quot;</span>:<span class="number">3999.00</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意，此处发送请求的方式必须为 POST，不能是 PUT，否则会发生错误 。返回结果:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;_index&quot;</span>: <span class="string">&quot;shopping&quot;</span>,<span class="comment">//索引</span></span><br><span class="line">    <span class="attr">&quot;_type&quot;</span>: <span class="string">&quot;_doc&quot;</span>,<span class="comment">//类型-文档</span></span><br><span class="line">    <span class="attr">&quot;_id&quot;</span>: <span class="string">&quot;ANQqsHgBaKNfVnMbhZYU&quot;</span>,<span class="comment">//唯一标识，可以类比为 MySQL 中的主键，随机生成</span></span><br><span class="line">    <span class="attr">&quot;_version&quot;</span>: <span class="number">1</span>,<span class="comment">//版本</span></span><br><span class="line">    <span class="attr">&quot;result&quot;</span>: <span class="string">&quot;created&quot;</span>,<span class="comment">//结果，这里的 create 表示创建成功</span></span><br><span class="line">    <span class="attr">&quot;_shards&quot;</span>: &#123;<span class="comment">//</span></span><br><span class="line">        <span class="attr">&quot;total&quot;</span>: <span class="number">2</span>,<span class="comment">//分片 - 总数</span></span><br><span class="line">        <span class="attr">&quot;successful&quot;</span>: <span class="number">1</span>,<span class="comment">//创建成功数</span></span><br><span class="line">        <span class="attr">&quot;failed&quot;</span>: <span class="number">0</span><span class="comment">//失败数</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;_seq_no&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">&quot;_primary_term&quot;</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面的数据创建后，由于没有指定数据唯一性标识（ID），默认情况下， ES 服务器会随机生成一个。如果想要自定义唯一性标识，需要在创建时指定： <a href="http://127.0.0.1:9200/shopping/_doc/1">http://127.0.0.1:9200/shopping/_doc/1</a> ,1就是指定的id, <strong>此处需要注意：如果增加数据时明确数据主键，那么请求方式也可以为 PUT。</strong></p>
<h3 id="2-2-文档查询"><a href="#2-2-文档查询" class="headerlink" title="2.2 文档查询"></a>2.2 文档查询</h3><p>查看文档时，需要指明文档的唯一性标识，类似于 MySQL 中数据的主键查询</p>
<h4 id="2-2-1-主键查询"><a href="#2-2-1-主键查询" class="headerlink" title="2.2.1 主键查询"></a>2.2.1 主键查询</h4><p>在 Postman 中，向 ES 服务器发 GET 请求 ： <a href="http://127.0.0.1:9200/shopping/_doc/1">http://127.0.0.1:9200/shopping/_doc/1</a> 。返回结果如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;_index&quot;</span>: <span class="string">&quot;shopping&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_type&quot;</span>: <span class="string">&quot;_doc&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_id&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_version&quot;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;_seq_no&quot;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;_primary_term&quot;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">&quot;found&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">    <span class="attr">&quot;_source&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;title&quot;</span>: <span class="string">&quot;小米手机&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;category&quot;</span>: <span class="string">&quot;小米&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;images&quot;</span>: <span class="string">&quot;http://www.gulixueyuan.com/xm.jpg&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;price&quot;</span>: <span class="number">3999</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-2-2-全查询"><a href="#2-2-2-全查询" class="headerlink" title="2.2.2 全查询"></a>2.2.2 全查询</h4><p>查看索引下所有数据，向 ES 服务器发 GET 请求 ： <a href="http://127.0.0.1:9200/shopping/_search%E3%80%82">http://127.0.0.1:9200/shopping/_search。</a></p>
<h3 id="2-3-文档修改"><a href="#2-3-文档修改" class="headerlink" title="2.3 文档修改"></a>2.3 文档修改</h3><h4 id="2-3-1-全量修改"><a href="#2-3-1-全量修改" class="headerlink" title="2.3.1 全量修改"></a>2.3.1 全量修改</h4><p>和新增文档一样，输入相同的 URL 地址请求，如果请求体变化，会将原有的数据内容覆盖, 在 Postman 中，向 ES服务器发 POST 请求 ： <a href="http://127.0.0.1:9200/shopping/_doc/1">http://127.0.0.1:9200/shopping/_doc/1</a>, 请求体JSON内容为:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;title&quot;</span>:<span class="string">&quot;华为手机&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;category&quot;</span>:<span class="string">&quot;华为&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;images&quot;</span>:<span class="string">&quot;http://www.gulixueyuan.com/hw.jpg&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;price&quot;</span>:<span class="number">1999.00</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>修改成功,返回结果如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;_index&quot;</span>: <span class="string">&quot;shopping&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_type&quot;</span>: <span class="string">&quot;_doc&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_id&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_version&quot;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="attr">&quot;result&quot;</span>: <span class="string">&quot;updated&quot;</span>,<span class="comment">//&lt;-----------updated 表示数据被更新</span></span><br><span class="line">    <span class="attr">&quot;_shards&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;total&quot;</span>: <span class="number">2</span>,</span><br><span class="line">        <span class="attr">&quot;successful&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;failed&quot;</span>: <span class="number">0</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;_seq_no&quot;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="attr">&quot;_primary_term&quot;</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-3-2-局部修改"><a href="#2-3-2-局部修改" class="headerlink" title="2.3.2 局部修改"></a>2.3.2 局部修改</h4><p>修改数据时，也可以只修改某一给条数据的局部信息, 未修改的内容不会删除和覆盖, 保持原样, 向 ES 服务器发 POST 请求 ： <a href="http://127.0.0.1:9200/shopping/_update/1%E3%80%82%E8%AF%B7%E6%B1%82%E4%BD%93JSON%E5%86%85%E5%AE%B9%E4%B8%BA">http://127.0.0.1:9200/shopping/_update/1。请求体JSON内容为</a>:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;doc&quot;</span>: &#123;</span><br><span class="line">		<span class="attr">&quot;title&quot;</span>:<span class="string">&quot;小米手机&quot;</span>,</span><br><span class="line">		<span class="attr">&quot;category&quot;</span>:<span class="string">&quot;小米&quot;</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-文档删除"><a href="#2-4-文档删除" class="headerlink" title="2.4 文档删除"></a>2.4 文档删除</h3><p>删除一个文档不会立即从磁盘上移除，它只是被标记成已删除（逻辑删除）。向 ES 服务器发 DELETE 请求 ： <a href="http://127.0.0.1:9200/shopping/_doc/1">http://127.0.0.1:9200/shopping/_doc/1</a> , 返回结果:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;_index&quot;</span>: <span class="string">&quot;shopping&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_type&quot;</span>: <span class="string">&quot;_doc&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_id&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;_version&quot;</span>: <span class="number">4</span>,</span><br><span class="line">    <span class="attr">&quot;result&quot;</span>: <span class="string">&quot;deleted&quot;</span>,<span class="comment">//&lt;---删除成功</span></span><br><span class="line">    <span class="attr">&quot;_shards&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;total&quot;</span>: <span class="number">2</span>,</span><br><span class="line">        <span class="attr">&quot;successful&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;failed&quot;</span>: <span class="number">0</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;_seq_no&quot;</span>: <span class="number">4</span>,</span><br><span class="line">    <span class="attr">&quot;_primary_term&quot;</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-5-复杂查询"><a href="#2-5-复杂查询" class="headerlink" title="2.5 复杂查询"></a>2.5 复杂查询</h3><h4 id="2-5-1-条件查询"><a href="#2-5-1-条件查询" class="headerlink" title="2.5.1 条件查询"></a>2.5.1 条件查询</h4><ol>
<li><p>URL带参查询</p>
<p>例如: 查找category为小米的文档，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search?q=category:%E5%B0%8F%E7%B1%B3">http://127.0.0.1:9200/shopping/_search?q=category:小米</a></p>
<p>上述为URL带参数形式查询，这很容易让不善者心怀恶意，或者参数值出现中文会出现乱码情况。为了避免这些情况，我们可用使用带JSON请求体请求进行查询。</p>
</li>
<li><p>请求体带参查询</p>
<p>查找category为小米的文档，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;match&quot;</span>:&#123;</span><br><span class="line">			<span class="attr">&quot;category&quot;</span>:<span class="string">&quot;小米&quot;</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>查找所有文档内容</p>
<p>在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;match_all&quot;</span>:&#123;&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>查询指定字段</p>
<p>如只查询title字段的内容, 在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;match_all&quot;</span>:&#123;&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">	<span class="attr">&quot;_source&quot;</span>:[<span class="string">&quot;title&quot;</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="2-5-2-分页查询"><a href="#2-5-2-分页查询" class="headerlink" title="2.5.2 分页查询"></a>2.5.2 分页查询</h4><p>在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;match_all&quot;</span>:&#123;&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">	<span class="attr">&quot;from&quot;</span>:<span class="number">0</span>,<span class="comment">//页码</span></span><br><span class="line">	<span class="attr">&quot;size&quot;</span>:<span class="number">2</span><span class="comment">//一页多少条数据</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-5-3-查询排序"><a href="#2-5-3-查询排序" class="headerlink" title="2.5.3 查询排序"></a>2.5.3 查询排序</h4><p>如果你想通过排序查出价格最高的手机，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;match_all&quot;</span>:&#123;&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">	<span class="attr">&quot;sort&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;price&quot;</span>:&#123;</span><br><span class="line">			<span class="attr">&quot;order&quot;</span>:<span class="string">&quot;desc&quot;</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-5-4-多条件查询"><a href="#2-5-4-多条件查询" class="headerlink" title="2.5.4 多条件查询"></a>2.5.4 多条件查询</h4><p>假设想找出小米牌子，价格为3999元的。（**must相当于数据库的&amp;&amp;**）,在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;bool&quot;</span>:&#123;</span><br><span class="line">			<span class="attr">&quot;must&quot;</span>:[&#123;</span><br><span class="line">				<span class="attr">&quot;match&quot;</span>:&#123;</span><br><span class="line">					<span class="attr">&quot;category&quot;</span>:<span class="string">&quot;小米&quot;</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;,&#123;</span><br><span class="line">				<span class="attr">&quot;match&quot;</span>:&#123;</span><br><span class="line">					<span class="attr">&quot;price&quot;</span>:<span class="number">3999.00</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;]</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设想找出小米和华为的牌子。（**should相当于数据库的||**）,在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;bool&quot;</span>:&#123;</span><br><span class="line">			<span class="attr">&quot;should&quot;</span>:[&#123;</span><br><span class="line">				<span class="attr">&quot;match&quot;</span>:&#123;</span><br><span class="line">					<span class="attr">&quot;category&quot;</span>:<span class="string">&quot;小米&quot;</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;,&#123;</span><br><span class="line">				<span class="attr">&quot;match&quot;</span>:&#123;</span><br><span class="line">					<span class="attr">&quot;category&quot;</span>:<span class="string">&quot;华为&quot;</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;]</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2-5-4-范围查询"><a href="#2-5-4-范围查询" class="headerlink" title="2.5.4 范围查询"></a>2.5.4 范围查询</h4><p>假设想找出小米和华为的牌子，价格大于2000元的手机。在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;bool&quot;</span>:&#123;</span><br><span class="line">			<span class="attr">&quot;should&quot;</span>:[&#123;</span><br><span class="line">				<span class="attr">&quot;match&quot;</span>:&#123;</span><br><span class="line">					<span class="attr">&quot;category&quot;</span>:<span class="string">&quot;小米&quot;</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;,&#123;</span><br><span class="line">				<span class="attr">&quot;match&quot;</span>:&#123;</span><br><span class="line">					<span class="attr">&quot;category&quot;</span>:<span class="string">&quot;华为&quot;</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;],</span><br><span class="line">            <span class="attr">&quot;filter&quot;</span>:&#123;</span><br><span class="line">            	<span class="attr">&quot;range&quot;</span>:&#123;</span><br><span class="line">                	<span class="attr">&quot;price&quot;</span>:&#123;</span><br><span class="line">                    	<span class="attr">&quot;gt&quot;</span>:<span class="number">2000</span></span><br><span class="line">                	&#125;</span><br><span class="line">	            &#125;</span><br><span class="line">    	    &#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-5-5-全文检索"><a href="#2-5-5-全文检索" class="headerlink" title="2.5.5 全文检索"></a>2.5.5 全文检索</h4><p>这功能像搜索引擎那样，如品牌输入“小华”，返回结果带回品牌有“小米”和华为的。在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;match&quot;</span>:&#123;</span><br><span class="line">			<span class="attr">&quot;category&quot;</span> : <span class="string">&quot;小华&quot;</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-5-6-完全匹配"><a href="#2-5-6-完全匹配" class="headerlink" title="2.5.6 完全匹配"></a>2.5.6 完全匹配</h4><p>与全文检索不同, 搜索的关键词不能拆分,必须完全匹配关键词,  Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;match_phrase&quot;</span>:&#123;</span><br><span class="line">			<span class="attr">&quot;category&quot;</span> : <span class="string">&quot;华为&quot;</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-5-7-高亮查询"><a href="#2-5-7-高亮查询" class="headerlink" title="2.5.7 高亮查询"></a>2.5.7 高亮查询</h4><p>在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;query&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;match_phrase&quot;</span>:&#123;</span><br><span class="line">			<span class="attr">&quot;category&quot;</span> : <span class="string">&quot;为&quot;</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">    <span class="attr">&quot;highlight&quot;</span>:&#123;</span><br><span class="line">        <span class="attr">&quot;fields&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;category&quot;</span>:&#123;&#125;<span class="comment">//&lt;----高亮这字段</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-6-聚合查询"><a href="#2-6-聚合查询" class="headerlink" title="2.6 聚合查询"></a>2.6 聚合查询</h3><p>聚合允许使用者对 es 文档进行统计分析，类似与关系型数据库中的 group by，当然还有很多其他的聚合，例如取最大值max、平均值avg等等。</p>
<h4 id="2-6-1-分组"><a href="#2-6-1-分组" class="headerlink" title="2.6.1 分组"></a>2.6.1 分组</h4><p>接下来按price字段进行分组：在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;aggs&quot;</span>:&#123;<span class="comment">//聚合操作</span></span><br><span class="line">		<span class="attr">&quot;price_group&quot;</span>:&#123;<span class="comment">//名称，随意起名</span></span><br><span class="line">			<span class="attr">&quot;terms&quot;</span>:&#123;<span class="comment">//分组</span></span><br><span class="line">				<span class="attr">&quot;field&quot;</span>:<span class="string">&quot;price&quot;</span><span class="comment">//分组字段</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面返回结果会附带原始数据的。若不想要不附带原始数据的结果，在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;aggs&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;price_group&quot;</span>:&#123;</span><br><span class="line">			<span class="attr">&quot;terms&quot;</span>:&#123;</span><br><span class="line">				<span class="attr">&quot;field&quot;</span>:<span class="string">&quot;price&quot;</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">    <span class="attr">&quot;size&quot;</span>:<span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-6-2-平均值"><a href="#2-6-2-平均值" class="headerlink" title="2.6.2 平均值"></a>2.6.2 平均值</h4><p>对所有手机价格求平均值, 在 Postman 中，向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/shopping/_search%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/shopping/_search，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">&quot;aggs&quot;</span>:&#123;</span><br><span class="line">		<span class="attr">&quot;price_avg&quot;</span>:&#123;<span class="comment">//名称，随意起名</span></span><br><span class="line">			<span class="attr">&quot;avg&quot;</span>:&#123;<span class="comment">//求平均</span></span><br><span class="line">				<span class="attr">&quot;field&quot;</span>:<span class="string">&quot;price&quot;</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">    <span class="attr">&quot;size&quot;</span>:<span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-7-映射关系"><a href="#2-7-映射关系" class="headerlink" title="2.7 映射关系"></a>2.7 映射关系</h3><p>索引库(index)中的映射类似于数据库(database)中的表结构(table)。创建数据库表需要设置字段名称，类型，长度，约束等；索引库也一样，需要知道这个类型下有哪些字段，每个字段有哪些约束信息，这就叫做映射(mapping)。</p>
<h4 id="2-7-1-创建映射"><a href="#2-7-1-创建映射" class="headerlink" title="2.7.1 创建映射"></a>2.7.1 创建映射</h4><p>假如有一个user索引, 向 ES 服务器发 PUT请求 ： <a href="http://127.0.0.1:9200/user/_mapping%EF%BC%8C%E9%99%84%E5%B8%A6JSON%E4%BD%93%E5%A6%82%E4%B8%8B%EF%BC%9A">http://127.0.0.1:9200/user/_mapping，附带JSON体如下：</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;properties&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;name&quot;</span>:&#123;</span><br><span class="line">        	<span class="attr">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">        	<span class="attr">&quot;index&quot;</span>: <span class="literal">true</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;sex&quot;</span>:&#123;</span><br><span class="line">        	<span class="attr">&quot;type&quot;</span>: <span class="string">&quot;keyword&quot;</span>,</span><br><span class="line">        	<span class="attr">&quot;index&quot;</span>: <span class="literal">true</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;tel&quot;</span>:&#123;</span><br><span class="line">        	<span class="attr">&quot;type&quot;</span>: <span class="string">&quot;keyword&quot;</span>,</span><br><span class="line">        	<span class="attr">&quot;index&quot;</span>: <span class="literal">false</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-7-2-查询映射"><a href="#2-7-2-查询映射" class="headerlink" title="2.7.2 查询映射"></a>2.7.2 查询映射</h4><p>向 ES 服务器发 GET请求 ： <a href="http://127.0.0.1:9200/user/_mapping">http://127.0.0.1:9200/user/_mapping</a> , 返回结果为:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;user&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;mappings&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;name&quot;</span>: &#123;</span><br><span class="line">                    <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">&quot;sex&quot;</span>: &#123;</span><br><span class="line">                    <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;keyword&quot;</span></span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">&quot;tel&quot;</span>: &#123;</span><br><span class="line">                    <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;keyword&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;index&quot;</span>: <span class="literal">false</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Git使用</title>
    <url>/2019/11/20/Git%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="一-创建版本库"><a href="#一-创建版本库" class="headerlink" title="一. 创建版本库"></a>一. 创建版本库</h2><ul>
<li>初始化一个Git仓库：<strong>git init</strong></li>
<li>添加文件到Git仓库：<ol>
<li><strong>git add &lt;file&gt;</strong></li>
<li><strong>git commit</strong></li>
</ol>
</li>
</ul>
<hr>
<h2 id="二-时光机穿梭"><a href="#二-时光机穿梭" class="headerlink" title="二. 时光机穿梭"></a>二. 时光机穿梭</h2><ul>
<li>查看工作区状态，文件是否被修改过：<strong>git status</strong></li>
<li>查看修改的内容：<strong>git diff</strong></li>
</ul>
<h3 id="1、版本回退"><a href="#1、版本回退" class="headerlink" title="1、版本回退"></a>1、版本回退</h3><ul>
<li><strong>HEAD</strong> ：当前版本</li>
<li><strong>HEAD^</strong> ：上个版本</li>
<li><strong>git reset –hard commit_id</strong> ：定位版本</li>
<li><strong>git log</strong> ：穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本</li>
<li><strong>git reflog</strong> ：要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。</li>
</ul>
<span id="more"></span>

<h3 id="2、工作区和暂存区"><a href="#2、工作区和暂存区" class="headerlink" title="2、工作区和暂存区"></a>2、工作区和暂存区</h3><ol>
<li>工作区：就是你在电脑里能看到的目录，比如我的learngit文件夹就是一个工作区</li>
<li>版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。</li>
<li>暂存区：Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区。<ul>
<li>第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；</li>
<li>第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。</li>
</ul>
</li>
</ol>
<h3 id="3、管理修改"><a href="#3、管理修改" class="headerlink" title="3、管理修改"></a>3、管理修改</h3><ul>
<li>每次修改，如果不add到暂存区，就不会加入到commit中。</li>
</ul>
<h3 id="4、撤销修改"><a href="#4、撤销修改" class="headerlink" title="4、撤销修改"></a>4、撤销修改</h3><ul>
<li><strong>git checkout – file</strong>：丢弃工作区的修改</li>
<li><strong>git reset HEAD file</strong>：把暂存区的修改撤销掉，重新放回工作区</li>
</ul>
<h3 id="5、删除文件"><a href="#5、删除文件" class="headerlink" title="5、删除文件"></a>5、删除文件</h3><ul>
<li><strong>git rm</strong>：从版本库中删除文件</li>
</ul>
<h2 id="三-远程仓库"><a href="#三-远程仓库" class="headerlink" title="三.远程仓库"></a>三.远程仓库</h2><h3 id="1-添加远程库"><a href="#1-添加远程库" class="headerlink" title="1.添加远程库"></a>1.添加远程库</h3><ul>
<li>关联一个远程库：<strong>git remote add origin git@server-name:path/repo-name.git</strong></li>
<li>关联后第一次推送<strong>master</strong>分支的所有内容：<strong>git push -u origin master</strong></li>
<li>此后，每次本地提交后，只要有必要，就可以使用命令<strong>git push origin master</strong>推送最新修改</li>
</ul>
<blockquote>
<p>ps:由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。</p>
</blockquote>
<h3 id="2-从远程库克隆"><a href="#2-从远程库克隆" class="headerlink" title="2.从远程库克隆"></a>2.从远程库克隆</h3><ul>
<li>要克隆一个仓库，首先必须知道仓库的地址，然后使用git clone命令克隆</li>
<li>Git支持多种协议，包括https，但通过ssh支持的原生git协议速度最快</li>
</ul>
<h2 id="四-分支管理"><a href="#四-分支管理" class="headerlink" title="四.分支管理"></a>四.分支管理</h2><ol>
<li>创建与合并分支<ul>
<li>查看分支：<strong>git branch</strong></li>
<li>创建分支：<strong>git branch&lt;name&gt;</strong></li>
<li>切换分支：<strong>git cheakout&lt;name&gt;</strong></li>
<li>创建+切换分支：<strong>git cheakout -b &lt;name&gt;</strong></li>
<li>合并某分支到当前分支：<strong>git merge&lt;name&gt;</strong></li>
<li>删除分支：<strong>git branch - d &lt;name&gt;</strong></li>
</ul>
</li>
<li>解决冲突<ul>
<li>查看分支合并图：<strong>git log – graph<br>eg：git log –graph –pretty =oneline –abbrev -commit</strong></li>
</ul>
</li>
<li>分支管理策略<ul>
<li>合并分支时加 <strong>–no-ff</strong>参数：普通模式合并，合并后的历史有分支，禁用 <strong>fast forward</strong><br><strong>eg:git log –no-ff-m”merge with no–ff”dev</strong></li>
</ul>
</li>
<li>Bug分支<ul>
<li><strong>git stash</strong>：把当前工作现场隐藏起来，去修复bug</li>
<li><strong>git stash pop</strong>：恢复工作现场同时删除stash内容</li>
</ul>
</li>
<li>Feature分支<ul>
<li>开发一个新feature，最好新建一个分支；</li>
<li>如果要丢弃一个没有被合并过的分支，可以通过 <strong>git branch -D &lt;name&gt;</strong> 强行删除</li>
</ul>
</li>
<li>多人协作<ul>
<li><strong>git remote -v</strong>：查看远程库信息</li>
<li><strong>git push origin branch-name</strong>：从本地推送分支</li>
<li><strong>git pull</strong>：推送失败时，抓取远程的新提交</li>
<li>**git checkout -b &lt;branch-name&gt; origin/&lt;branch-name&gt;**：在本地创建和远程分支对应的分支（本地和远程分支的名称最好一致）</li>
<li>**git branch –set-upstream &lt;branch-name&gt; origin/&lt;branch-name&gt;**：建立本地分支和远程分支的关联</li>
</ul>
</li>
</ol>
<h2 id="五-标签管理"><a href="#五-标签管理" class="headerlink" title="五.标签管理"></a>五.标签管理</h2><ol>
<li>创建标签<ul>
<li>**git tag &lt;name&gt;**：新建一个标签（默认为HEAD，也可以指定commit id）</li>
<li>**git tag -a <tagname> -m “blablabla…”**：可以指定标签信息</li>
<li>**git tag -s <tagname> -m “blablabla…”**：可以用PGP签名信息</li>
<li><strong>git tag</strong>：查看所有标签</li>
</ul>
</li>
<li>操作标签<ul>
<li>**git push origin &lt;tagname&gt;**：推送一个本地标签</li>
<li><strong>git push origin –tags</strong>：推送全部未推送过的本地标签</li>
<li>**git tag -d &lt;tagname&gt;**：删除一个本地标签</li>
<li>**git push origin :refs/tags/&lt;tagname&gt;**：删除一个远程标签</li>
</ul>
</li>
</ol>
<h2 id="六-自定义Git"><a href="#六-自定义Git" class="headerlink" title="六.自定义Git"></a>六.自定义Git</h2><ol>
<li>忽略特殊文件<ul>
<li>忽略某些文件时，需要编写 <strong>.gitignore</strong>；</li>
</ul>
</li>
<li>配置别名<ul>
<li>我们只需要敲一行命令，告诉Git，以后st就表示 <strong>status：git config –global alias.st status</strong></li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">eg：</span><br><span class="line">$ git config --global alias.co checkout $ git config --global alias.ci commit $ git config --global alias.br branch</span><br><span class="line"></span><br><span class="line">$ git config --global alias.unstage &#x27;reset HEAD&#x27;</span><br><span class="line">$ git config --global alias.last &#x27;log -1&#x27;</span><br><span class="line"></span><br><span class="line">git config --global alias.lg &quot;log --color --graph --pretty=format:&#x27;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#x27; --abbrev-commit&quot;</span><br><span class="line">。</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>IoC容器:BeanFactory与ApplicationContext</title>
    <url>/2022/07/23/IoC%E5%AE%B9%E5%99%A8-BeanFactory%E4%B8%8EApplicationContext/</url>
    <content><![CDATA[<p>在Spring IoC容器中有两个主要的容器系列: 一个是<strong>实现BeanFactory接口的简单容器系列</strong>, 这个系列容器只实现了容器的最基本功能; 另一个是<strong>ApplicationContext应用上下文</strong>, 他作为容器的高级形态. 应用上下文在简单容器的基础上,增加了许多面向框架的特性. </p>
<span id="more"></span>

<h2 id="IoC容器的设计"><a href="#IoC容器的设计" class="headerlink" title="IoC容器的设计"></a>IoC容器的设计</h2><p>这张图描述了IoC容器中的主要设计接口.</p>
<img src="/2022/07/23/IoC%E5%AE%B9%E5%99%A8-BeanFactory%E4%B8%8EApplicationContext/IoC%E5%AE%B9%E5%99%A8%E7%9A%84%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E5%9B%BE.jpg" class="">

<ul>
<li>从BeanFactory到HierachicalBeanFactory，再到ConfigurableBeanFactory，是一条主要的BeanFactory设计路径，BeanFactory接口定义了基本的IoC容器的规范，它们都包含了getBean()的基本方法(通过这个方法可以从容器中获取Bean, 继承自BeanFactory)。HierachicalBeanFactory增加了getParentBeanFactory()的接口功能，使BeanFactory具备了双亲IoC容器的管理功能。ConfigurableBeanFactory接口主要定义了一些对BeanFactory的配置功能，比如通过setParentBeanFactory()设置双亲IoC容器，通过addBeanPostProcessor()配置Bean后置处理器。</li>
<li>以ApplicationContext应用上下文接口为核心的接口设计，是第二条接口设计主线。我们常用的应用上下文基本上都是ConfigurableApplicationContext或者WebApplicationContext的实现。</li>
</ul>
<h3 id="BeanFactory的应用场景"><a href="#BeanFactory的应用场景" class="headerlink" title="BeanFactory的应用场景"></a>BeanFactory的应用场景</h3><p>BeanFactory提供的是最基本的IoC容器的功能和IoC容器所应该遵守的最基本的服务契约。用户使用容器时，可以使用转义符“&amp;”来得到FactoryBean本身，用来区分通过容器来获取FactoryBean产生的对象和获取FactoryBean本身。</p>
<blockquote>
<p>FactoryBean是一个Factory，也就是IoC容器或对象工厂；BeanFactory，在Spring中，所有的Bean都是由BeanFactory（也就是IoC容器）来进行管理的。但对FactoryBean而言，这个Bean不是简单的Bean，而是一个能产生或者修饰对象生成的工厂Bean。</p>
</blockquote>
<p>BeanFactory接口方法勾画出了IoC容器的基本特性。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">BeanFactory</span> </span>&#123;</span><br><span class="line">    <span class="comment">//用于解除对FactoryBean实例的引用，并将其与FactoryBean创建的bean区分开来。例如，如果名为myJndiObject是一个FactoryBean，获取&amp;myJndiObject将返回FactoryBean，而不是myJndiObject这个FactoryBean产生出来的对象。</span></span><br><span class="line">    String FACTORY_BEAN_PREFIX = <span class="string">&quot;&amp;&quot;</span>;</span><br><span class="line">    <span class="comment">//从容器中取得Bean</span></span><br><span class="line">    <span class="function">Object <span class="title">getBean</span><span class="params">(String name)</span> <span class="keyword">throws</span> BeansException</span>;</span><br><span class="line">    &lt;T&gt; <span class="function">T <span class="title">getBean</span><span class="params">(String name, Class&lt;T&gt; requiredType)</span> <span class="keyword">throws</span> BeansException</span>;</span><br><span class="line">    <span class="function">Object <span class="title">getBean</span><span class="params">(String name, Object... args)</span> <span class="keyword">throws</span> BeansException</span>;</span><br><span class="line">    &lt;T&gt; <span class="function">T <span class="title">getBean</span><span class="params">(Class&lt;T&gt; requiredType)</span> <span class="keyword">throws</span> BeansException</span>;</span><br><span class="line">    &lt;T&gt; <span class="function">T <span class="title">getBean</span><span class="params">(Class&lt;T&gt; requiredType, Object... args)</span> <span class="keyword">throws</span> BeansException</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//返回指定的Bean的提供者，以便进行实例的按需检索，包括可用性和唯一性选项。</span></span><br><span class="line">    &lt;T&gt; <span class="function">ObjectProvider&lt;T&gt; <span class="title">getBeanProvider</span><span class="params">(Class&lt;T&gt; requiredType)</span></span>;</span><br><span class="line">    &lt;T&gt; <span class="function">ObjectProvider&lt;T&gt; <span class="title">getBeanProvider</span><span class="params">(ResolvableType requiredType)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//判断容器是否含有指定名字的Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">containsBean</span><span class="params">(String name)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//查询指定名字的Bean是否是Singleton类型的bean</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isSingleton</span><span class="params">(String name)</span> <span class="keyword">throws</span> NoSuchBeanDefinitionException</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//查询指定名字的Bean是否是prototype类型的bean</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isPrototype</span><span class="params">(String name)</span> <span class="keyword">throws</span> NoSuchBeanDefinitionException</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//查询指定了名字的Bean的Class类型是否是特定的Class类型，这个Class类型可以由用户指定</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isTypeMatch</span><span class="params">(String name, ResolvableType typeToMatch)</span> <span class="keyword">throws</span> NoSuchBeanDefinitionException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isTypeMatch</span><span class="params">(String name, Class&lt;?&gt; typeToMatch)</span> <span class="keyword">throws</span> NoSuchBeanDefinitionException</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//查询指定名字的bean的class类型</span></span><br><span class="line">    Class&lt;?&gt; getType(String name) <span class="keyword">throws</span> NoSuchBeanDefinitionException;</span><br><span class="line">    Class&lt;?&gt; getType(String name, <span class="keyword">boolean</span> allowFactoryBeanInit) <span class="keyword">throws</span> NoSuchBeanDefinitionException;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//查询指定了名字的Bean的所有别名，这些别名都是用户在BeanDefinition中定义的</span></span><br><span class="line">    String[] getAliases(String name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="BeanFactory容器的设计原理"><a href="#BeanFactory容器的设计原理" class="headerlink" title="BeanFactory容器的设计原理"></a>BeanFactory容器的设计原理</h3><p>BeanFactory接口提供了使用IoC容器的规范，与Spring应用中用到的那些上下文相比，有一个明显的特点：它只提供最基本的IoC容器的功能。</p>
<p>在Spring中，实际上是把DefaultListableBeanFactory作为一个默认的功能完整的IoC容器来使用，可以通过扩展DefaultListableBeanFactory来获得基本的IoC容器的功能。</p>
<p>编程式使用IoC容器的过程：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ClassPathResource resource = <span class="keyword">new</span> ClassPathResource(<span class="string">&quot;beans.xml&quot;</span>);</span><br><span class="line">DefaultListableBeanFactory factory = <span class="keyword">new</span> DefaultListableBeanFactory();</span><br><span class="line">XmlBeanDefinitionReader reader = <span class="keyword">new</span> XmlBeanDefinitionReader(factory);</span><br><span class="line">reader.loadBeanDefinitions(resource);</span><br></pre></td></tr></table></figure>

<p>这样就可以使用DefaultListableBeanFactory这个IoC容器了，在使用时，需要如下几个步骤：</p>
<ol>
<li>创建IoC配置文件的抽象资源，这个抽象资源包含了BeanDefinition的定义信息</li>
<li>创建一个BeanFactory，这里是DefaultListableBeanFactory</li>
<li>创建一个载入BeanDefinition的读取器，这里使用XmlBeanDefinitionReader来载入，XML文件形式的BeanDefinition，通过一个回调配置给BeanFactory</li>
<li>从定义好的资源位置读入配置信息，具体的解析过程由XmlBeanDefinitionReader来完成。完成整个载入和注册Bean定义之后，需要的IoC容器就建立起来了</li>
</ol>
<h3 id="ApplicationContext的应用场景"><a href="#ApplicationContext的应用场景" class="headerlink" title="ApplicationContext的应用场景"></a>ApplicationContext的应用场景</h3><p>ApplicationContext除了能够提供前面介绍的BeanFactory的基本功能外，还为用户提供了以下的附加服务。</p>
<ul>
<li>支持不同的信息源。扩展了MessageSource接口，可以支持国际化的实现，为开发多语言版本的应用提供服务。</li>
<li>访问资源。对ResourceLoader和Resource的支持，可以从不同地方得到bean定义资源，一般来说，具体的ApplicationContext都是继承了DefaultResourceLoader的子类。</li>
<li>支持应用时间。继承了接口ApplicationEvenPublisher,从而在上下文中引入事件机制。这些事件和Bean的生命周期的结婚为Bean的管理提供了便利</li>
<li>在ApplicationContext中提供的附加服务。与简单的BeanFactory相比，对它的使用是一种面向框架的使用风格，所以<strong>一般建议在开发应用时使用ApplicationContext作为IoC容器的基本形式</strong>。</li>
</ul>
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>IoC容器的初始化过程</title>
    <url>/2022/07/23/IoC%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<p>IoC容器的初始化入口就是refresh()方法来启动的，这个方法标志容器正式启动。IoC容器启动包括BeanDefinition的Resource定位、载入和注入三个基本过程。Spring把这三个过程分开，并使用不同的模块来完成。可以让用户更加灵活地对这三个过程进行剪裁或扩展，定义出最合适自己地IoC容器地初始化过程。</p>
<span id="more"></span>

<h3 id="BeanDefinition的Resource定位"><a href="#BeanDefinition的Resource定位" class="headerlink" title="BeanDefinition的Resource定位"></a>BeanDefinition的Resource定位</h3><p>这个Resource定位指的是BeanDefinition的资源定位，它由ResourceLoader通过统一的Resource接口来完成，对各种形式的BeanDefinition的使用都提供了统一的接口。</p>
<p>在类路径中去寻找以文件形式存在的BeanDefinition信息：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ClassPathResource resource = <span class="keyword">new</span> ClassPathResource(<span class="string">&quot;beans.xml&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>这里定义的<strong>Resource并不能由DefaultListableBeanFactory直接使用</strong>，需要BeanDefinitionReader来对这些信息进行处理，而ApplicationContext不要中间这步，因为ApplicationContext中已经提供了一系列加载不同Resource的读取器的实现，而DefaultListableBeanFactory只是一个纯粹的IoC容器，需要为它配置特定的读取器才能完成这些功能，不过这能提高定制IoC容器的灵活性。</p>
<p>下面以FileSystemXmlApplicationContext为例，它是怎么完成这个Resource定位过程。</p>
<img src="/2022/07/23/IoC%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/FileSystemXmlApplicationContext.png" class="">

<p>图中可以看到，FileSystemXmlApplicationContext已经通过继承AbstractApplicationContext<strong>具备了ResourceLoader读入以Resource定义的BeanDefinition的能力，因为AbstractApplicationContext的基类是DefaultResourceLoader</strong>。</p>
<h3 id="BeanDefinition的载入和解析"><a href="#BeanDefinition的载入和解析" class="headerlink" title="BeanDefinition的载入和解析"></a>BeanDefinition的载入和解析</h3><p>Resource的定位完后，接下来就是载入过程。对于IoC容器来说，载入过程，相当于把定义的BeanDefinition在IoC容器中转化成一个Spring内部表示的数据结构的过程。</p>
<p>refresh()方法是载入BeanDefinition的入口，该方法在AbstractApplicationContext类中实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">refresh</span><span class="params">()</span> <span class="keyword">throws</span> BeansException, IllegalStateException </span>&#123;</span><br><span class="line">	<span class="keyword">synchronized</span> (<span class="keyword">this</span>.startupShutdownMonitor) &#123;</span><br><span class="line">		StartupStep contextRefresh = <span class="keyword">this</span>.applicationStartup.start(<span class="string">&quot;spring.context.refresh&quot;</span>);</span><br><span class="line">		<span class="comment">// Prepare this context for refreshing.</span></span><br><span class="line">		prepareRefresh();</span><br><span class="line">		<span class="comment">// 这里是在子类中启动refreshBeanFactorty()的地方</span></span><br><span class="line">		ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();</span><br><span class="line">		<span class="comment">// Prepare the bean factory for use in this context.</span></span><br><span class="line">		prepareBeanFactory(beanFactory);</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			<span class="comment">// 设置BeanFactory的后置处理</span></span><br><span class="line">			postProcessBeanFactory(beanFactory);</span><br><span class="line">			StartupStep beanPostProcess = <span class="keyword">this</span>.applicationStartup.start(<span class="string">&quot;spring.context.beans.post-process&quot;</span>);</span><br><span class="line">			<span class="comment">// 调用BeanFactory的后处理器，这些处理器是在Bean定义中向容器注册的</span></span><br><span class="line">			invokeBeanFactoryPostProcessors(beanFactory);</span><br><span class="line">			<span class="comment">// 注册bean的后处理器，在bean创建过程中调用</span></span><br><span class="line">			registerBeanPostProcessors(beanFactory);</span><br><span class="line">			beanPostProcess.end();</span><br><span class="line">			<span class="comment">// 对上下文中的消息源进行初始化</span></span><br><span class="line">			initMessageSource();</span><br><span class="line">			<span class="comment">// 初始化上下文中的事件机制</span></span><br><span class="line">			initApplicationEventMulticaster();</span><br><span class="line">			<span class="comment">// 初始化其他的特殊bean</span></span><br><span class="line">			onRefresh();</span><br><span class="line">			<span class="comment">// 检查监听bean并将这些Bean向容器注册</span></span><br><span class="line">			registerListeners();</span><br><span class="line">			<span class="comment">// 实例化所有的（non-lazy-init）单件</span></span><br><span class="line">			finishBeanFactoryInitialization(beanFactory);</span><br><span class="line">			<span class="comment">// 发布容器事件，结束Refresh过程</span></span><br><span class="line">			finishRefresh();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">catch</span> (BeansException ex) &#123;</span><br><span class="line">			<span class="keyword">if</span> (logger.isWarnEnabled()) &#123;</span><br><span class="line">				logger.warn(<span class="string">&quot;Exception encountered during context initialization - &quot;</span> +</span><br><span class="line">						<span class="string">&quot;cancelling refresh attempt: &quot;</span> + ex);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">// 为防止Bean资源占用，在异常处理中，销毁已经在前面过程中生成的单价bean</span></span><br><span class="line">			destroyBeans();</span><br><span class="line">			<span class="comment">// 重置&#x27;active&#x27;标志</span></span><br><span class="line">			cancelRefresh(ex);</span><br><span class="line">			<span class="comment">// Propagate exception to caller.</span></span><br><span class="line">			<span class="keyword">throw</span> ex;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">finally</span> &#123;</span><br><span class="line">			<span class="comment">// Reset common introspection caches in Spring&#x27;s core, since we</span></span><br><span class="line">			<span class="comment">// might not ever need metadata for singleton beans anymore...</span></span><br><span class="line">			resetCommonCaches();</span><br><span class="line">			contextRefresh.end();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>来到obtainFreshBeanFactory方法下的refreshBeanFactorty()方法，在AbstractRefreshableApplicationContext中实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">refreshBeanFactory</span><span class="params">()</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">	<span class="comment">//如果已经建立了BeanFactory,则销毁并关闭该BeanFactory</span></span><br><span class="line">	<span class="keyword">if</span> (hasBeanFactory()) &#123;</span><br><span class="line">		destroyBeans();</span><br><span class="line">		closeBeanFactory();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		<span class="comment">//创建一个默认IoC容器提供ApplicationContext使用</span></span><br><span class="line">		DefaultListableBeanFactory beanFactory = createBeanFactory();</span><br><span class="line">		beanFactory.setSerializationId(getId());</span><br><span class="line">		customizeBeanFactory(beanFactory);</span><br><span class="line">        <span class="comment">//启动对BeanDefinition的载入</span></span><br><span class="line">		loadBeanDefinitions(beanFactory);</span><br><span class="line">		<span class="keyword">this</span>.beanFactory = beanFactory;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">catch</span> (IOException ex) &#123;</span><br><span class="line">		<span class="keyword">throw</span> <span class="keyword">new</span> ApplicationContextException(<span class="string">&quot;I/O error parsing bean definition source for &quot;</span> + getDisplayName(), ex);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上处可以看出，我们使用的<strong>IoC容器是DefaultListableBeanFactory</strong>。对BeanDefinition的载入是loadBeanDefinition方法，这里调用这个方法实际上是一个抽象方法，实际的在载入过程发生在子类，也就是我们采用哪种方式来定义bean的，那解析式就用相应的类进行解析，如我们采用注解方式就使用的是AnnotationConfigWebApplicationContext子类。这里使用XML定义，所以调用的是子类AbstractXmlApplicationContext中的实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">loadBeanDefinitions</span><span class="params">(DefaultListableBeanFactory beanFactory)</span> <span class="keyword">throws</span> BeansException, IOException </span>&#123;</span><br><span class="line">	<span class="comment">// 创建XmlBeanDefinitionReader，并通过回调设置到BeanFactory中去，</span></span><br><span class="line">	XmlBeanDefinitionReader beanDefinitionReader = <span class="keyword">new</span> XmlBeanDefinitionReader(beanFactory);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 为XmlBeanDefinitionReader配置ResourceLoader，因为DefaultResourceLoader它的父类，所以this指代</span></span><br><span class="line">	<span class="comment">// resource loading environment.</span></span><br><span class="line">	beanDefinitionReader.setEnvironment(<span class="keyword">this</span>.getEnvironment());</span><br><span class="line">	beanDefinitionReader.setResourceLoader(<span class="keyword">this</span>);</span><br><span class="line">	beanDefinitionReader.setEntityResolver(<span class="keyword">new</span> ResourceEntityResolver(<span class="keyword">this</span>));</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Allow a subclass to provide custom initialization of the reader,</span></span><br><span class="line">	<span class="comment">//这是启动Bean定义信息载入的过程</span></span><br><span class="line">	initBeanDefinitionReader(beanDefinitionReader);</span><br><span class="line">	loadBeanDefinitions(beanDefinitionReader);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">loadBeanDefinitions</span><span class="params">(XmlBeanDefinitionReader reader)</span> <span class="keyword">throws</span> BeansException, IOException </span>&#123;</span><br><span class="line">    <span class="comment">//以Resource的方式获取配置文件的资源位置</span></span><br><span class="line">	Resource[] configResources = getConfigResources();</span><br><span class="line">	<span class="keyword">if</span> (configResources != <span class="keyword">null</span>) &#123;</span><br><span class="line">		reader.loadBeanDefinitions(configResources);</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">//以String的形式获取配置文件的位置</span></span><br><span class="line">	String[] configLocations = getConfigLocations();</span><br><span class="line">	<span class="keyword">if</span> (configLocations != <span class="keyword">null</span>) &#123;</span><br><span class="line">		reader.loadBeanDefinitions(configLocations);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>具体的载入在XmlBeanDefinitionReader实现，因为需要应对不同形式定义的BeanDefinition，需要其他种类的BeanDefinitionReader来完成数据的载入，这里使用的是XML方式的定义，所以使用XmlBeanDefinitionReader。此方法已在父类AbstractBeanDefinitionReader中实现了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">loadBeanDefinitions</span><span class="params">(Resource... resources)</span> <span class="keyword">throws</span> BeanDefinitionStoreException </span>&#123;</span><br><span class="line">    <span class="comment">// 如果Resource为空，则停止BeanDefinition的载入</span></span><br><span class="line">    <span class="comment">// 然后启动载入BeanDefinition的过程，这个过程会遍历整个Resource集合所包含的BeanDefinition信息</span></span><br><span class="line">	Assert.notNull(resources, <span class="string">&quot;Resource array must not be null&quot;</span>);</span><br><span class="line">	<span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> (Resource resource : resources) &#123;</span><br><span class="line">		count += loadBeanDefinitions(resource);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里调用的loadBeanDefinitions(Resource res)是一个接口方法，具体的实现在XmlBeanDefinitionReader中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这里是调用的入口</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">loadBeanDefinitions</span><span class="params">(Resource resource)</span> <span class="keyword">throws</span> BeanDefinitionStoreException </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> loadBeanDefinitions(<span class="keyword">new</span> EncodedResource(resource));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 这里是载入XML形式的BeanDefintion的地方</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">loadBeanDefinitions</span><span class="params">(EncodedResource encodedResource)</span> <span class="keyword">throws</span> BeanDefinitionStoreException </span>&#123;</span><br><span class="line">	Assert.notNull(encodedResource, <span class="string">&quot;EncodedResource must not be null&quot;</span>);</span><br><span class="line">	<span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">		logger.trace(<span class="string">&quot;Loading XML bean definitions from &quot;</span> + encodedResource);</span><br><span class="line">	&#125;</span><br><span class="line">	Set&lt;EncodedResource&gt; currentResources = <span class="keyword">this</span>.resourcesCurrentlyBeingLoaded.get();</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (!currentResources.add(encodedResource)) &#123;</span><br><span class="line">		<span class="keyword">throw</span> <span class="keyword">new</span> BeanDefinitionStoreException(</span><br><span class="line">				<span class="string">&quot;Detected cyclic loading of &quot;</span> + encodedResource + <span class="string">&quot; - check your import definitions!&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//这里得到XML文件，并得到IO的InputSource准备进行读取</span></span><br><span class="line">	<span class="keyword">try</span> (InputStream inputStream = encodedResource.getResource().getInputStream()) &#123;</span><br><span class="line">		InputSource inputSource = <span class="keyword">new</span> InputSource(inputStream);</span><br><span class="line">		<span class="keyword">if</span> (encodedResource.getEncoding() != <span class="keyword">null</span>) &#123;</span><br><span class="line">			inputSource.setEncoding(encodedResource.getEncoding());</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> doLoadBeanDefinitions(inputSource, encodedResource.getResource());</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">catch</span> (IOException ex) &#123;</span><br><span class="line">		<span class="keyword">throw</span> <span class="keyword">new</span> BeanDefinitionStoreException(</span><br><span class="line">				<span class="string">&quot;IOException parsing XML document from &quot;</span> + encodedResource.getResource(), ex);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">finally</span> &#123;</span><br><span class="line">		currentResources.remove(encodedResource);</span><br><span class="line">		<span class="keyword">if</span> (currentResources.isEmpty()) &#123;</span><br><span class="line">			<span class="keyword">this</span>.resourcesCurrentlyBeingLoaded.remove();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这是从特定的XML文件中实际载入BeanDefinition地方</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">doLoadBeanDefinitions</span><span class="params">(InputSource inputSource, Resource resource)</span></span></span><br><span class="line"><span class="function">		<span class="keyword">throws</span> BeanDefinitionStoreException </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 这里取得XML文件的Doucument对象，没有按照Spring的Bean规则进行解析，需要进行下一步</span></span><br><span class="line">		Document doc = doLoadDocument(inputSource, resource);</span><br><span class="line">        <span class="comment">// 这里启动的是对BeanDefinition解析的详细过程，这个解析会使用到Spring的Bean配置规则。</span></span><br><span class="line">		<span class="keyword">int</span> count = registerBeanDefinitions(doc, resource);</span><br><span class="line">		<span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">			logger.debug(<span class="string">&quot;Loaded &quot;</span> + count + <span class="string">&quot; bean definitions from &quot;</span> + resource);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> count;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">catch</span> (BeanDefinitionStoreException ex) &#123;</span><br><span class="line">		<span class="keyword">throw</span> ex;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//此处还有许多XML解析的异常</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">registerBeanDefinitions</span><span class="params">(Document doc, Resource resource)</span> <span class="keyword">throws</span> BeanDefinitionStoreException </span>&#123;</span><br><span class="line">    <span class="comment">// 得到BeanDefinitionDocumentReader来对XML的BeanDefintion进行解析</span></span><br><span class="line">	BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();</span><br><span class="line">	<span class="keyword">int</span> countBefore = getRegistry().getBeanDefinitionCount();</span><br><span class="line">    <span class="comment">// 具体的解析过程在这个方法中完成</span></span><br><span class="line">	documentReader.registerBeanDefinitions(doc, createReaderContext(resource));</span><br><span class="line">	<span class="keyword">return</span> getRegistry().getBeanDefinitionCount() - countBefore;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从documentReader.registerBeanDefinitions方法可以知道解析过程在parseBeanDefinitions(root, this.delegate)方法中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">parseBeanDefinitions</span><span class="params">(Element root, BeanDefinitionParserDelegate delegate)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (delegate.isDefaultNamespace(root)) &#123;</span><br><span class="line">		NodeList nl = root.getChildNodes();</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nl.getLength(); i++) &#123;</span><br><span class="line">			Node node = nl.item(i);</span><br><span class="line">			<span class="keyword">if</span> (node <span class="keyword">instanceof</span> Element ele) &#123;</span><br><span class="line">				<span class="keyword">if</span> (delegate.isDefaultNamespace(ele)) &#123;</span><br><span class="line">					parseDefaultElement(ele, delegate);</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">else</span> &#123;</span><br><span class="line">					delegate.parseCustomElement(ele);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span> &#123;</span><br><span class="line">		delegate.parseCustomElement(root);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">parseDefaultElement</span><span class="params">(Element ele, BeanDefinitionParserDelegate delegate)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123;</span><br><span class="line">		importBeanDefinitionResource(ele);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span> (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123;</span><br><span class="line">		processAliasRegistration(ele);</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 对每一个Bean标签解析</span></span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span> (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123;</span><br><span class="line">		processBeanDefinition(ele, delegate);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span> (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123;</span><br><span class="line">		<span class="comment">// recurse</span></span><br><span class="line">		doRegisterBeanDefinitions(ele);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">processBeanDefinition</span><span class="params">(Element ele, BeanDefinitionParserDelegate delegate)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//BeanDefinitonHolder是BeanDefintion对象的封装类，封装了BeanDefintion、Bean的名字和别名。用它来完成向IoC容器注册。</span></span><br><span class="line">    <span class="comment">// 是通过BeanDefinitionParserDelegate对XML元素的信息按照Spring的Bean规则进行解析得到的</span></span><br><span class="line">    <span class="comment">// 这里并不涉及对象的实例化过程，对象的实例化实际上是在依赖注入时完成的</span></span><br><span class="line">	BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);</span><br><span class="line">	<span class="keyword">if</span> (bdHolder != <span class="keyword">null</span>) &#123;</span><br><span class="line">		bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			<span class="comment">// 向IoC容器注册解析得到BeanDefinition的地方</span></span><br><span class="line">			BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">catch</span> (BeanDefinitionStoreException ex) &#123;</span><br><span class="line">				getReaderContext().error(<span class="string">&quot;Failed to register bean definition with name &#x27;&quot;</span> +</span><br><span class="line">						bdHolder.getBeanName() + <span class="string">&quot;&#x27;&quot;</span>, ele, ex);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// 在BeanDefintion向IoC容器注册完以后，发送消息</span></span><br><span class="line">		getReaderContext().fireComponentRegistered(<span class="keyword">new</span> BeanComponentDefinition(bdHolder));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以知道Bean的解析是在BeanDefinitionParserDelegate中完成的，包含了对各种Spring Bean定义规则的处理，也就是&lt;bean&gt;&lt;/bean&gt;这个常见的元素信息。</p>
<h3 id="BeanDefinition在IoC容器注册"><a href="#BeanDefinition在IoC容器注册" class="headerlink" title="BeanDefinition在IoC容器注册"></a>BeanDefinition在IoC容器注册</h3><p>现在用户定义的BeanDefinition信息已经在容器内建立了自己的数据结构以及相应的数据表示，<strong>但此时这些数据还不能供IoC直接使用，需要对这些数据进行注册</strong>。在DefaultListableBeanFactory中，是通过HashMap来持有载入的BeanDefinition的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** Map of bean definition objects, keyed by bean name. */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, BeanDefinition&gt; beanDefinitionMap = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;(<span class="number">256</span>);</span><br></pre></td></tr></table></figure>

<p>在解析过程processBeanDefinition方法中完成了bean的解析，然后开始向IoC容器注册。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 向IoC容器注册解析得到BeanDefinition的地方</span></span><br><span class="line">BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());</span><br></pre></td></tr></table></figure>

<p>最终调用的registerBeanDefinition方法是DefaultListableBeanFactory中，注意的是：如果遇到同名的Bean，进行处理的时候需要依据allowBeanDefinitionOverriding的配置来完成。</p>
<p><strong>完成了BeanDefinition的注册，就完成了IoC容器的初始化过程</strong>。这些BeanDefinition信息存在容器的beanDefinitonMap中。</p>
<p>容器的作用就是对这些信息进行处理和维护，是容器建立依赖反转的基础。</p>
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>JRS303数据校验</title>
    <url>/2022/06/28/JRS303%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C/</url>
    <content><![CDATA[<p>在日常开发中，我们经常会遇到需要对数据进行校验的场景，例如非空校验和邮箱电话号码格式等校验。这个时候，JRS303校验就能派上用场，如果数据不满足标准，则会统一抛出异常，方便异常中心统一处理</p>
<p>首先，我们需要导入相关依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-validation<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="常用的校验注解"><a href="#常用的校验注解" class="headerlink" title="常用的校验注解"></a>常用的校验注解</h2><span id="more"></span>

<p>这些注解可以用于需要校验的字段上。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Null</span> <span class="comment">//验证对象是否为null </span></span><br><span class="line"><span class="meta">@NotNull</span> <span class="comment">//验证对象是否不为null, 无法查检长度为0的字符串 </span></span><br><span class="line"><span class="meta">@NotBlank</span> <span class="comment">//检查约束字符串是不是Null还有被Trim的长度是否大于0,只对字符串,且会去掉前后空格. </span></span><br><span class="line"><span class="meta">@NotEmpty</span> <span class="comment">//检查约束元素是否为NULL或者是EMPTY.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Booelan检查 </span></span><br><span class="line"><span class="meta">@AssertTrue</span> <span class="comment">//验证 Boolean 对象是否为 true </span></span><br><span class="line"><span class="meta">@AssertFalse</span> <span class="comment">//验证 Boolean 对象是否为 false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//长度检查 </span></span><br><span class="line"><span class="meta">@Size(min=2, max=4)</span> <span class="comment">//验证对象（Array,Collection,Map,String）长度是否在给定的范围之内 </span></span><br><span class="line"><span class="meta">@Length(min=2, max=6)</span> <span class="comment">//验证字符串的长度是否在min和max数值之间</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//日期检查 </span></span><br><span class="line"><span class="meta">@Past</span> <span class="comment">//验证 Date 和 Calendar 对象是否在当前时间之前，验证成立的话被注释的元素一定是一个过去的日期 </span></span><br><span class="line"><span class="meta">@Future</span> <span class="comment">//验证 Date 和 Calendar 对象是否在当前时间之后 ，验证成立的话被注释的元素一定是一个将来的日期 </span></span><br><span class="line"><span class="meta">@Pattern</span> <span class="comment">//验证 String 对象是否符合正则表达式的规则，被注释的元素符合制定的正则表达式，regexp:正则表达式 flags: 指定 Pattern.Flag 的数组，表示正则表达式的相关选项。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//数值检查 </span></span><br><span class="line"><span class="comment">//建议使用在Stirng,Integer类型，不建议使用在int类型上，因为表单值为“”时无法转换为int，但可以转换为Stirng为”“,Integer为null </span></span><br><span class="line"><span class="meta">@Min</span> <span class="comment">//验证 Number 和 String 对象是否大等于指定的值 </span></span><br><span class="line"><span class="meta">@Max</span> <span class="comment">//验证 Number 和 String 对象是否小等于指定的值 </span></span><br><span class="line"><span class="meta">@DecimalMax</span> <span class="comment">//被标注的值必须不大于约束中指定的最大值. 这个约束的参数是一个通过BigDecimal定义的最大值的字符串表示.小数存在精度 </span></span><br><span class="line"><span class="meta">@DecimalMin</span> <span class="comment">//被标注的值必须不小于约束中指定的最小值. 这个约束的参数是一个通过BigDecimal定义的最小值的字符串表示.小数存在精度 </span></span><br><span class="line"><span class="meta">@Digits</span> <span class="comment">//验证 Number 和 String 的构成是否合法 </span></span><br><span class="line"><span class="meta">@Digits(integer=,fraction=)</span> <span class="comment">//验证字符串是否是符合指定格式的数字，interger指定整数精度，fraction指定小数精度。 </span></span><br><span class="line"><span class="meta">@Range(min=, max=)</span> <span class="comment">//被指定的元素必须在合适的范围内 </span></span><br><span class="line"><span class="meta">@Range(min=10000,max=50000,message=”range.bean.wage”)</span> </span><br><span class="line"><span class="meta">@Valid</span> <span class="comment">//递归的对关联对象进行校验, 如果关联对象是个集合或者数组,那么对其中的元素进行递归校验,如果是一个map,则对其中的值部分进行校验.(是否进行递归验证) </span></span><br><span class="line"><span class="meta">@CreditCardNumber</span> <span class="comment">//信用卡验证 </span></span><br><span class="line"><span class="meta">@Email</span> <span class="comment">//验证是否是邮件地址，如果为null,不进行验证，算通过验证。 </span></span><br><span class="line"><span class="meta">@ScriptAssert(lang= ,script=, alias=)</span> </span><br><span class="line"><span class="meta">@URL(protocol=,host=, port=,regexp=, flags=)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="数据校验方式"><a href="#数据校验方式" class="headerlink" title="数据校验方式"></a>数据校验方式</h2><p>当我们只在对象中的字段标注了校验注解，不启用在对象上的@Valid和@Validated注解是不生效的</p>
<h3 id="属性注入值校验"><a href="#属性注入值校验" class="headerlink" title="属性注入值校验"></a>属性注入值校验</h3><p>在配置文件中输入的值，在注入时会对值进行校验</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@ConfigurationProperties(prefix = &quot;people&quot;)</span></span><br><span class="line"><span class="meta">@Validated</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">People</span> </span>&#123;</span><br><span class="line">    <span class="meta">@NotBlank(message = &quot;姓名不能为空&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="meta">@Min(value = 0,message = &quot;不能小于0&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> Integer age;</span><br><span class="line">    <span class="meta">@Past</span></span><br><span class="line">    <span class="keyword">private</span> Data birth;</span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="方法传参校验"><a href="#方法传参校验" class="headerlink" title="方法传参校验"></a>方法传参校验</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@Data</span><br><span class="line">public class User &#123;</span><br><span class="line">    @NotBlank(message = &quot;姓名不能为空&quot;)</span><br><span class="line">    private String name;</span><br><span class="line">    @Min(value = 0,message = &quot;不能小于0&quot;)</span><br><span class="line">    private Integer age;</span><br><span class="line">    @Past</span><br><span class="line">    private Data birth;</span><br><span class="line">    @Length(min = 8,max = 20)</span><br><span class="line">    private String password;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@PostMapping(&quot;/login&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title">login</span><span class="params">(<span class="meta">@Valid</span> <span class="meta">@RequestBody</span> User user)</span> </span>&#123;</span><br><span class="line">        Map&lt;String,Object&gt; map=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        map.put(<span class="string">&quot;200&quot;</span>,<span class="string">&quot;success&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面的代码当执行login方法，传入user对象，@Valid开启校验，会对User对象的字段的值根据字段上的校验注解进行校验，如果校验不通过会抛出异常同时提示错误信息。如果在注解中自定义message错误信息，错误信息则为自定义的，否则是注解中的默认错误信息。</p>
<h3 id="自定义封装校验结果"><a href="#自定义封装校验结果" class="headerlink" title="自定义封装校验结果"></a>自定义封装校验结果</h3><p>我们也可以给校验的对象后，紧跟一个BindingResult参数，就可以获取到校验的结果。拿到校验的结果，就可以自定义的封装。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@PostMapping(&quot;/login&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title">login</span><span class="params">(<span class="meta">@Valid</span> <span class="meta">@RequestBody</span> User user, BindingResult result)</span> </span>&#123;</span><br><span class="line">        Map&lt;String,Object&gt; map=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>( result.hasErrors())&#123;</span><br><span class="line">        Map&lt;String,String&gt; map=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="comment">//1.获取错误的校验结果</span></span><br><span class="line">        result.getFieldErrors().forEach((item)-&gt;&#123;</span><br><span class="line">            <span class="comment">//获取发生错误时的message</span></span><br><span class="line">            String message = item.getDefaultMessage();</span><br><span class="line">            <span class="comment">//获取发生错误的字段</span></span><br><span class="line">            String field = item.getField();</span><br><span class="line">            map.put(field,message);</span><br><span class="line">        &#125;);</span><br><span class="line">        map.put(<span class="string">&quot;error&quot;</span>,map);</span><br><span class="line">        <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">       map.put(<span class="string">&quot;200&quot;</span>,<span class="string">&quot;success&quot;</span>);</span><br><span class="line">       <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="统一异常处理"><a href="#统一异常处理" class="headerlink" title="统一异常处理"></a>统一异常处理</h2><p>上述都是针对于该请求设置了一个内容校验，如果针对于每个请求都单独进行配置，显然不是太合适，实际上可以统一的对于异常进行处理。</p>
<p>抽取一个异常处理类，可以使用SpringMvc所提供的@ControllerAdvice，通过“basePackages”能够说明处理哪些路径下的异常,@RestControllerAdvice等同于@RestController。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@RestControllerAdvice</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GlobalExceptionControllerAdvice</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@ExceptionHandler(value = Exception.class)</span> <span class="comment">// 处理哪种异常类型</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ApiResult <span class="title">handleValidException</span><span class="params">(MethodArgumentNotValidException exception)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        Map&lt;String,String&gt; map=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="comment">// 获取数据校验的错误结果</span></span><br><span class="line">        BindingResult bindingResult = exception.getBindingResult();</span><br><span class="line">        bindingResult.getFieldErrors().forEach(fieldError -&gt; &#123;</span><br><span class="line">            String message = fieldError.getDefaultMessage();</span><br><span class="line">            String field = fieldError.getField();</span><br><span class="line">            map.put(field,message);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        log.error(<span class="string">&quot;数据校验出现问题&#123;&#125;,异常类型&#123;&#125;&quot;</span>,exception.getMessage(),exception.getClass());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ApiResult.error(<span class="number">400</span>,<span class="string">&quot;数据校验出现问题&quot;</span>).put(<span class="string">&quot;data&quot;</span>,map);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="分组校验功能"><a href="#分组校验功能" class="headerlink" title="分组校验功能"></a>分组校验功能</h2><p>对于不同的操作，字段校验的规则和数量可能是不同的，所以我们将校验规则分组，指定什么情况下才需要进行校验, 对于不同的操作进行不同的校验组，使用groups属性。</p>
<ol>
<li><p>想要使用分组校验功能，根据文档我们首先编写不同的校验组接口，只编写空接口，用来表示就可以了：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//新增分组</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">AddGroup</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//修改分组</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UpdateGroup</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>编写好分组接口，对于不同的检验规则，标注不同的分组标识</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    <span class="meta">@NotBlank(message = &quot;姓名不能为空&quot;, groups=&#123;AddGroup.class,UpdateGroup.class&#125;)</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="meta">@Min(value = 0,message = &quot;不能小于0&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> Integer age;</span><br><span class="line">    <span class="meta">@Past</span></span><br><span class="line">    <span class="keyword">private</span> Data birth;</span><br><span class="line">    <span class="meta">@Length(min = 8,max = 20, groups = &#123;AddGroup.class&#125;)</span></span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>在方法上标注不同的分组校验，使用@Validated注解：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserController</span> </span>&#123;</span><br><span class="line">    <span class="comment">//将会校验user带有AddGroup的字段，没有这个分组的字段不会进行校验</span></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/add&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title">add</span><span class="params">(<span class="meta">@Validated(&#123;AddGroup.class&#125;)</span> <span class="meta">@RequestBody</span> User user)</span> </span>&#123;</span><br><span class="line">        Map&lt;String,Object&gt; map=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        map.put(<span class="string">&quot;200&quot;</span>,<span class="string">&quot;success&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>@Validated({AddGroup.class})</strong>:启用不同的分组校验规则。</p>
<p><strong>注意：</strong>在使用分组校验的情况下，对于没有标注分组的校验规则，默认是不生效的，想要起作用就必须要加groups。</p>
</li>
</ol>
<h2 id="自定义校验功能"><a href="#自定义校验功能" class="headerlink" title="自定义校验功能"></a>自定义校验功能</h2><p>假如我们将要校验showStatus的0或1状态，可以用正则，但我们可以利用自定义校验方式解决。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">	* 显示状态[0-不显示；1-显示]</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">private</span> Integer showStatus;</span><br></pre></td></tr></table></figure>

<ol>
<li><p>添加依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>javax.validation<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>validation-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0.1.Final<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>编写自定义的校验注解</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="comment">//使用自定义的校验器，可以使用多个校验器</span></span><br><span class="line"><span class="meta">@Constraint(validatedBy = &#123; ListValueConstraintValidator.class&#125;)</span></span><br><span class="line"><span class="meta">@Target(&#123; METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE &#125;)</span></span><br><span class="line"><span class="meta">@Retention(RUNTIME)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> ListValue &#123;</span><br><span class="line">    <span class="comment">// 使用该属性去Validation.properties中取</span></span><br><span class="line">    <span class="function">String <span class="title">message</span><span class="params">()</span> <span class="keyword">default</span> &quot;</span>&#123;cn.qmulin.common.valid.ListValue.message&#125;<span class="string">&quot;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Class&lt;?&gt;[] groups() default &#123; &#125;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Class&lt;? extends Payload&gt;[] payload() default &#123; &#125;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    int[] value() default &#123;&#125;;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure></li>
<li><p>编写自定义的校验器</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListValueConstraintValidator</span> <span class="keyword">implements</span> <span class="title">ConstraintValidator</span>&lt;<span class="title">ListValue</span>,<span class="title">Integer</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Set&lt;Integer&gt; set=<span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">    <span class="comment">//初始化注解可验证的正确数据，用于校验时，这里是获取@ListValue中value值，并初始化</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">(ListValue constraintAnnotation)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] value = constraintAnnotation.value();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i : value) &#123;</span><br><span class="line">            set.add(i);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">//校验结果返回</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValid</span><span class="params">(Integer value, ConstraintValidatorContext context)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span>  set.contains(value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>使用方式</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">	* 显示状态[0-不显示；1-显示]</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">@ListValue(value = &#123;0,1&#125;,groups =&#123;AddGroup.class&#125;, message=&quot;必须输入0或1&quot;)</span></span><br><span class="line"><span class="keyword">private</span> Integer showStatus;</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux基础认识</title>
    <url>/2019/11/21/Linux%E5%9F%BA%E7%A1%80%E8%AE%A4%E8%AF%86/</url>
    <content><![CDATA[<h2 id="一-磁盘分区"><a href="#一-磁盘分区" class="headerlink" title="一. 磁盘分区"></a>一. 磁盘分区</h2><ol>
<li>在Linux系统中，每个设备都被当成一个文件来对待。比如SATA接口的硬盘的文件名即为/dev/sd[a-d]，其中括号内的字母为a-d当中的任意一</li>
<li>SATA、USB、SAS等磁盘接口都是使用SCSI模块来驱动的，因此这些接口的磁盘设备文件名都是/dev/sd[a-p]的格式，设备文件名是根据Linux内核检测磁盘的顺序来命名。</li>
<li>磁盘由碟片、机械手臂、磁头和主轴马达所组成。</li>
<li>碟片上面可细分出<strong>扇区</strong>（磁道中被半径分割的一个个扇形）与<strong>磁道</strong>（每一个圆形就是一个磁道）两种单位，其中扇区的物理大小设计有两种，分别是512字节和4k字节。</li>
<li>所有碟片的同一个磁道我们称为<strong>柱面</strong>，通常那是文件系统的最小单位，也就是分区的最小单位。</li>
</ol>
<span id="more"></span>

<h3 id="MBR-MS-DOS-分区表格式与限制"><a href="#MBR-MS-DOS-分区表格式与限制" class="headerlink" title="MBR(MS-DOS)分区表格式与限制"></a>MBR(MS-DOS)分区表格式与限制</h3><blockquote>
<p>早期的Linux系统为了兼容Windows的磁盘，使用的是MBR(Master Boot Record,主引导记录)的方式来处理引导程序与分区表，启动引导程序记录区与分区表则通常放在磁盘的第一个扇区，这个扇区通常是512字节的大小（旧磁盘扇区都是512字节）</p>
</blockquote>
<ol>
<li>第一个扇区的512字节主要有两个东西：<ul>
<li> <strong>主引导记录（Master Boot Record，MBR）</strong>：可以安装启动引导程序的地方，有446字节。</li>
<li><strong>分区表</strong>：记录整块硬盘分区的状态，有64字节。由于分区表所在的区块仅有64字节容量，因此最多仅能有四组记录区，每组记录区记录了该区段的启动与结束的柱面号码。</li>
</ul>
</li>
<li>这四个分区的记录被称为主要或扩展分区</li>
<li>扩展分区的目的是使用额外的扇区来记录分区的信息，扩展分区本身并不能被拿来格式化。扩展分区可以继续切出分区，就称为逻辑分区</li>
<li>能够被格式化后作为数据存取的分区是主要分区与逻辑分区，扩展分区无法格式化。</li>
<li>逻辑分区的数量依操作系统而不同，在Linux系统中SATA硬盘已经可以突破63个以上的分区限制。</li>
<li>当分区超过4个分区是，一定要有扩展分区，而且必须将所有剩下的空间都分配给扩展分区，然后再以逻辑分区的方式来划分扩展分区的空间。分区的序号1-4号是保留给主要/扩展分区的，因此第一个逻辑分区一定是由5号开始。</li>
<li>MBR分区表的限制有以下问题<ul>
<li>操作系统无法使用2.2TB以上的磁盘容量</li>
<li>MBR仅有一个区块，若被破坏后，经常无法或很难恢复</li>
<li>MBR内的存放启动引导程序的区块仅446字节，无法存储较多的程序代码。</li>
</ul>
</li>
</ol>
<h3 id="GPT-GUID-partition-table-磁盘分区表"><a href="#GPT-GUID-partition-table-磁盘分区表" class="headerlink" title="GPT(GUID partition table)磁盘分区表"></a>GPT(GUID partition table)磁盘分区表</h3><blockquote>
<p>为了兼容所有的磁盘，因此在扇区的定义上面，大多会使用所谓的逻辑区块地址(Logical Block Address,LBA)来处理，而第一个LBA称为LBA0（从0开始编号），与MBR仅使用第一个512字节区块来记录不同，GPT使用了34个LBA区块来记录分区信息，除了前面的34个LBA之外，整个磁盘的最后34个LBA也拿来作为另外一个备份。</p>
</blockquote>
<ol>
<li>**LBA0(MBR兼容区块)**：<blockquote>
<p>与MBR模式相似，这个兼容区块也分为两个部分，一个是跟之前446字节相似的区块，<strong>存储了第一阶段的启动引导程序</strong>。二是原本的分区表的记录区内，这个兼容模式仅放入一个特殊标识符，用来表示此磁盘为GPT格式之意。而不懂GPT分区表的磁盘管理程序，就不会认识这块磁盘除非用户有特殊要求要处理这块磁盘。</p>
</blockquote>
</li>
<li>**LBA1(GPT 表头记录)**：<blockquote>
<p>这个部分记录了分区表本身的位置与大小，同时记录了备份用的GPT分区（就是最后34个LBA区块）放置的位置，同时放置了分区表的校验码（CRC32），操作系统可以根据这个校验码来判断GPT是否正确，若有错误，还可以通过这个记录区来获取备份的GPT来恢复。</p>
</blockquote>
</li>
<li>**LBA2-33(实际记录分区信息处)**：<blockquote>
<p>从LBA2区块开始，<strong>每个LBA都可以记录4组分区记录，所以在默认的情况下，总共可以有4 * 32=128组分区记录</strong>因为每个LBA有512字节，因此每组记录用到128字节的空间，除了每组记录所需要的标识符与相关的记录之外，GPT在每组记录中分别提供了64位来记载开始/结束的扇区号码，因此，GPT分区表对于单一分区来说，最大容量限制为2^64 * 512字节=2^63 * 1K字节=2^33 * 1TB=8ZB。<strong>GPT分区已经没有所谓的主、扩展、逻辑分区的概念，既然每组记录都可以独立存在，当然每个都可以视为主要分区，每个分区都可以格式化使用</strong></p>
</blockquote>
</li>
</ol>
<h3 id="启动流程中的BIOS和UEFI启动检测程序"><a href="#启动流程中的BIOS和UEFI启动检测程序" class="headerlink" title="启动流程中的BIOS和UEFI启动检测程序"></a>启动流程中的BIOS和UEFI启动检测程序</h3><ol>
<li>整个启动流程到操作系统之前的过程：<blockquote>
<ol>
<li>BIOS：启动主动执行的固件，会认识第一个可启动的设备。</li>
<li>MBR：第一个可启动设备的第一个扇区内的主引导记录块，内含启动引导代码；</li>
<li>启动引导程序(boot loader)：一个可读取内核文件来执行的软件</li>
<li>内核文件：开始启动操作系统</li>
</ol>
</blockquote>
</li>
<li>Boot loader的主要任务有：<ol>
<li>提供选项：用户可以选择不同的启动选项，这也是多重引导的重要功能。</li>
<li>加载内核文件：直接指向可使用的程序区段来启动操作系统</li>
<li>转交其他启动引导程序：将启动管理功能转交给其他启动引导程序负责<blockquote>
<p>启动引导程序除了可以安装在MBR之外,还可以安装在每个分区的启动扇区(boot sector)</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<h3 id="Linux磁盘分区的选择"><a href="#Linux磁盘分区的选择" class="headerlink" title="Linux磁盘分区的选择"></a>Linux磁盘分区的选择</h3><ol>
<li> 目录树架构: &nbsp; 整个目录树架构最重要的就是那个根目录,这个根目录的表示方法为一条斜线”<strong>/</strong>“</li>
<li> 挂载: 就是利用一个目录当成进入点,将磁盘分区的数据放置在该目录下;也就是说进入该目录就可以读取该分区的意思</li>
</ol>
<h4 id="X-Window-与命令行模式的切换"><a href="#X-Window-与命令行模式的切换" class="headerlink" title="X Window 与命令行模式的切换"></a>X Window 与命令行模式的切换</h4><ul>
<li><strong>Ctrl + Alt + F2 ~ F6: 命令行模式登录tty2~tty6终端</strong></li>
<li><strong>Ctrl + Alt + F1: 图形用户界面模式</strong> </li>
<li><strong>纯命令行界面(不能有X存在)启动图形界面的做法: startx</strong></li>
</ul>
<h2 id="二-命令的操作"><a href="#二-命令的操作" class="headerlink" title="二. 命令的操作"></a>二. 命令的操作</h2><h3 id="开始执行命令"><a href="#开始执行命令" class="headerlink" title="开始执行命令"></a>开始执行命令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">command [-options] parameter2 parameter2 ... </span><br></pre></td></tr></table></figure>
<ol>
<li>一行命令中第一个输入的部分绝对是命令(command)或可执行文件(例如shell脚本)</li>
<li>command为命令的名称,例如变换1工作目录的命令为cd等;</li>
<li>中括号 [] 并不存在与实际的命令中,表示是可选的,而加入选项设置时,通常选项前会带 - 号,例如 -h;有时候会使用选项的完整全名,则选项前带有 – 符号,例如 –help;</li>
<li>parameter1 parameter2为依附在选项后面的参数, 或是command的参数</li>
<li>命令, 选项, 参数等这几个东西中间以空格来区分, 不论空几格shell都视为一格,<strong>所以空格是很重要的特殊字符</strong></li>
<li>按下回车键后, 该命令就立即执行, <strong>回车键代表着一行命令的开始行动</strong></li>
<li>命令太长的时候, 可以使用反斜杠( \ )来转义回车键, 使命令连续到下一行, 注意, 反斜杠后就立刻接着特殊字符才能转义</li>
</ol>
<h3 id="基础的命令的操作"><a href="#基础的命令的操作" class="headerlink" title="基础的命令的操作"></a>基础的命令的操作</h3><ul>
<li><strong>显示日期与时间的命令: date [+%Y/%m/%d]</strong></li>
<li><strong>显示日历的命令: cal [month] [year]</strong></li>
<li><strong>简单的计算机: bc</strong></li>
</ul>
<h3 id="重要的几个热键"><a href="#重要的几个热键" class="headerlink" title="重要的几个热键"></a>重要的几个热键</h3><ol>
<li><p>[Tab]</p>
<ol>
<li>[Tab]接在一串命令的第一个字段后面，则为<strong>命令补全</strong></li>
<li>[Tab]接在一串命令的第二个字段后面，则为<strong>文件补全</strong></li>
<li>若安装了Bash-completion软件，则在某些命令后面使用[Tab]按键时，则可以进行<strong>选项/参数的补齐</strong>功能</li>
</ol>
</li>
<li><p>[Ctrl]-c</p>
</li>
<li><p>[Ctrl]-d</p>
<h3 id="重要的几个热键-1"><a href="#重要的几个热键-1" class="headerlink" title="重要的几个热键"></a>重要的几个热键</h3></li>
<li><p>[Tab]</p>
<ol>
<li>[Tab]接在一串命令的第一个字段后面，则为<strong>命令补全</strong></li>
<li>[Tab]接在一串命令的第二个字段后面，则为<strong>文件补全</strong></li>
<li>若安装了Bash-completion软件，则在某些命令后面使用[Tab]按键时，则可以进行<strong>选项/参数的补齐</strong>功能</li>
</ol>
</li>
<li><p>[Ctrl]-c：（先按着[Ctrl]不放再按下c，是组合按键），就是中断目前程序的按键</p>
</li>
<li><p>[Ctrl]-d：键盘输入结束(End Of File，EOF或End Of Input)的意思. 它也可以用来取代exit的输入.例如想要直接离开命令行模式,可以直接按下它就能够直接离开,相当于输入exit.</p>
</li>
<li><p>[Shift]+{[Page UP][Page Down]} :当命令的输入信息相当长,导致前面的部分已经不在目前的屏幕中,可以用它用来翻页</p>
</li>
</ol>
<h3 id="man-page"><a href="#man-page" class="headerlink" title="man page"></a>man page</h3><ol>
<li>[–help]:能够将该命令的用法作为一个大致的理解. 例: date –help</li>
<li>man: 在其他在线求助系统寻找说明的内容. 例: man date . 出现的这个屏幕界面,称为man page</li>
</ol>
<p>在man page 第一行出现的 [DATE(1)] ,DATE代表是命令的名称, 数字1代表” 一般用户可以使用的命令 “,其他数字如下表:</p>
<table>
<thead>
<tr>
<th align="center">代号</th>
<th align="center">代表内容</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center"><strong>用户在shell环境中可以可以操作的命令或可执行文件</strong></td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">系统内核可调用的函数与工具等</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">一些常用的函数与函数库, 大部分为Ｃ的函数库</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">设备文件的说明，通常在/dev下的文件</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center"><strong>配置文件或是某些文件的格式</strong></td>
</tr>
<tr>
<td align="center">6</td>
<td align="center">游戏</td>
</tr>
<tr>
<td align="center">7</td>
<td align="center">惯例与协议等, 例如Linux文件系统, 网络协议, ASCII代码等的说明</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center"><strong>系统管理员可用的管理命令</strong></td>
</tr>
<tr>
<td align="center">9</td>
<td align="center">跟内核有关的文件</td>
</tr>
</tbody></table>
<p>上述表的内容可以使用[man man] 来更详细地取得说明。</p>
<h3 id="info-page"><a href="#info-page" class="headerlink" title="info page"></a>info page</h3><p>info与man的用途差不多，但是与man page一口气输出一堆信息不同的是，info page则是将文件数据拆成一个一个的段落，每个段落用自己的页面来编写，并且在各个页面中还有类似网页的超链接来跳到各不同的页面中，每个独立的页面也被称为一个节点（node）。</p>
<ol>
<li>在这个页面中可以通过直接按下Ｎ、P、U去到下一个、上一个与上一层的节点。当不知道怎么使用info，直接按下h，系统就能提供一些基本按键功能的介绍。</li>
</ol>
<p><strong>总结下man、info、/usr/share/doc/ ：</strong></p>
<ul>
<li>在命令模式中，如果你知道某个命令，但却忘记了相关选项参数，先使用【–help】的功能来查询相关信息</li>
<li>当有任何不知道的命令或文件格式，但是想要了解它，使用man或info来查询</li>
<li>而如果想要架设一些其他的服务，或想要利用一整组软件来完成某项功能时，使用/usr/share/doc下面查询有没有服务的说明文件</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>MQ概述</title>
    <url>/2021/11/15/MQ%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h2 id="一、MQ概述"><a href="#一、MQ概述" class="headerlink" title="一、MQ概述"></a>一、MQ概述</h2><h3 id="1-1-MQ简介"><a href="#1-1-MQ简介" class="headerlink" title="1.1 MQ简介"></a>1.1 MQ简介</h3><p>MQ，Message Queue，是一种提供<strong>消息队列服务</strong>的中间件，也称为消息中间件，是一套提供了消息生产、存储、消费全过程API的软件系统。消息即数据。一般消息的体量不会很大。</p>
<span id="more"></span>

<h3 id="1-2-MQ用途"><a href="#1-2-MQ用途" class="headerlink" title="1.2 MQ用途"></a>1.2 MQ用途</h3><ol>
<li><p><strong>限流削峰</strong></p>
<p>MQ可以将系统的<code>超量</code>请求暂存其中，以便系统后期可以慢慢进行处理，从而避免了请求的丢失或系统<br>被压垮。</p>
<img src="/2021/11/15/MQ%E6%A6%82%E8%BF%B0/878a9feb249f4db7bd02f5def3fbdc51.png" class=""></li>
<li><p><strong>异步解耦</strong></p>
<p>上游系统对下游系统的调用若为同步调用，则会大大降低系统的<a href="https://so.csdn.net/so/search?q=%E5%90%9E%E5%90%90%E9%87%8F&spm=1001.2101.3001.7020">吞吐量</a>与并发度，且系统耦合度太高。而异步调用则会解决这些问题。所以两层之间若要实现由同步到异步的转化，一般性做法就是，在这两层间添加一个MQ层。</p>
<img src="/2021/11/15/MQ%E6%A6%82%E8%BF%B0/%E5%BC%82%E6%AD%A5%E8%A7%A3%E8%80%A6.png" class=""></li>
<li><p><strong>数据收集</strong></p>
<p>分布式系统会产生海量级数据流，如：业务日志、监控数据、用户行为等。针对这些数据流进行实时或批量采集汇总，然后对这些数据流进行大数据分析，这是当前互联网平台的必备技术。通过MQ完成此类数据收集是最好的选择。</p>
</li>
</ol>
<h3 id="1-3-常见MQ产品"><a href="#1-3-常见MQ产品" class="headerlink" title="1.3 常见MQ产品"></a>1.3 常见MQ产品</h3><ul>
<li><p><strong>ActiveMQ</strong></p>
<p>ActiveMQ是使用Java语言开发一款MQ产品。早期很多公司与项目中都在使用。但现在的社区活跃度已经很低。现在的项目中已经很少使用了。</p>
</li>
<li><p><strong>RabbitMQ</strong></p>
<p>RabbitMQ是使用ErLang语言开发的一款MQ产品。其吞吐量较Kafka与RocketMQ要低，且由于其不是Java语言开发，所以公司内部对其实现定制化开发难度较大。</p>
</li>
<li><p><strong>Kafka</strong></p>
<p>Kafka是使用Scala/Java语言开发的一款MQ产品。其最大的特点就是高吞吐率，常用于大数据领域的实时计算、日志采集等场景。其没有遵循任何常见的MQ协议，而是使用自研协议。对于Spring Cloud Netflix，其仅支持RabbitMQ与Kafka。</p>
</li>
<li><p><strong>RocketMQ</strong></p>
<p>RocketMQ是使用Java语言开发的一款MQ产品。经过数年阿里双11的考验，性能与稳定性非常高。其没有遵循任何常见的MQ协议，而是使用自研协议。对于Spring Cloud Alibaba，其支持RabbitMQ、Kafka，但提倡使用RocketMQ。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th align="center">关键词</th>
<th align="center">ACTIVEMQ</th>
<th align="center">RABBITMQ</th>
<th align="center">KAFKA</th>
<th align="center">ROCKETMQ</th>
</tr>
</thead>
<tbody><tr>
<td align="center">开发语言</td>
<td align="center">Java</td>
<td align="center">ErLang</td>
<td align="center">Java</td>
<td align="center">Java</td>
</tr>
<tr>
<td align="center">单机吞吐量</td>
<td align="center">万级</td>
<td align="center">万级</td>
<td align="center">十万级</td>
<td align="center">十万级</td>
</tr>
<tr>
<td align="center">Topic</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">百级Topic时会影响系统吞吐量</td>
<td align="center">千级Topic时会影响系统吞吐量</td>
</tr>
<tr>
<td align="center">社区活跃度</td>
<td align="center">低</td>
<td align="center">高</td>
<td align="center">高</td>
<td align="center">高</td>
</tr>
</tbody></table>
<h3 id="1-4-MQ常见协议"><a href="#1-4-MQ常见协议" class="headerlink" title="1.4 ＭＱ常见协议"></a>1.4 ＭＱ常见协议</h3><p>一般情况下MQ的实现是要遵循一些常规性协议的。常见的协议如下：</p>
<p><code>以下协议，RocketMQ都不支持</code></p>
<ul>
<li><p>JMS<br>JMS，Java Messaging Service（Java消息服务）。是Java平台上有关MOM（Message OrientedMiddleware，面向消息的中间件 PO/OO/AO）的技术规范，它便于消息系统中的Java应用程序进行消息交换，并且通过提供标准的产生、发送、接收消息的接口，简化企业应用的开发。ActiveMQ是该协议的典型实现。</p>
</li>
<li><p>STOMP<br>STOMP，Streaming Text Orientated Message Protocol（面向流文本的消息协议），是一种MOM设计的简单文本协议。STOMP提供一个可互操作的连接格式，允许客户端与任意STOMP消息代理（Broker）进行交互。ActiveMQ是该协议的典型实现，RabbitMQ通过插件可以支持该协议。</p>
</li>
<li><p>AMQP<br>AMQP，Advanced Message Queuing Protocol（高级消息队列协议），一个提供统一消息服务的应用<br>层标准，是应用层协议的一个开放标准，是一种MOM设计。基于此协议的客户端与消息中间件可传递<br>消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。 RabbitMQ是该协议的典型实<br>现。</p>
</li>
<li><p>MQTT<br>MQTT，Message Queuing Telemetry Transport（消息队列遥测传输），是IBM开发的一个即时通讯协<br>议，是一种二进制协议，主要用于服务器和低功耗IoT（物联网）设备间的通信。该协议支持所有平<br>台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和致动器的通信协议。 RabbitMQ通<br>过插件可以支持该协议。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ集群</title>
    <url>/2021/11/18/RocketMQ%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h2 id="一、集群搭建理论"><a href="#一、集群搭建理论" class="headerlink" title="一、集群搭建理论"></a>一、集群搭建理论</h2><img src="/2021/11/18/RocketMQ%E9%9B%86%E7%BE%A4/broker_cluster.png" class="">

<span id="more"></span>

<h3 id="1-1-数据复制与刷盘策略"><a href="#1-1-数据复制与刷盘策略" class="headerlink" title="1.1 数据复制与刷盘策略"></a>1.1 数据复制与刷盘策略</h3><img src="/2021/11/18/RocketMQ%E9%9B%86%E7%BE%A4/flush.png" class="">

<h4 id="1-1-1-复制策略"><a href="#1-1-1-复制策略" class="headerlink" title="1.1.1 复制策略"></a>1.1.1 复制策略</h4><p>复制策略是Broker的Master与Slave间的数据同步方式。分为同步复制与异步复制：</p>
<ul>
<li><p><code>同步复制</code>：<em>消息写入master后，master会等待slave同步数据成功后才向producer返回成功ACK</em></p>
</li>
<li><p><code>异步复制</code>：<em>消息写入master后，master立即向producer返回成功ACK，无需等待slave同步数据成功</em></p>
<blockquote>
<p>异步复制策略会降低系统的写入延迟，RT变小，提高了系统的吞吐量</p>
</blockquote>
</li>
</ul>
<h4 id="1-1-2-刷盘策略"><a href="#1-1-2-刷盘策略" class="headerlink" title="1.1.2 刷盘策略"></a>1.1.2 刷盘策略</h4><p>刷盘策略指的是broker中消息的<code>落盘方式</code>，即<code>消息发送到broker内存后消息持久化到磁盘的方式</code>。分为同步刷盘与异步刷盘:</p>
<ul>
<li><code>同步刷盘</code>：<em>当消息持久化到broker的<code>磁盘后</code>才算是消息写入成功。</em></li>
<li><code>异步刷盘</code>：<em>当消息写入到broker的<code>内存后</code>即表示消息写入成功，无需等待消息持久化到磁盘。</em></li>
</ul>
<blockquote>
<p>1）异步刷盘策略会降低系统的写入延迟，RT变小，提高了系统的吞吐量<br>2）消息写入到Broker的内存，一般是写入到了PageCache<br>3）对于异步 刷盘策略，消息会写入到PageCache后立即返回成功ACK。但并不会立即做落盘操作，而是当PageCache到达一定量时会自动进行落盘。</p>
</blockquote>
<h3 id="1-2-Broker集群模式"><a href="#1-2-Broker集群模式" class="headerlink" title="1.2 Broker集群模式"></a>1.2 Broker集群模式</h3><p>根据Broker集群中各个节点间关系的不同，Broker集群可以分为以下几类：</p>
<h4 id="1-2-1-单Master"><a href="#1-2-1-单Master" class="headerlink" title="1.2.1 单Master"></a>1.2.1 单Master</h4><p>只有一个broker（其本质上就不能称为集群）。这种方式也只能是在测试时使用，生产环境下不能使用，因为存在单点问题。</p>
<h4 id="1-2-2-多Master"><a href="#1-2-2-多Master" class="headerlink" title="1.2.2 多Master"></a>1.2.2 多Master</h4><p>broker集群仅由多个master构成，不存在Slave。同一Topic的各个Queue会平均分布在各个master节点上。</p>
<ul>
<li><strong>优点</strong>：配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器<br>宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步<br>刷盘一条不丢），性能最高；</li>
<li><strong>缺点</strong>：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅（不可消费），消息实时性会受到影响</li>
</ul>
<blockquote>
<p>以上优点的前提是，这些Master都配置了RAID磁盘阵列。如果没有配置，一旦出现某Master宕机，则会发生大量消息丢失的情况。</p>
</blockquote>
<h4 id="1-2-3-多Master多Slave模式-异步复制"><a href="#1-2-3-多Master多Slave模式-异步复制" class="headerlink" title="1.2.3 多Master多Slave模式-异步复制"></a>1.2.3 多Master多Slave模式-异步复制</h4><p>broker集群由多个master构成，每个master又配置了多个slave（在配置了RAID磁盘阵列的情况下，一个master一般配置一个slave即可）。master与slave的关系是主备关系，即master负责处理消息的读写请求，而slave仅负责消息的备份与master宕机后的角色切换。</p>
<p>异步复制即前面所讲的<code>复制策略</code>中的<code>异步复制策略</code>，即消息写入master成功后，master立即向producer返回成功ACK，无需等待slave同步数据成功。</p>
<p>该模式的最大特点之一是，当master宕机后slave能够<code>自动切换</code>为master。不过由于slave从master的同步具有短暂的延迟（毫秒级），所以当master宕机后，这种异步复制方式可能会存在少量消息的丢失问题。</p>
<blockquote>
<p><em>Slave从Master同步的延迟越短，其可能丢失的消息就越少</em></p>
<p>对于Master的RAID磁盘阵列；若使用的也是异步复制策略，同样也存在延迟问题，同样也可能会丢失消息。但RAID阵列的秘诀是微秒级的（因为是由硬盘支持的），所以其丢失的数据量会更少。</p>
</blockquote>
<h4 id="1-2-4-多Master多Slave模式-同步双写"><a href="#1-2-4-多Master多Slave模式-同步双写" class="headerlink" title="1.2.4 多Master多Slave模式-同步双写"></a>1.2.4 多Master多Slave模式-同步双写</h4><p>该模式是<code>多Master多Slave模式</code>的<code>同步复制</code>实现。所谓<code>同步双写</code>，指的是消息写入master成功后，master会等待slave同步数据成功后才向producer返回成功ACK，即master与slave都要写入成功后才会返回成功ACK，也即<code>双写</code>。</p>
<p>该模式与<code>异步复制模式</code>相比，优点是消息的安全性更高，不存在消息丢失的情况。但单个消息的RT(响应时间)略高，从而导致性能要略低（大约低10%）。</p>
<p>该模式存在一个大的问题：对于目前的版本，Master宕机后，Slave不会自动切换到Master（致命问题）。</p>
<h4 id="1-2-5-最佳实践"><a href="#1-2-5-最佳实践" class="headerlink" title="1.2.5 最佳实践"></a>1.2.5 最佳实践</h4><p>一般会为Master配置RAID10磁盘阵列，然后再为其配置一个Slave。即利用了RAID10磁盘阵列的高<br>效、安全性，又解决了可能会影响订阅的问题。——-多M多S+RAID10阵列</p>
<blockquote>
<p>1）RAID磁盘阵列的效率要高于Master-Slave集群。因为RAID是硬件支持的。也正因为如此，所以RAID阵列的搭建成本较高。</p>
<p>2）多Master+RAID阵列，与多Master多Slave集群的区别是什么？</p>
<ul>
<li>多Master+RAID阵列，其仅仅可以保证数据不丢失，即不影响消息写入，但其可能会影响到<br>消息的订阅。但其执行效率要远高于<code>多Master多Slave集群</code></li>
<li>多Master多Slave集群，其不仅可以保证数据不丢失，也不会影响消息写入。其运行效率要低<br>于<code>多Master+RAID阵列</code></li>
</ul>
</blockquote>
<h2 id="二、集群搭建实践"><a href="#二、集群搭建实践" class="headerlink" title="二、集群搭建实践"></a>二、集群搭建实践</h2><h3 id="2-1-集群架构"><a href="#2-1-集群架构" class="headerlink" title="2.1 集群架构"></a>2.1 集群架构</h3><p>这里要搭建一个双主双从异步复制的Broker集群。为了方便，这里使用了两台主机来完成集群的搭建。这两台主机的功能与broker角色分配如下表。</p>
<table>
<thead>
<tr>
<th align="center">序号</th>
<th align="center">主机名/IP</th>
<th align="center">IP</th>
<th align="center">功能</th>
<th align="center">BROKER角色</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">rocketmqOS1</td>
<td align="center">192.168.109.104</td>
<td align="center">NameServer + Broker</td>
<td align="center">Master1 + Slave2</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">rocketmqOS2</td>
<td align="center">192.168.109.105</td>
<td align="center">NameServer + Broker</td>
<td align="center">Master2 + Slave1</td>
</tr>
</tbody></table>
<h3 id="2-2-克隆生成rocketmqOS1"><a href="#2-2-克隆生成rocketmqOS1" class="headerlink" title="2.2 克隆生成rocketmqOS1"></a>2.2 克隆生成rocketmqOS1</h3><p>克隆主机，并修改配置。指定主机名为rocketmqOS1</p>
<h3 id="2-3-修改rocketmqOS1配置文件"><a href="#2-3-修改rocketmqOS1配置文件" class="headerlink" title="2.3 修改rocketmqOS1配置文件"></a>2.3 修改rocketmqOS1配置文件</h3><ol>
<li><p>要修改的配置文件在rocketMQ解压目录的<code>conf/2m-2s-async</code>目录中</p>
<img src="/2021/11/18/RocketMQ%E9%9B%86%E7%BE%A4/mqOS1.png" class=""></li>
<li><p><strong>修改broker-a.properties</strong>———-Master机，将该配置文件内容修改为如下：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 指定整个broker集群的名称，或者说是RocketMQ集群的名称</span></span><br><span class="line"><span class="attr">brokerClusterName</span>=<span class="string">DefaultCluster</span></span><br><span class="line"><span class="comment"># 指定master-slave集群的名称。一个RocketMQ集群可以包含多个master-slave集群</span></span><br><span class="line"><span class="attr">brokerName</span>=<span class="string">broker-a</span></span><br><span class="line"><span class="comment"># master的brokerId为0</span></span><br><span class="line"><span class="attr">brokerId</span>=<span class="string">0</span></span><br><span class="line"><span class="comment"># 指定删除消息存储过期文件的时间为凌晨4点</span></span><br><span class="line"><span class="attr">deleteWhen</span>=<span class="string">04</span></span><br><span class="line"><span class="comment"># 指定未发生更新的消息存储文件的保留时长为48小时，48小时后过期，将会被删除</span></span><br><span class="line"><span class="attr">fileReservedTime</span>=<span class="string">48</span></span><br><span class="line"><span class="comment"># 指定当前broker为异步复制master</span></span><br><span class="line"><span class="attr">brokerRole</span>=<span class="string">ASYNC_MASTER</span></span><br><span class="line"><span class="comment"># 指定刷盘策略为异步刷盘</span></span><br><span class="line"><span class="attr">flushDiskType</span>=<span class="string">ASYNC_FLUSH</span></span><br><span class="line"><span class="comment"># 指定Name Server的地址</span></span><br><span class="line"><span class="attr">namesrvAddr</span>=<span class="string">192.168.109.104:9876;192.168.109.105:9876</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>修改broker-b-s.properties</strong>——-Salve机,，将该配置文件内容修改为如下：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">brokerClusterName</span>=<span class="string">DefaultCluster</span></span><br><span class="line"><span class="comment"># 指定这是另外一个master-slave集群</span></span><br><span class="line"><span class="attr">brokerName</span>=<span class="string">broker-b</span></span><br><span class="line"><span class="comment"># slave的brokerId为非0</span></span><br><span class="line"><span class="attr">brokerId</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">deleteWhen</span>=<span class="string">04</span></span><br><span class="line"><span class="attr">fileReservedTime</span>=<span class="string">48</span></span><br><span class="line"><span class="comment"># 指定当前broker为slave</span></span><br><span class="line"><span class="attr">brokerRole</span>=<span class="string">SLAVE</span></span><br><span class="line"><span class="attr">flushDiskType</span>=<span class="string">ASYNC_FLUSH</span></span><br><span class="line"><span class="attr">namesrvAddr</span>=<span class="string">192.168.109.104:9876;192.168.109.105:9876</span></span><br><span class="line"><span class="comment"># 指定Broker对外提供服务的端口，即Broker与producer与consumer通信的端口。默认10911。由于当前主机同时充当着master1与slave2，而前面的master1使用的是默认端口。这里需要将这两个端口加以区分，以区分出master1与slave2</span></span><br><span class="line"><span class="attr">listenPort</span>=<span class="string">11911</span></span><br><span class="line"><span class="comment"># 指定消息存储相关的路径。默认路径为~/store目录。由于当前主机同时充当着master1与slave2，master1使用的是默认路径，这里就需要再指定一个不同路径</span></span><br><span class="line"><span class="attr">storePathRootDir</span>=<span class="string">~/store-s</span></span><br><span class="line"><span class="attr">storePathCommitLog</span>=<span class="string">~/store-s/commitlog</span></span><br><span class="line"><span class="attr">storePathConsumeQueue</span>=<span class="string">~/store-s/consumequeue</span></span><br><span class="line"><span class="attr">storePathIndex</span>=<span class="string">~/store-s/index</span></span><br><span class="line"><span class="attr">storeCheckpoint</span>=<span class="string">~/store-s/checkpoint</span></span><br><span class="line"><span class="attr">abortFile</span>=<span class="string">~/store-s/abort</span></span><br></pre></td></tr></table></figure></li>
<li><p>其他配置，除了以上配置外，这些配置文件中还可以设置其它属性。</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#指定整个broker集群的名称，或者说是RocketMQ集群的名称</span></span><br><span class="line"><span class="attr">brokerClusterName</span>=<span class="string">rocket-MS</span></span><br><span class="line"><span class="comment">#指定master-slave集群的名称。一个RocketMQ集群可以包含多个master-slave集群</span></span><br><span class="line"><span class="attr">brokerName</span>=<span class="string">broker-a</span></span><br><span class="line"><span class="comment">#0 表示 Master，&gt;0 表示 Slave</span></span><br><span class="line"><span class="attr">brokerId</span>=<span class="string">0</span></span><br><span class="line"><span class="comment">#多个nameServer地址，分号分割</span></span><br><span class="line"><span class="attr">namesrvAddr</span>=<span class="string">nameserver1:9876;nameserver2:9876</span></span><br><span class="line"><span class="comment">#默认为新建Topic所创建的队列数</span></span><br><span class="line"><span class="attr">defaultTopicQueueNums</span>=<span class="string">4</span></span><br><span class="line"><span class="comment">#是否允许 Broker 自动创建Topic，建议生产环境中关闭</span></span><br><span class="line"><span class="attr">autoCreateTopicEnable</span>=<span class="string">true</span></span><br><span class="line"><span class="comment">#是否允许 Broker 自动创建订阅组，建议生产环境中关闭</span></span><br><span class="line"><span class="attr">autoCreateSubscriptionGroup</span>=<span class="string">true</span></span><br><span class="line"><span class="comment">#Broker对外提供服务的端口，即Broker与producer与consumer通信的端口</span></span><br><span class="line"><span class="attr">listenPort</span>=<span class="string">10911</span></span><br><span class="line"><span class="comment">#HA高可用监听端口，即Master与Slave间通信的端口，默认值为listenPort+1</span></span><br><span class="line"><span class="attr">haListenPort</span>=<span class="string">10912</span></span><br><span class="line"><span class="comment">#指定删除消息存储过期文件的时间为凌晨4点</span></span><br><span class="line"><span class="attr">deleteWhen</span>=<span class="string">04</span></span><br><span class="line"><span class="comment">#指定未发生更新的消息存储文件的保留时长为48小时，48小时后过期，将会被删除</span></span><br><span class="line"><span class="attr">fileReservedTime</span>=<span class="string">48</span></span><br><span class="line"><span class="comment">#指定commitLog目录中每个文件的大小，默认1G</span></span><br><span class="line"><span class="attr">mapedFileSizeCommitLog</span>=<span class="string">1073741824</span></span><br><span class="line"><span class="comment">#指定ConsumeQueue的每个Topic的每个Queue文件中可以存放的消息数量，默认30w条</span></span><br><span class="line"><span class="attr">mapedFileSizeConsumeQueue</span>=<span class="string">300000</span></span><br><span class="line"><span class="comment">#在清除过期文件时，如果该文件被其他线程所占用（引用数大于0，比如读取消息），此时会阻止此次删除任务，同时在第一次试图删除该文件时记录当前时间戳。该属性则表示从第一次拒绝删除后开始计时，该文件最多可以保留的时长。在此时间内若引用数仍不为0，则删除仍会被拒绝。不过时间到后，文件将被强制删除</span></span><br><span class="line"><span class="attr">destroyMapedFileIntervalForcibly</span>=<span class="string">120000</span></span><br><span class="line"><span class="comment">#指定commitlog、consumequeue所在磁盘分区的最大使用率，超过该值，则需立即清除过期文</span></span><br><span class="line"><span class="attr">件</span></span><br><span class="line"><span class="attr">diskMaxUsedSpaceRatio</span>=<span class="string">88</span></span><br><span class="line"><span class="comment">#指定store目录的路径，默认在当前用户主目录中</span></span><br><span class="line"><span class="attr">storePathRootDir</span>=<span class="string">/usr/local/rocketmq-all-4.5.0/store</span></span><br><span class="line"><span class="comment">#commitLog目录路径</span></span><br><span class="line"><span class="attr">storePathCommitLog</span>=<span class="string">/usr/local/rocketmq-all-4.5.0/store/commitlog</span></span><br><span class="line"><span class="comment">#consumeueue目录路径</span></span><br><span class="line"><span class="attr">storePathConsumeQueue</span>=<span class="string">/usr/local/rocketmq-all-4.5.0/store/consumequeue</span></span><br><span class="line"><span class="comment">#index目录路径</span></span><br><span class="line"><span class="attr">storePathIndex</span>=<span class="string">/usr/local/rocketmq-all-4.5.0/store/index</span></span><br><span class="line"><span class="comment">#checkpoint文件路径</span></span><br><span class="line"><span class="attr">storeCheckpoint</span>=<span class="string">/usr/local/rocketmq-all-4.5.0/store/checkpoint</span></span><br><span class="line"><span class="comment">#abort文件路径</span></span><br><span class="line"><span class="attr">abortFile</span>=<span class="string">/usr/local/rocketmq-all-4.5.0/store/abort</span></span><br><span class="line"><span class="comment">#指定消息的最大大小</span></span><br><span class="line"><span class="attr">maxMessageSize</span>=<span class="string">65536</span></span><br><span class="line"><span class="comment">#Broker的角色</span></span><br><span class="line"><span class="comment"># - ASYNC_MASTER 异步复制Master</span></span><br><span class="line"><span class="comment"># - SYNC_MASTER 同步双写Master</span></span><br><span class="line"><span class="comment"># - SLAVE</span></span><br><span class="line"><span class="attr">brokerRole</span>=<span class="string">SYNC_MASTER</span></span><br><span class="line"><span class="comment">#刷盘策略</span></span><br><span class="line"><span class="comment"># - ASYNC_FLUSH 异步刷盘</span></span><br><span class="line"><span class="comment"># - SYNC_FLUSH 同步刷盘</span></span><br><span class="line"><span class="attr">flushDiskType</span>=<span class="string">SYNC_FLUSH</span></span><br><span class="line"><span class="comment">#发消息线程池数量</span></span><br><span class="line"><span class="attr">sendMessageThreadPoolNums</span>=<span class="string">128</span></span><br><span class="line"><span class="comment">#拉消息线程池数量</span></span><br><span class="line"><span class="attr">pullMessageThreadPoolNums</span>=<span class="string">128</span></span><br><span class="line"><span class="comment">#强制指定本机IP，需要根据每台机器进行修改。官方介绍可为空，系统默认自动识别，但多网卡时IP地址可能读取错误</span></span><br><span class="line"><span class="attr">brokerIP1</span>=<span class="string">192.168.3.105</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-4-克隆生成rocketmqOS2"><a href="#2-4-克隆生成rocketmqOS2" class="headerlink" title="2.4 克隆生成rocketmqOS2"></a>2.4 克隆生成rocketmqOS2</h3><p>克隆rocketmqOS1主机，并修改配置。指定主机名为rocketmqOS2。</p>
<h3 id="2-5-修改rocketmqOS2配置文件"><a href="#2-5-修改rocketmqOS2配置文件" class="headerlink" title="2.5 修改rocketmqOS2配置文件"></a>2.5 修改rocketmqOS2配置文件</h3><p>对于rocketmqOS2主机，同样需要修改rocketMQ解压目录的conf目录的子目录<code>2m-2s-async</code>中的两个配置文件。</p>
<ol>
<li><p><strong>修改broker-b.properties</strong>—–Master机</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">brokerClusterName</span>=<span class="string">DefaultCluster</span></span><br><span class="line"><span class="attr">brokerName</span>=<span class="string">broker-b</span></span><br><span class="line"><span class="attr">brokerId</span>=<span class="string">0</span></span><br><span class="line"><span class="attr">deleteWhen</span>=<span class="string">04</span></span><br><span class="line"><span class="attr">fileReservedTime</span>=<span class="string">48</span></span><br><span class="line"><span class="attr">brokerRole</span>=<span class="string">ASYNC_MASTER</span></span><br><span class="line"><span class="attr">flushDiskType</span>=<span class="string">ASYNC_FLUSH</span></span><br><span class="line"><span class="attr">namesrvAddr</span>=<span class="string">192.168.109.104:9876;192.168.109.105:9876</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>修改broker-a-s.properties</strong>———Salve机</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">brokerClusterName</span>=<span class="string">DefaultCluster</span></span><br><span class="line"><span class="attr">brokerName</span>=<span class="string">broker-a</span></span><br><span class="line"><span class="attr">brokerId</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">deleteWhen</span>=<span class="string">04</span></span><br><span class="line"><span class="attr">fileReservedTime</span>=<span class="string">48</span></span><br><span class="line"><span class="attr">brokerRole</span>=<span class="string">SLAVE</span></span><br><span class="line"><span class="attr">flushDiskType</span>=<span class="string">ASYNC_FLUSH</span></span><br><span class="line"><span class="attr">namesrvAddr</span>=<span class="string">192.168.109.104:9876;192.168.109.105:9876</span></span><br><span class="line"><span class="attr">listenPort</span>=<span class="string">11911</span></span><br><span class="line"><span class="attr">storePathRootDir</span>=<span class="string">~/store-s</span></span><br><span class="line"><span class="attr">storePathCommitLog</span>=<span class="string">~/store-s/commitlog</span></span><br><span class="line"><span class="attr">storePathConsumeQueue</span>=<span class="string">~/store-s/consumequeue</span></span><br><span class="line"><span class="attr">storePathIndex</span>=<span class="string">~/store-s/index</span></span><br><span class="line"><span class="attr">storeCheckpoint</span>=<span class="string">~/store-s/checkpoint</span></span><br><span class="line"><span class="attr">abortFile</span>=<span class="string">~/store-s/abort</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-6-启动服务器"><a href="#2-6-启动服务器" class="headerlink" title="2.6 启动服务器"></a>2.6 启动服务器</h3><h4 id="2-6-1-启动NameServer集群"><a href="#2-6-1-启动NameServer集群" class="headerlink" title="2.6.1 启动NameServer集群"></a>2.6.1 启动NameServer集群</h4><p>分别启动rocketmqOS1与rocketmqOS2两个主机中的NameServer。启动命令完全相同。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup sh bin/mqnamesrv &amp;</span><br><span class="line">tail -f ~/logs/rocketmqlogs/namesrv.log</span><br></pre></td></tr></table></figure>

<h4 id="2-6-2-启动Master"><a href="#2-6-2-启动Master" class="headerlink" title="2.6.2 启动Master"></a>2.6.2 启动Master</h4><p>分别启动rocketmqOS1与rocketmqOS2两个主机中的broker master。注意，它们指定所要加载的配置<br>文件是不同的。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup sh bin/mqbroker -c conf/2m-2s-async/broker-a.properties &amp;</span><br><span class="line">tail -f ~/logs/rocketmqlogs/broker.log</span><br><span class="line"></span><br><span class="line">nohup sh bin/mqbroker -c conf/2m-2s-async/broker-b.properties &amp;</span><br><span class="line">tail -f ~/logs/rocketmqlogs/broker.log</span><br></pre></td></tr></table></figure>

<h4 id="2-6-3-启动Slave"><a href="#2-6-3-启动Slave" class="headerlink" title="2.6.3 启动Slave"></a>2.6.3 启动Slave</h4><p>分别启动rocketmqOS1与rocketmqOS2两个主机中的broker slave。注意，它们指定所要加载的配置<br>文件是不同的。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup sh bin/mqbroker -c conf/2m-2s-async/broker-b-s.properties &amp;</span><br><span class="line">tail -f ~/logs/rocketmqlogs/broker.log</span><br><span class="line"></span><br><span class="line">nohup sh bin/mqbroker -c conf/2m-2s-async/broker-a-s.properties &amp;</span><br><span class="line">tail -f ~/logs/rocketmqlogs/broker.log</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP拥塞控制</title>
    <url>/2021/03/31/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/</url>
    <content><![CDATA[<h2 id="一、拥塞控制原理"><a href="#一、拥塞控制原理" class="headerlink" title="一、拥塞控制原理"></a>一、拥塞控制原理</h2><p>在实践中，丢包一般是当前网络变得拥塞时由于路由器缓存溢出引起的。分组重传因此作为网络拥塞的征兆来对待，为了处理网络拥塞，需要一些机制以在面临网络拥塞时遏制发送发。</p>
<h3 id="1-1-拥塞原因与代价"><a href="#1-1-拥塞原因与代价" class="headerlink" title="1.1 拥塞原因与代价"></a>1.1 拥塞原因与代价</h3><p>随着发送方增加其发送速率并使网络拥塞会发生以下情况：</p>
<ol>
<li><p>情况1：两个发送方和一台具有无穷大的路由器</p>
<p>在这种（极端）理想化的情况中，当发送速率越大，接近链路容量时，分组经历巨大的排队时延。</p>
<span id="more"></span></li>
<li><p>情况2：两个发送方和一台具有有限缓存的路由器：</p>
<p>发送方必须执行重传已补偿因为缓存溢出而丢弃(丢失)的分组。</p>
<p>发送方在遇到大时延所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本。</p>
</li>
<li><p>情况3：多个发送方和具有有限缓存的多台路由器及多跳路径</p>
<p>每当有一个分组在第二跳路由器上被丢弃时，第一跳路由器所做的将分组转发到第二跳路由器的工作就是“劳而无功”的。即当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了。</p>
</li>
</ol>
<h3 id="1-2-拥塞控制方法"><a href="#1-2-拥塞控制方法" class="headerlink" title="1.2 拥塞控制方法"></a>1.2 拥塞控制方法</h3><p>在实践中所采用的两种主要的拥塞方法，根据网络层是否为运输层拥塞控制提供显式帮助，来区分拥塞控制方法：</p>
<ul>
<li><p>端到端拥塞控制</p>
<p>网络层没有为运输层拥塞控制提供显式支持。即在网络中存在拥塞，端系统也必须通过对网络行为的观察(如分组丢失和时延)来推断。TCP采用端到端的方法解决拥塞控制，TCP报文段的丢失(通过超时或3次冗余确认而得知)被认为是网络拥塞的一个迹象。</p>
</li>
<li><p>网络辅助的拥塞控制</p>
<p>在<strong>ATM可用比特率</strong>拥塞控制中，路由器显式地通知发送方它(路由器)能在输出链路上支持的最大主机发送速率。</p>
</li>
</ul>
<h2 id="二、TCP拥塞控制"><a href="#二、TCP拥塞控制" class="headerlink" title="二、TCP拥塞控制"></a>二、TCP拥塞控制</h2><p>TCP必须使用端到端拥塞控制而不是使网络辅助的拥塞控制，<strong>因为IP层不向端系统提供显式的网络拥塞反馈</strong>。</p>
<p>在TCP流量控制中提到TCP连接的每一端都是由一个接收缓存、一个发送缓存和几个变量(LastByteRead、rwnd等)组成。运行在TCP发送方的TCP拥塞控制机制跟踪一个额外的变量，即<strong>拥塞窗口</strong>(cwnd)。在一个发送方中未被确认的数据量不会超过cwnd与rwnd中的最小值：</p>
<center>LasteByteSent - LastByteAcked <= min {cwnd , rwnd}</center>

<p>约束限制了发送方中未被确认的数据量，因此间接限制了发送方的发送速率，所以发送方的发送速率大概是cwnd/RTT字节/秒，通过调节cwnd的值，发送方因此能调整它向连接发送数据的速率。</p>
<p><strong>那么TCP发送方怎么确定它应当发送的速率，使得网络不会堵塞，与此同时又能充分利用所有可用的宽带？</strong>TCP使用了下列指导性原则回答这些问题：</p>
<ul>
<li>一个丢失的报文段表意味着拥塞，因此当丢失报文段时应当降低TCP发送方的速率</li>
<li>一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，当对先前未确认报文段的确认到达时，能够增加发送方的速率。确认的到达表示报文段从发送方成功地交付给接收方，因此该网络不拥塞，拥塞窗口长度可以增加。</li>
<li>宽带探测。</li>
</ul>
<h3 id="2-1-TCP拥塞控制算法"><a href="#2-1-TCP拥塞控制算法" class="headerlink" title="2.1 TCP拥塞控制算法"></a>2.1 TCP拥塞控制算法</h3><p>该算法包括3个主要部分：慢启动、拥塞避免、快速恢复。慢启动和拥塞避免是TCP的强制部分，两者的差异在于对收到的ACK做出反应时增加cwnd长度的方式，慢启动比拥塞避免能更快地增加cwnd的长度。快速恢复是推荐部分，对TCP发送方并非是必需的。</p>
<h4 id="2-1-1-慢启动"><a href="#2-1-1-慢启动" class="headerlink" title="2.1.1 慢启动"></a>2.1.1 慢启动</h4><p>在慢启动状态，cwnd的值以一个MSS开始并且每当传输的报文段首次被确认就增加一个MSS。如图所示：</p>
<img src="/2021/03/31/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/TCP%E6%85%A2%E5%90%AF%E5%8A%A8.png" class="">

<p><strong>TCP发送速率起始慢，但在慢启动阶段以指数增长。</strong>何时结束这种指数增长呢？</p>
<p><strong>首先</strong>，如果存在一个由超时指示的丢包事件，TCP发送方将cwnd设置为1并重新开始慢启动过程。它还将第二个状态变量的值ssthresh(“慢启动阈值”的速记)设置为cwnd/2，即当检测到拥塞时将ssthresh置为拥塞窗口值的一半。<strong>第二种</strong>方式与ssthresh的值相关联，当cwnd的值等于ssthresh时，结束慢启动并且TCP转移到拥塞避免模式。<strong>最后一种</strong>是，如果检测到3个冗余ACK，这时TCP执行一种<strong>快速重传</strong>并进入<strong>快速恢复</strong>状态。</p>
<h4 id="2-1-2-拥塞避免"><a href="#2-1-2-拥塞避免" class="headerlink" title="2.1.2 拥塞避免"></a>2.1.2 拥塞避免</h4><p>进入拥塞避免状态，cwnd的值大约是上次遇到拥塞时的值的一半，即距离拥塞可能并不遥远，TCP无法每过一个RTT再将cwnd的值翻番，而是采用了一种较为保守的方法，<strong>每个RTT只将cwnd的值增加一个MSS</strong>。那何时停止结束拥塞避免的线性增长呢？</p>
<p>当出现超时时，与慢启动的情况一样，cwnd的值被设置为1MSS，当丢包事件出现时，ssthresh的值被更新为cwnd值的一半。如果是由一个三个冗余ACK事件触发，TCP将cwnd的值减半，并且当收到3个冗余ACK，将ssthresh的值记录为cwnd的值的一半。接下来进入快速恢复状态。</p>
<h4 id="2-1-3-快速恢复"><a href="#2-1-3-快速恢复" class="headerlink" title="2.1.3 快速恢复"></a>2.1.3 快速恢复</h4><p>在快速恢复中，对于引起TCP进人快速恢复状态的缺失报文段，对收到的每个冗余的ACK, cwnd的值增加一个MSS。最终，当对丢失报文段的一个ACK到达时，TCP在降低cwnd后进人拥塞避免状态。如果出现超时事件，快速恢复在执行如同在慢启动和拥塞避免中相同的动作后，迁移到慢启动状态:当丟包事件出现时，cwnd 的值被设置为1个MSS，并且ssthresh的值设置为cwnd值的一半。</p>
<table>
<thead>
<tr>
<th align="center">状态</th>
<th align="center">行为</th>
</tr>
</thead>
<tbody><tr>
<td align="center">cwnd &lt; ssthresh</td>
<td align="center">发送端处于慢启动阶段，窗口指数增长</td>
</tr>
<tr>
<td align="center">cwnd &gt; ssthresh</td>
<td align="center">发送端处于拥塞避免阶段，窗口线性增长</td>
</tr>
<tr>
<td align="center">收到三个冗余ACK</td>
<td align="center">ssthresh设置为cwnd/2，cwnd=ssthresh + 3</td>
</tr>
<tr>
<td align="center">超时事件发生</td>
<td align="center">ssthresh = cwnd/2 , cwnd = 1MSS，进入慢启动阶段</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>进程详解</title>
    <url>/2021/09/17/%E8%BF%9B%E7%A8%8B%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="一、进程"><a href="#一、进程" class="headerlink" title="一、进程"></a>一、进程</h2><p>进程的经典定义就是<code>一个执行中程序的实例</code>。系统中的每个程序都运行在某个进程的上下文(context)中，上下文是由程序正确运行所需的状态组成的，这个状态包括<code>存放在内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合</code>。</p>
<p>进程提供给应用程序的<strong>关键抽象</strong>：</p>
<ul>
<li><strong>一个独立的逻辑控制流，它提供一个假象，好像我们的程序独占地使用处理器</strong>。</li>
<li><strong>一个私有的地址空间，它提供一个假象，好像我们的程序独占地使用内存系统</strong>。</li>
</ul>
<span id="more"></span>

<h3 id="1-1-逻辑控制流"><a href="#1-1-逻辑控制流" class="headerlink" title="1.1 逻辑控制流"></a>1.1 逻辑控制流</h3><img src="/2021/09/17/%E8%BF%9B%E7%A8%8B%E8%AF%A6%E8%A7%A3/%E9%80%BB%E8%BE%91%E6%8E%A7%E5%88%B6%E6%B5%81.png" class=""> 如图所示，处理器的一个物理控制流被分成3个逻辑流，每个进程一个，每个竖直的条表示一个进程的逻辑流的一部分。进程是轮流使用处理器的，每个进程执行它的流的一部分，然后被**抢占**（暂时挂起），然后轮到其他进程。

<h3 id="1-2-并发流"><a href="#1-2-并发流" class="headerlink" title="1.2 并发流"></a>1.2 并发流</h3><p><strong>一个逻辑流的执行在时间上与另一个流重叠，称为并发流，这两个流并发地运行</strong>，在上图中，进程A和B并发地运行，A和C也一样。B和C没有并发地运行，因为B的最后一条指令在C的第一条指令之前执行。</p>
<p>多个流并发地执行的一般现象称为<strong>并发</strong>。一个进程和其他进程轮流运行的概念称为<strong>多任务</strong>。一个进程执行它的控制流的一部分的每一时间段叫做<strong>时间片</strong>，因此多任务也叫<strong>时间分片</strong>。</p>
<p><strong>并发流的思想与流运行的处理器核数或者计算机数无关</strong>。如果两个流并发地运行在不同的处理器核或者计算机上，那么称为<strong>并行流</strong>，它们并行地运行，且并行地执行。</p>
<h3 id="1-3-私有地址空间"><a href="#1-3-私有地址空间" class="headerlink" title="1.3 私有地址空间"></a>1.3 私有地址空间</h3><p>进程为每个程序提供它自己的私有地址空间。一般而言，和这个空间中某个地址相关联的那个内存字节是不能被其他进程读或者写的，从这个意义上说，这个地址空间是私有的。尽管和每个私有地址空间相关联的内存的内容一般是不同的，但是每个这样的空间都有相同的通用结构。下图是一个x86-64 Linux进程的地址空间的组织结构。</p>
<img src="/2021/09/17/%E8%BF%9B%E7%A8%8B%E8%AF%A6%E8%A7%A3/%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4.png" class="">

<p>地址空间底部是保留给用户程序的，包括通常的代码、数据、堆和栈段。代码段总是从地址0x400000开始。地址空间顶部保留给内核(操作系统常驻内存的部分)。地址空间的这个部分包含内核在代表进程执行指令时(比如当应用程序执行系统调用时)使用的代码、数据和栈。</p>
<h3 id="1-4-用户模式和内核模式"><a href="#1-4-用户模式和内核模式" class="headerlink" title="1.4 用户模式和内核模式"></a>1.4 用户模式和内核模式</h3><p>为了使操作系统内核提供一个无懈可击的进程抽象，处理器需限制一个应用可以执行的指令以及它可以访问的地址空间范围。</p>
<p>处理器通常是用某个控制寄存器中的一个<strong>模式位</strong>(mode bit)来提供这种功能的，该寄存器描述了进程当前享有的特权。当设置了模式位时，进程就运行在<strong>内核模式</strong>中(有时叫做<strong>超级用户模式</strong>)。<code>一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中的任何内存位置</code>。</p>
<p>没有设置模式位时，进程就进入<strong>用户模式</strong>。<code>用户模式中的进程不允许执行特权指令，比如停止处理器、改变模式位，或者发起一个I/O操作；也不允许用户模式中的进程直接引用地址空间中内核区的代码和数据</code>。用户程序必须通过系统调用接口间接地访问内核代码和数据。</p>
<p><strong>应用程序代码的进程初始时是在用户模式中</strong>，进程从用户模式变为内核模式的唯一方法是通过诸如中断、故障、或者陷入系统调用这样的异常。</p>
<h3 id="1-5-上下文切换"><a href="#1-5-上下文切换" class="headerlink" title="1.5 上下文切换"></a>1.5 上下文切换</h3><p>操作系统内核使用一种称为<strong>上下文切换</strong>(contextswitch)的较高层形式的异常控制流来实现多任务。上下文切换机制是建立在那些较低层异常机制之上的。<strong>内核为每个进程维持一个上下文</strong>(context)。上下文就是内核重新启动一个被抢占的进程所需的状态。它由一些对象的值组成，这些对象包括通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构，比如描述地址空间的页表、包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表。</p>
<p>在进程的执行中，内核可以决定抢占当前进程，并重新开始一个先前被抢占了的进程，这种决策叫做<strong>调度</strong>，是由内核中称为调度器的代码处理的。</p>
<p>内核调度了一个新的进程运行后，它就抢占当前进程，并使用<code>上下文切换</code>的机制来将控制转移到新的进程：1.保存当前进程的上下文，2.恢复某个先前被抢占的进程被保存的上下文，3.将控制传递给这个新恢复的进程。</p>
<img src="/2021/09/17/%E8%BF%9B%E7%A8%8B%E8%AF%A6%E8%A7%A3/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2.png" class="">

<p>一个read系统调用需要访问磁盘，内核可以选择执行上下文切换，运行另外一个进程B，而不是等待数据从磁盘到达，随后进程B在用户模式下运行一会儿，直到磁盘发出一个中断信号，表示数据已经从磁盘传送到了内存，内核就执行一个从进程B到进程A的上下文切换，将控制返回给进程A中紧随在系统调用read之后的那条指令。（<strong>上下文切换一般在内核模式，用户模式也可以</strong>）</p>
<h2 id="二、进程控制"><a href="#二、进程控制" class="headerlink" title="二、进程控制"></a>二、进程控制</h2><p>本节所描述的重要函数都是C程序中操作进程的系统调用。</p>
<h3 id="2-1-获取进程ID"><a href="#2-1-获取进程ID" class="headerlink" title="2.1 获取进程ID"></a>2.1 获取进程ID</h3><p>每个进程都有一个唯一的正数(非零)进程ID（PID）。getpid函数返回调用进程的PID；getppid函数返回它的父进程的PID(创建调用进程的进程)。</p>
<h3 id="2-2-创建和终止进程"><a href="#2-2-创建和终止进程" class="headerlink" title="2.2 创建和终止进程"></a>2.2 创建和终止进程</h3><p>从程序员的角度看，进程总是处于下面三种状态之一：</p>
<ul>
<li><strong>运行</strong>。进程要么在CPU上执行，要么在等待被执行且最终会被内核调度。</li>
<li><strong>停止</strong>。进程的执行被挂起(suspended)， 且不会被调度。当收到SIGSTOP、SIGTSTP、SIGTTIN或者SIGTTOU信号时，进程就停止，并且保持停止直到它收到一个SIGCONT信号，在这个时刻，进程再次开始运行。(信号是一种软件中断的形式)</li>
<li><strong>终止</strong>。进程永远地停止了。进程会因为三种原因终止: 1)收到一个信号，该信号的<br>默认行为是终止进程，2)从主程序返回，3)调用exit函数。</li>
</ul>
<p>exit函数以status退出状态来终止进程(另一种设置退出状态的方法是从主程序中返回一个整数值。)</p>
<p>父进程通过调用fork函数创建一个新的运行的子进程。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>异步编排-CompletableFuture</title>
    <url>/2022/06/29/%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92-CompletableFuture/</url>
    <content><![CDATA[<p>在 Java 8 中, 新增加了一个包含 50 个方法左右的类: CompletableFuture，提供了非常强大的Future 的扩展功能，可以帮助我们简化异步编程的复杂性，提供了函数式编程的能力，可以通过回调的方式处理计算结果，并且提供了转换和组合 CompletableFuture 的方法。 CompletableFuture 类实现了 Future 接口，所以你还是可以像以前一样通过<code>get</code>方法阻塞或者轮询的方式获得结果，但是这种方式不推荐使用。</p>
<p>CompletableFuture 和 FutureTask 同属于 Future 接口的实现类，都可以获取线程的执行结果。</p>
<span id="more"></span>

<img src="/2022/06/29/%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92-CompletableFuture/CompletableFuture.png" class="">

<h2 id="创建异步对象"><a href="#创建异步对象" class="headerlink" title="创建异步对象"></a>创建异步对象</h2><p>CompletableFuture 提供了四个静态方法来创建一个异步操作。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CompletableFuture&lt;Void&gt; <span class="title">runAsync</span><span class="params">(Runnable runnable)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CompletableFuture&lt;Void&gt; <span class="title">runAsync</span><span class="params">(Runnable runnable, Executor executor)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title">supplyAsync</span><span class="params">(Supplier&lt;U&gt; supplier)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title">supplyAsync</span><span class="params">(Supplier&lt;U&gt; supplier, Executor executor)</span></span></span><br></pre></td></tr></table></figure>

<ol>
<li>runAsync都是没有返回结果的，supplyAsync都是可以获取返回结果的。</li>
<li>可以传入自定义的线程池，否则就使用ForkJoinPool.commonPool()默认线程池。。</li>
</ol>
<h3 id="获取任务结果的方法"><a href="#获取任务结果的方法" class="headerlink" title="获取任务结果的方法"></a>获取任务结果的方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 如果完成则返回结果，否则就抛出具体的异常</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> T <span class="title">get</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, ExecutionException </span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 最大时间等待返回结果，否则就抛出具体异常</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> T <span class="title">get</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException, ExecutionException, TimeoutException</span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 完成时返回结果值，否则抛出unchecked异常。为了更好地符合通用函数形式的使用，如果完成此 CompletableFuture所涉及的计算引发异常，则此方法将引发unchecked异常并将底层异常作为其原因</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> T <span class="title">join</span><span class="params">()</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 如果完成则返回结果值（或抛出任何遇到的异常），否则返回给定的 valueIfAbsent。</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> T <span class="title">getNow</span><span class="params">(T valueIfAbsent)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 如果任务没有完成，返回的值设置为给定值</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">complete</span><span class="params">(T value)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">// 如果任务没有完成，就抛出给定异常</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">completeExceptionally</span><span class="params">(Throwable ex)</span> </span></span><br><span class="line"><span class="function"> </span></span><br></pre></td></tr></table></figure>

<h2 id="计算完成时回调方法"><a href="#计算完成时回调方法" class="headerlink" title="计算完成时回调方法"></a>计算完成时回调方法</h2><p>whenComplete是当某个任务执行完成后执行的回调方法，会将执行结果或者执行期间抛出的异常传递给回调方法，如果是正常执行则异常为null，回调方法对应的CompletableFuture的result和该任务一致，如果该任务正常执行，则get方法返回执行结果，如果是执行异常，则get方法抛出异常。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;T&gt; <span class="title">whenComplete</span><span class="params">(BiConsumer&lt;? <span class="keyword">super</span> T, ? <span class="keyword">super</span> Throwable&gt; action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;T&gt; <span class="title">whenCompleteAsync</span><span class="params">(BiConsumer&lt;? <span class="keyword">super</span> T, ? <span class="keyword">super</span> Throwable&gt; action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;T&gt; <span class="title">whenCompleteAsync</span><span class="params">(BiConsumer&lt;? <span class="keyword">super</span> T, ? <span class="keyword">super</span> Throwable&gt; action, Executor executor)</span></span></span><br><span class="line"><span class="function">    </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;T&gt; <span class="title">exceptionally</span><span class="params">(Function&lt;Throwable, ? extends T&gt; fn)</span></span></span><br><span class="line"><span class="function">       </span></span><br></pre></td></tr></table></figure>

<ol>
<li><p>whenComplete 可以处理正常和异常的计算结果，exceptionally 处理异常情况。并且、可以自定义线程池，默认的使用ForkJoinPool.commonPool()线程池。</p>
</li>
<li><p>whenComplete 和 whenCompleteAsync 的区别：</p>
<blockquote>
<p>whenComplete：是执行当前任务的线程执行继续执行 whenComplete 的任务。 whenCompleteAsync：是执行把 whenCompleteAsync 这个任务继续提交给线程池或另一个线程来进行执行。</p>
</blockquote>
</li>
<li><p>方法不以 Async 结尾，意味着 Action 使用相同的线程执行，而 Async 可能会使用其他线程执行（如果是使用相同的线程池，也可能会被同一个线程选中执行）</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CompletableFutureDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException,InterruptedException </span>&#123;</span><br><span class="line">       CompletableFuture future = CompletableFuture.supplyAsync(<span class="keyword">new</span> Supplier&lt;Object&gt;() &#123;</span><br><span class="line">          	<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> Object <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(Thread.currentThread().getName() +<span class="string">&quot;completableFuture&quot;</span>);</span><br><span class="line">                <span class="keyword">int</span> i = <span class="number">10</span> / <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1024</span>;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;).whenComplete(<span class="keyword">new</span> BiConsumer&lt;Object, Throwable&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(Object o, Throwable throwable)</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;-------o=&quot;</span> + o.toString());</span><br><span class="line">                System.out.println(<span class="string">&quot;-------throwable=&quot;</span> + throwable);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).exceptionally(<span class="keyword">new</span> Function&lt;Throwable, Object&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> Object <span class="title">apply</span><span class="params">(Throwable throwable)</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;throwable=&quot;</span> + throwable); <span class="keyword">return</span> <span class="number">6666</span>;</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;);</span><br><span class="line">        System.out.println(future.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<p>有异常：</p>
<img src="/2022/06/29/%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92-CompletableFuture/whenComplete.png" class="">

<p>无异常：</p>
<img src="/2022/06/29/%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92-CompletableFuture/whenCompleteNoExce.png" class="">

<h2 id="handle方法"><a href="#handle方法" class="headerlink" title="handle方法"></a>handle方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;U&gt; <span class="function">CompletableFuture&lt;U&gt; <span class="title">handle</span><span class="params">(BiFunction&lt;? <span class="keyword">super</span> T, Throwable, ? extends U&gt; fn)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title">handleAsync</span><span class="params">(BiFunction&lt;? <span class="keyword">super</span> T, Throwable, ? extends U&gt; fn)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title">handleAsync</span><span class="params">(BiFunction&lt;? <span class="keyword">super</span> T, Throwable, ? extends U&gt; fn, Executor executor)</span></span></span><br><span class="line"><span class="function">       </span></span><br></pre></td></tr></table></figure>

<p>和whenComplete基本 一样，可对结果做最后的处理（可处理异常），可改变返回值。</p>
<h2 id="线程串行化方法"><a href="#线程串行化方法" class="headerlink" title="线程串行化方法"></a>线程串行化方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//----thenApply</span></span><br><span class="line"><span class="keyword">public</span> &lt;U&gt; <span class="function">CompletableFuture&lt;U&gt; <span class="title">thenApply</span><span class="params">(Function&lt;? <span class="keyword">super</span> T,? extends U&gt; fn)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title">thenApplyAsync</span><span class="params">(Function&lt;? <span class="keyword">super</span> T,? extends U&gt; fn)</span></span></span><br><span class="line"><span class="function">       </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title">thenApplyAsync</span><span class="params">(Function&lt;? <span class="keyword">super</span> T,? extends U&gt; fn, Executor executor)</span></span></span><br><span class="line"><span class="function"> </span></span><br><span class="line"><span class="function"><span class="comment">//----thenAccept  </span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">thenAccept</span><span class="params">(Consumer&lt;? <span class="keyword">super</span> T&gt; action)</span></span></span><br><span class="line"><span class="function">     </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">thenAcceptAsync</span><span class="params">(Consumer&lt;? <span class="keyword">super</span> T&gt; action)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">thenAcceptAsync</span><span class="params">(Consumer&lt;? <span class="keyword">super</span> T&gt; action, Executor executor)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"> <span class="comment">//----thenRun   </span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">thenRun</span><span class="params">(Runnable action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">thenRunAsync</span><span class="params">(Runnable action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">thenRunAsync</span><span class="params">(Runnable action, Executor executor)</span></span></span><br></pre></td></tr></table></figure>

<ol>
<li><p>thenApply 方法：当一个线程依赖另一个线程时，获取上一个任务返回的结果，并返回当前任务的返回值。</p>
<blockquote>
<p>Function&lt;? super T,? extends U&gt;</p>
<p>T：上一个任务返回结果的类型；U：当前任务的返回值类型</p>
</blockquote>
</li>
<li><p>thenAccept 方法：消费处理结果。接收任务的处理结果，并消费处理，无返回结果。</p>
</li>
<li><p>thenRun 方法：只要上面的任务执行完成，就开始执行 thenRun，只是处理完任务后，执行thenRun 的后续操作</p>
</li>
<li><p>带有 Async 默认是异步执行的。</p>
</li>
<li><p><strong>以上都要前置任务成功完成。</strong></p>
</li>
</ol>
<h2 id="两任务组合-都要完成"><a href="#两任务组合-都要完成" class="headerlink" title="两任务组合-都要完成"></a>两任务组合-都要完成</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//--------thenCombine</span></span><br><span class="line"><span class="keyword">public</span> &lt;U,V&gt; <span class="function">CompletableFuture&lt;V&gt; <span class="title">thenCombine</span><span class="params">(CompletionStage&lt;? extends U&gt; other,BiFunction&lt;? <span class="keyword">super</span> T,? <span class="keyword">super</span> U,? extends V&gt; fn)</span></span></span><br><span class="line"><span class="function">    </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U,V&gt; CompletableFuture&lt;V&gt; <span class="title">thenCombineAsync</span><span class="params">(CompletionStage&lt;? extends U&gt; other,BiFunction&lt;? <span class="keyword">super</span> T,? <span class="keyword">super</span> U,? extends V&gt; fn)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U,V&gt; CompletableFuture&lt;V&gt; <span class="title">thenCombineAsync</span><span class="params">(CompletionStage&lt;? extends U&gt; other,BiFunction&lt;? <span class="keyword">super</span> T,? <span class="keyword">super</span> U,? extends V&gt; fn, Executor executor)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">//--------  thenAcceptBoth</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U&gt; CompletableFuture&lt;Void&gt; <span class="title">thenAcceptBoth</span><span class="params">(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;? <span class="keyword">super</span> T, ? <span class="keyword">super</span> U&gt; action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U&gt; CompletableFuture&lt;Void&gt; <span class="title">thenAcceptBothAsync</span><span class="params">(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;? <span class="keyword">super</span> T, ? <span class="keyword">super</span> U&gt; action)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U&gt; CompletableFuture&lt;Void&gt; <span class="title">thenAcceptBothAsync</span><span class="params">(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;? <span class="keyword">super</span> T, ? <span class="keyword">super</span> U&gt; action, Executor executor)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">//---------runAfterBoth</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">runAfterBoth</span><span class="params">(CompletionStage&lt;?&gt; other,Runnable action)</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">runAfterBothAsync</span><span class="params">(CompletionStage&lt;?&gt; other,Runnable action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">runAfterBothAsync</span><span class="params">(CompletionStage&lt;?&gt; other,Runnable action,Executor executor)</span></span></span><br></pre></td></tr></table></figure>

<ol>
<li>两个任务必须都完成，触发该任务。</li>
<li>thenCombine：组合两个 future，获取两个 future 的返回结果，并返回当前任务的返回值</li>
<li>thenAcceptBoth：组合两个 future，获取两个 future 任务的返回结果，然后处理任务，没有返回值。</li>
<li>runAfterBoth：组合两个 future，不需要获取 future 的结果，只需两个 future 处理完任务后，处理该任务。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//thenCombine</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf3 = cf1.thenCombine(cf2, (a, b) -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf3 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> a + b;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        System.out.println(<span class="string">&quot;cf3结果-&gt;&quot;</span> + cf3.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试结果：</p>
<img src="/2022/06/29/%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92-CompletableFuture/thenCombine.png" class="">

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//thenAcceptBoth</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">        </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf3 = cf1.thenAcceptBoth(cf2, (a, b) -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf3 do something....&quot;</span>);</span><br><span class="line">            System.out.println(a + b);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        System.out.println(<span class="string">&quot;cf3结果-&gt;&quot;</span> + cf3.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试结果：</p>
<img src="/2022/06/29/%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92-CompletableFuture/thenAcceptBoth.png" class="">

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//runAfterBoth</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf1 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf1 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Integer&gt; cf2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf2 do something....&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        CompletableFuture&lt;Void&gt; cf3 = cf1.runAfterBoth(cf2, () -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot; cf3 do something....&quot;</span>);</span><br><span class="line">        &#125;);</span><br><span class="line"> </span><br><span class="line">        System.out.println(<span class="string">&quot;cf3结果-&gt;&quot;</span> + cf3.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试结果：</p>
<img src="/2022/06/29/%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92-CompletableFuture/runAfterBoth.png" class="">

<h2 id="两任务组合-一个完成"><a href="#两任务组合-一个完成" class="headerlink" title="两任务组合- 一个完成"></a>两任务组合- 一个完成</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;U&gt; <span class="function">CompletableFuture&lt;U&gt; <span class="title">applyToEither</span><span class="params">(CompletionStage&lt;? extends T&gt; other, Function&lt;? <span class="keyword">super</span> T, U&gt; fn)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title">applyToEitherAsync</span><span class="params">(CompletionStage&lt;? extends T&gt; other, Function&lt;? <span class="keyword">super</span> T, U&gt; fn)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="title">applyToEitherAsync</span><span class="params">(CompletionStage&lt;? extends T&gt; other, Function&lt;? <span class="keyword">super</span> T, U&gt; fn,Executor executor)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">acceptEither</span><span class="params">(CompletionStage&lt;? extends T&gt; other,Consumer&lt;? <span class="keyword">super</span> T&gt; action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">acceptEitherAsync</span><span class="params">(CompletionStage&lt;? extends T&gt; other,Consumer&lt;? <span class="keyword">super</span> T&gt; action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">acceptEitherAsync</span><span class="params">(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? <span class="keyword">super</span> T&gt; action,Executor executor)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">runAfterEither</span><span class="params">(CompletionStage&lt;?&gt; other,Runnable action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">runAfterEitherAsync</span><span class="params">(CompletionStage&lt;?&gt; other,Runnable action)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;Void&gt; <span class="title">runAfterEitherAsync</span><span class="params">(CompletionStage&lt;?&gt; other,Runnable action,Executor executor)</span></span></span><br></pre></td></tr></table></figure>

<ol>
<li>当两个任务中，任意一个 future 任务完成的时候，执行任务</li>
<li>applyToEither：两个任务有一个执行完成，获取它的返回值，处理任务并有新的返回值。 </li>
<li>acceptEither：两个任务有一个执行完成，获取它的返回值，处理任务，没有新的返回值。</li>
<li> runAfterEither：两个任务有一个执行完成，不需要获取 future 的结果，处理任务，也没有返回值。</li>
</ol>
<h2 id="多任务组合"><a href="#多任务组合" class="headerlink" title="多任务组合"></a>多任务组合</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CompletableFuture&lt;Void&gt; <span class="title">allOf</span><span class="params">(CompletableFuture&lt;?&gt;... cfs)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> CompletableFuture&lt;Object&gt; <span class="title">anyOf</span><span class="params">(CompletableFuture&lt;?&gt;... cfs)</span></span></span><br></pre></td></tr></table></figure>

<ol>
<li><p>allOf：CompletableFuture是多个任务都执行完成后才会执行，只有有一个任务执行异常，则返回的CompletableFuture执行get方法时会抛出异常，如果都是正常执行，则get返回null。</p>
</li>
<li><p>anyOf：CompletableFuture是多个任务只要有一个任务执行完成，则返回的CompletableFuture执行get方法时会抛出异常，如果都是正常执行，则get返回执行完成任务的结果。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux文件和目录</title>
    <url>/2019/11/30/Linux%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/</url>
    <content><![CDATA[<h1 id="一、Linux的文件权限与目录配置"><a href="#一、Linux的文件权限与目录配置" class="headerlink" title="一、Linux的文件权限与目录配置"></a>一、Linux的文件权限与目录配置</h1><p>Linux一般将文件可读写的身份分为三个类别，分别是拥有者(owner)、所属群组(group)、其他人(others)，且三种身份各有读、写、执行等权限</p>
<h2 id="1-1-用户与用户组"><a href="#1-1-用户与用户组" class="headerlink" title="1.1 用户与用户组"></a>1.1 用户与用户组</h2><ol>
<li><p>文件拥有者</p>
<p>用户</p>
</li>
<li><p><strong>用户组</strong></p>
<p>用户组最有用的功能之一，就是当你在团队进行协同工作的时候。</p>
<p>每个账户都可以有多个用户组的支持</p>
</li>
<li><p>其他人</p>
</li>
</ol>
<p>在Linux里面，任何一个文件都具有用户(User)、所属群组(Group)及其他人(Others)三种身份的个别权限。</p>
<p>在Linux中，默认的情况下，所有的系统上的账号与一般身份用户，还有那个root相关信息，都记录在/etc/passwd这个文件内，至于个人的密码则是记录在/etc/shadow这个文件内。此外，Linux所有的组名都记录在/etc/group中。</p>
<span id="more"></span>

<h2 id="1-2-Linux文件权限概念"><a href="#1-2-Linux文件权限概念" class="headerlink" title="1.2 Linux文件权限概念"></a>1.2 Linux文件权限概念</h2><h3 id="1-2-1-Linux文件属性"><a href="#1-2-1-Linux文件属性" class="headerlink" title="1.2.1 Linux文件属性"></a>1.2.1 Linux文件属性</h3><ol>
<li><p>查看文件命令：ls -al</p>
<ol>
<li>ls是list的意思，重点在显示文件的文件名与相关属性，而选项【-al】则表示列出所有的文件详细的权限与属性（包含隐藏文件，文件名第一个字符为【 . 】的文件）。</li>
<li>显示的格式为：[ 权限 ] [ 链接数 ]  [ 拥有者 ]  [ 用户组 ]  [ 文件大小 ]  [ 最后修改日期 ]  [ 文件名 ]</li>
</ol>
</li>
<li><p>第一栏文件的类型与权限</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-rwxrwx---</span><br></pre></td></tr></table></figure>

<ul>
<li>第一个字符代表这个文件是<strong>目录、文件或是链接文件</strong>等：</li>
<li>当为[ d ]则是目录，例如上表文件名为【.config】的那一行；</li>
<li>当为[ - ]则是文件。</li>
<li>若是[ | ]则表示为链接文件（link file）</li>
<li>若是[ b ]则表示为设备文件里面的可供存储的周边设备（可按块随机读写的设备）</li>
<li>若是[ c ]则表示为设备文件里面的串行端口设备，例如键盘、鼠标（一次性读取设备）</li>
<li>接下来的字符中，以三个为一组，且均为【rwx】的三个参数的组合。其中，[ r ]代表可读（read）、[ w ]代表可写、[ x ]代表可执行(execute)。这三个权限的位置不会改变，如果没有权限，就会出现减号[ - ]而已。</li>
<li>第一组为<strong>文件拥有者可具备的权限</strong>，</li>
<li>第二组为<strong>加入此用户组之账号的权限</strong></li>
<li>第三组为<strong>非本人且没有加入本用户组的其他账号的权限</strong></li>
</ul>
</li>
<li><p>第二栏表示有多少文件名链接到此节点(inode)</p>
<p>记录有多少不同的文件名链接到相同的一个inode号码</p>
</li>
<li><p>第三栏表示这个文件（或目录）的拥有者账号</p>
</li>
<li><p>第四栏表示这个文件的所属用户组</p>
</li>
<li><p>第五栏为这个文件的容量大小，默认单位是Bytes</p>
</li>
<li><p>第六栏为这个文件的创建日期或是最近的修改日期</p>
<p>如果需要显示完整的时间格式，可以利用ls的选项，即【ls -| –full-time】</p>
</li>
<li><p>第七栏为这个文件名</p>
</li>
</ol>
<h3 id="1-2-2-修改文件属性与权限"><a href="#1-2-2-修改文件属性与权限" class="headerlink" title="1.2.2 修改文件属性与权限"></a>1.2.2 修改文件属性与权限</h3><ul>
<li><p>chgrp：<strong>修改文件所属用户组</strong>：</p>
<p>要修改的组名必须要在/etc/group文件中才行，否则会显示错误。</p>
</li>
<li><p>chown：<strong>修改文件拥有者</strong>：</p>
<p>要修改的拥有者必须要在/etc/passwd文件中才行，否则会显示错误。</p>
<p>还可以顺便直接修改用户组的名称。</p>
</li>
<li><p>chmod：<strong>修改文件的权限，SUID、SGID、SBIT等的特性</strong>：</p>
<ul>
<li><p>数字类型修改文件权限</p>
<p>Linux文件的基本权限有9个分别是拥有者、所属群组、其他人三种身份各有自己的读、写、执行权限。各权限的数字对照为：r：4；w：2；x：1。每种身份各自的三个权限数字是需要累加的。</p>
<p>命令格式：<code>chmod 644 .bashrc</code></p>
</li>
<li><p>符号类型修改文件权限</p>
<table>
<thead>
<tr>
<th align="center">命令</th>
<th align="center">身份</th>
<th align="center">操作</th>
<th align="center">权限</th>
<th align="center">文件类型</th>
</tr>
</thead>
<tbody><tr>
<td align="center">chmod</td>
<td align="center">u、g、o、a(全部身份)</td>
<td align="center">+(加入)、-(移除)、=(设置)</td>
<td align="center">r、w、x</td>
<td align="center">文件或目录</td>
</tr>
</tbody></table>
<p>命令格式：<code>chmod u=rwx,go=rx .bashrc</code></p>
</li>
</ul>
</li>
</ul>
<h3 id="1-2-3-目录与文件的权限意义"><a href="#1-2-3-目录与文件的权限意义" class="headerlink" title="1.2.3 目录与文件的权限意义"></a>1.2.3 目录与文件的权限意义</h3><pre><code>1. 权限对文件的重要性
</code></pre>
<p>   r：可读取此文件的实际内容，如读取文本文件的文字内容等；</p>
<p>   w：可以编辑、新增或是修改该文件的内容，<strong>但不具备有删除该文件本身的权限</strong>；</p>
<p>   x：该文件具有可以被系统执行的权限。在Windows下一个文件是否具有执行的能力是借由<strong>扩展名</strong>来判断的，例如：.exe、.bat等。但在Linux下面，<strong>我们的文件是否能被执行，则是借由是否具有【x】这个权限来决定，跟文件名是没有绝对的关系的</strong>。</p>
<pre><code>2. 权限对目录的重要性
</code></pre>
<p>   <strong>目录主要的内容在记录文件名列表，文件名与目录有强烈的关联。</strong></p>
<ul>
<li><p>r（read contents in directory）：表示具有读取目录结构列表的权限。</p>
</li>
<li><p>w（modify contents of directory）：表示你具有改动该目录结构列表的权限，包括：</p>
<p>建立新的文件与目录、删除已存在的文件与目录（不论该文件的权限是什么）、将已存在的文件或目录进行更名、移动该目录内的文件和目录位置。总之，目录的w权限就与该目录下面的文件名的变动有关</p>
</li>
<li><p>x（access directory）：表示用户能否进入该目录成为工作目录的用途，所谓的工作目录就是你目前所在的目录</p>
</li>
</ul>
<p>  对一般文件来说，rwx主要是针对文件的内容来设计权限，对目录来说，rwx则是针对目录内的文件名列表来设计权限。</p>
<h3 id="1-2-4-Linux文件种类与扩展名"><a href="#1-2-4-Linux文件种类与扩展名" class="headerlink" title="1.2.4 Linux文件种类与扩展名"></a>1.2.4 Linux文件种类与扩展名</h3><h4 id="文件种类"><a href="#文件种类" class="headerlink" title="文件种类"></a>文件种类</h4><ol>
<li><p>常规文件（regular file）</p>
<p>一般在进行读写的类型文件，在ls -al所显示中第一个字符为**[ - ]**。</p>
<ol>
<li>纯文本文件（ASCII）</li>
<li>二进制文件（binary）</li>
<li>数据文件（data）</li>
</ol>
</li>
<li><p>目录</p>
<p>就是目录，第一个属性为**[ d ]**</p>
</li>
<li><p>链接文件（link）</p>
<p>类似Windows系统下面的快捷方式，第一个属性为**[ l ]**（英文L的小写</p>
</li>
<li><p>设备与设备文件（device）</p>
<p>与系统周边及存储等相关的一些文件，通常都集中在/dev这个目录下，通常又分为两种：</p>
<ol>
<li>区块（block）设备文件：就是一些存储数据，以提供系统随机存取的接口设备，比如硬盘和软盘等。第一个属性为**[ b ]**。</li>
<li>字符（character）设备文件：即是一些串行端口的接口设备，例如键盘、鼠标等。这些设备的特色就是一次性读取，不能够截断输出。第一个属性为**[ c ]**。</li>
</ol>
</li>
<li><p>数据接口文件（sockets)</p>
<p>这种类型的文件通常被用在网络上的数据交换了，第一个属性为**[ s ]**，最常在/run或/tmp这些目录中看到这种文件类型。</p>
</li>
<li><p>数据传输文件（FIFO，pipe）</p>
<p>FIFO也是一种特殊的文件类型，它主要目的是解决多个程序同时读写一个文件所造成的错误问题，FIFO是先进先出的缩写，即管道，第一个属性为**[ p ]**。</p>
</li>
</ol>
<h4 id="Linux文件扩展名"><a href="#Linux文件扩展名" class="headerlink" title="Linux文件扩展名"></a>Linux文件扩展名</h4><p>  一个Linux文件能不能被执行，与它的第一栏的十个属性有关，与文件名根本一点关系也没有，和Windows的情况不同。只要你的权限中具有<strong>X</strong>的话，即代表这个文件具有可以被执行的能力。</p>
<p>  具有可执行的权限以及具有可执行的程序代码是两回事。</p>
<p>  有以下常用的扩展名：</p>
<pre><code>1. \*.sh：脚本或批处理文件（scripts)，因为批处理文件使用shell写成，所以扩展名就编程 .sh；
2. \*Z、\*.tar、\*.tar.gz、、*.tgz：经过打包的压缩文件；
3. \*.html、\*.php：网页相关文件
</code></pre>
<h4 id="Linux文件名长度限制"><a href="#Linux文件名长度限制" class="headerlink" title="Linux文件名长度限制"></a>Linux文件名长度限制</h4><p>  <strong>单一文件或目录的最大容许文件名为255字节，以一个ACII英文占用一个字节来说，则大约可达255个字符长度。若是以每个汉字占用2个字节来说，最大文件名就是大约在128个汉字之间。</strong></p>
<h4 id="Linux文件名的限制"><a href="#Linux文件名的限制" class="headerlink" title="Linux文件名的限制"></a>Linux文件名的限制</h4><p>  文件名要避免一些特殊字符比较好，比如：<code>* ? &gt; &lt; ; &amp; ! [ ] | \ &#39; &quot; ( ) &#123; &#125; - + </code></p>
<h2 id="1-3-Linux目录配置"><a href="#1-3-Linux目录配置" class="headerlink" title="1.3 Linux目录配置"></a>1.3 Linux目录配置</h2><h3 id="1-3-1-Linux目录配置的依据——FHS"><a href="#1-3-1-Linux目录配置的依据——FHS" class="headerlink" title="1.3.1 Linux目录配置的依据——FHS"></a>1.3.1 Linux目录配置的依据——FHS</h3><p>  FHS（Filesystem Hierarchy Standard）：让用户可以了解到已安装软件通常放置于哪个目录下。</p>
<p>  FHS依据文件系统使用的频繁与否与是否允许用户随意修改，将目录定义成为四种交互作用的形态：</p>
<table>
<thead>
<tr>
<th></th>
<th align="left">可分享（shareable）</th>
<th align="left">不可分享（unshareable）</th>
</tr>
</thead>
<tbody><tr>
<td>不变（static）</td>
<td align="left">/usr (软件存放处)</td>
<td align="left">/etc (配置文件)</td>
</tr>
<tr>
<td></td>
<td align="left">/opt (第三方辅助软件)</td>
<td align="left">/boot (启动与内核文件)</td>
</tr>
<tr>
<td>可变动（variable）</td>
<td align="left">/var/mail (用户邮箱)</td>
<td align="left">/var/run (程序相关)</td>
</tr>
<tr>
<td></td>
<td align="left">/var/spool/news (新闻组)</td>
<td align="left">/var/lock (程序相关)</td>
</tr>
</tbody></table>
<ul>
<li><strong>可分享</strong>：可以分享给其他系统挂载使用的目录，是能够分享给网络上其他主机挂载用的目录。</li>
<li><strong>不可分享</strong>：自己机器上面运行的设备文件或是与程序有关的socket文件等。</li>
<li><strong>不变</strong>：那些数据是不会经常变动的，跟随着发行版而不变动。例如函数库、文件说明、系统管理员所管理的主机服务配置文件等。</li>
<li><strong>可变动</strong>：经常修改的数据，例如日志文件、一般用户可自行接收的新闻组等。</li>
</ul>
<p>  FHS针对目录树架构仅定义出三层目录下面应该放置什么数据：</p>
<pre><code>1. /（root，根目录）：**与启动系统有关**；
2. /usr（unix software resource）：**与软件安装/执行有关**；
3. /var（variable）：**与系统运行过程有关**；
</code></pre>
<h4 id="根目录（-）的意义与内容"><a href="#根目录（-）的意义与内容" class="headerlink" title="根目录（/）的意义与内容"></a>根目录（/）的意义与内容</h4><p>  根目录是整个系统最重要的一个目录，所有的目录都是由根目录衍生出来，同时<strong>根目录也与启动、还原、系统修复等操作有关</strong>。</p>
<p>  FHS标准建议：<strong>根目录（/）所在分区应该越小越好，且应用程序所安装的软件最好不要与根目录放在同一个分区内，保持根目录越小越好。如此不但性能较佳，根目录所在的文件系统也较不容易发生问题</strong>。</p>
<p>  根目录（/）下文件目录的详情见<strong>P166页</strong></p>
<h4 id="usr的意义与内容"><a href="#usr的意义与内容" class="headerlink" title="/usr的意义与内容"></a>/usr的意义与内容</h4><p>  /usr里面放置的数据属于可分享与不可变动，**/usr是UNIX Software Resource的缩写，也就是UNIX操作系统软件资源放置的目录，而不是用户的数据，不是user的缩写**。</p>
<p>  /usr的子目录详情见<strong>P168页</strong>。</p>
<h4 id="var的意义与内容"><a href="#var的意义与内容" class="headerlink" title="/var的意义与内容"></a>/var的意义与内容</h4><p>  /var目录主要针对经常性变动的文件，包括缓存（Cache）、日志文件（log file）以及某些软件运行产生的文件，包括程序文件（lock file，run file），或例如MySQL数据库的文件等。</p>
<p>  /var的子目录详情见<strong>P169页</strong>。</p>
<h3 id="1-3-2-目录树"><a href="#1-3-2-目录树" class="headerlink" title="1.3.2 目录树"></a>1.3.2 目录树</h3><p>  主要的特性有：</p>
<ul>
<li><strong>目录树的启始点为根目录</strong></li>
<li><strong>每一个目录不止能使用本地分区的文件系统，也可以使用网络上的文件系统。例如利用Network File System（NFS）服务器挂载某特定目录等。</strong></li>
<li><strong>每一个文件在此目录树中的文件名（包含完整路径）都是独一无二的。</strong></li>
</ul>
<h3 id="1-3-3-绝对路径与相对路径"><a href="#1-3-3-绝对路径与相对路径" class="headerlink" title="1.3.3 绝对路径与相对路径"></a>1.3.3 绝对路径与相对路径</h3><p>  根据文件名写法的不同，也可以将所谓的路径定义为绝对路径与相对路径。</p>
<ul>
<li><strong>绝对路径</strong>：由根目录（/）开始写起的文件名或目录名称。</li>
<li><strong>相对路径</strong>：相对于目前路径的文件名写法，反正开头不是 / 就属于相对路径的写法。</li>
<li><strong>. ：代表当前的目录，也可以使用 ./ 表示；</strong></li>
<li><strong>.. ：代表上一层目录，也可以 ../ 来代表</strong></li>
</ul>
<h1 id="二、Linux文件与目录管理"><a href="#二、Linux文件与目录管理" class="headerlink" title="二、Linux文件与目录管理"></a>二、Linux文件与目录管理</h1><h2 id="2-1-目录与路径"><a href="#2-1-目录与路径" class="headerlink" title="2.1 目录与路径"></a>2.1 目录与路径</h2><h3 id="2-1-1-目录的相关操作"><a href="#2-1-1-目录的相关操作" class="headerlink" title="2.1.1 目录的相关操作"></a>2.1.1 目录的相关操作</h3><p>  比较特殊的目录：</p>
<blockquote>
<p>.     代表此层目录   </p>
<p>..    代表上一层目录</p>
<p>-    代表前一个工作目录</p>
<p>~    代表目前使用者身份所在的家目录</p>
<p>~account    代表account这个使用者的家目录（account是个账号名称）</p>
</blockquote>
<p>  注意：<strong>在所有目录下面都会存在的两个目录，分别是“ . ”与“ .. ”</strong>分别代表此层与上层目录的意思。</p>
<p>  常见的处理目录的命令：</p>
<ul>
<li>cd（change directory）：<strong>切换目录</strong></li>
<li>pwd（print working directory）：<strong>显示当前目录</strong></li>
<li>mkdir（make directory）：<strong>建立一个新目录</strong></li>
<li>rmdir：<strong>删除一个空目录，被删除的目录里面必定不能存在其他的目录或文件</strong>，如果要将所有目录下的东西都删除，就必须使用【rm -r 目录】</li>
</ul>
<h3 id="2-1-2-关于执行文件路径的变量：-PATH"><a href="#2-1-2-关于执行文件路径的变量：-PATH" class="headerlink" title="2.1.2 关于执行文件路径的变量：$PATH"></a>2.1.2 关于执行文件路径的变量：$PATH</h3><p>Q：为什么可以在任何地方执行/bin/ls这个命令？</p>
<p>A：这是因为<strong>环境变量PATH的帮助所导致的</strong>。当执行一个命令时，系统会依照PATH的设置去每个PATH定义的目录下查找文件名为命令名的可执行文件，如果在PATH定义的目录中含有多个同名可执行文件，那么先查找到的同名命令先被执行。</p>
<p>【echo $PATH】查看哪些目录被定义出来了，显示的每个目录中间用冒号（ : ）来隔开，每个目录有顺序之分。</p>
<ol>
<li><strong>不同身份用户默认的PATH不同，默认能够随意执行的命令也不同（如root与xys）</strong></li>
<li><strong>PATH是可以修改的</strong></li>
<li><strong>使用绝对路径或相对路径直接指定某个命令的文件名来执行，会比查找PATH来的正确</strong></li>
<li><strong>命令应该要放置到正确的目录下，执行才会比较方便</strong></li>
<li><strong>本目录（ . )最好不要放到PATH中</strong></li>
</ol>
<h2 id="2-2-文件与目录管理"><a href="#2-2-文件与目录管理" class="headerlink" title="2.2 文件与目录管理"></a>2.2 文件与目录管理</h2><h3 id="2-2-1-文件与目录的查看：ls"><a href="#2-2-1-文件与目录的查看：ls" class="headerlink" title="2.2.1 文件与目录的查看：ls"></a>2.2.1 文件与目录的查看：ls</h3><p>默认显示的只有：<strong>非隐藏文件的文件名、以文件名进行排序及文件名代表的颜色显示</strong>如此而已</p>
<h3 id="2-2-2-复制、删除与移动：cp、rm、mv"><a href="#2-2-2-复制、删除与移动：cp、rm、mv" class="headerlink" title="2.2.2 复制、删除与移动：cp、rm、mv"></a>2.2.2 复制、删除与移动：cp、rm、mv</h3><ul>
<li><p>cp（复制文件或目录）</p>
<blockquote>
<p> 除了单纯的复制之外，还可以建立链接文件（快捷方式)。</p>
<p> 不同身份者执行这个命令会有不同的结果产生，尤其是那个-a、-p的选项</p>
<p> 在默认条件中，cp的源文件与目标文件的权限是不同的，目标文件的拥有者通常会是命令操作者本身。</p>
</blockquote>
</li>
<li><p>rm（删除文件或目录）</p>
<blockquote>
<p> <strong>通常在Linux系统下，为了怕文件被root删除，都默认加入了 -i 这个选项，不过，使用 rm -r 这个命令之前，千万要注意，因为该目录或文件肯定会被root删除</strong></p>
</blockquote>
</li>
<li><p>mv（移动文件与目录，或重命名）</p>
<blockquote>
<p>移动文件或目录，另一个用途就是<strong>修改文件名</strong>。不过在Linux中有个rename命令。</p>
</blockquote>
</li>
</ul>
<h2 id="2-3-文件内容查看"><a href="#2-3-文件内容查看" class="headerlink" title="2.3 文件内容查看"></a>2.3 文件内容查看</h2><ul>
<li><strong>cat由第一行开始显示文件内容</strong></li>
<li><strong>tac从最后一行开始显示，可以看出tac是cat的倒着写</strong></li>
<li><strong>nl显示的时候，同时输出行号</strong></li>
<li><strong>more一页一页地显示文件内容</strong></li>
<li><strong>less与more类似，但是比more更好的是，它可以往前翻页</strong></li>
<li><strong>head只看前面几行</strong></li>
<li><strong>tail只看后面几行</strong></li>
<li><strong>od以二进制的方式读取文件内容</strong></li>
</ul>
<h3 id="6-3-1-直接查看文件内容"><a href="#6-3-1-直接查看文件内容" class="headerlink" title="6.3.1 直接查看文件内容"></a>6.3.1 直接查看文件内容</h3><p>  直接查看一个文件的内容可以使用cat/tac/nl这几个命令</p>
<pre><code>1. cat（concatenate）：将一个文件的内容连续打印在屏幕上面。
2. tac（反向列表示）
3. nl（添加行号打印）
</code></pre>
<h3 id="2-3-2-可翻页查看"><a href="#2-3-2-可翻页查看" class="headerlink" title="2.3.2 可翻页查看"></a>2.3.2 可翻页查看</h3><ol>
<li><p>more（一页一页翻动）</p>
<p>如果more后面接的文件内容行数大于屏幕输出的行数时，最后一行会显示出目前显示的百分比，而且还可以在最后一行输入一些有用的命令。</p>
<ul>
<li><strong>空格键（space）：代表向下翻一页</strong>；</li>
<li><strong>Enter：代表向下翻一行</strong>；</li>
<li><strong>/字符串：代表在这个显示的内容当中，向下查找字符串这个关键词</strong>；</li>
<li><strong>:f：立刻显示出文件名以及目前显示的行数</strong>；</li>
<li><strong>q：代表立刻离开more，不再显示该文件内容</strong>；</li>
<li><strong>b或 [ctrl]-b：代表往回翻页，不过这操作只对文件有用，对管道无用</strong>。</li>
</ul>
</li>
<li><p>less（一页一页翻动）</p>
<p>more不能向前翻页，而less可以通过按键来实现，可以输入的命令有：</p>
<ul>
<li><strong>空格键：向下翻动一页</strong></li>
<li><strong>pagedown：向下翻动一页</strong></li>
<li><strong>pageup：向上翻动一页</strong></li>
<li><strong>/字符串：向下查找字符串的功能</strong></li>
<li><strong>?字符串：向上查找字符串的功能</strong></li>
<li><strong>n：重复前一个查找（与/或?有关）</strong></li>
<li><strong>N：反向的重复前一个查找（与/或?有关）</strong></li>
<li><strong>g：前进到这一个数据的第一行</strong></li>
<li><strong>G：前进到这个数据的最后一行（注意大小写）</strong></li>
<li><strong>q：离开less这个程序</strong></li>
</ul>
</li>
</ol>
<h3 id="2-3-3-数据截取"><a href="#2-3-3-数据截取" class="headerlink" title="2.3.3 数据截取"></a>2.3.3 数据截取</h3><ol>
<li><p>head（取出前面几行）</p>
<p>若没有加上 -n 这个选项时，默认只显示十行，若只要一行？那就加入<code>head -n 1 filename</code>即可。</p>
<p>如果 -n 接的是负数，例如 <code>-n -100</code>时，代表列出前面所有的行数，但不包括后面100行。</p>
</li>
<li><p>tail（取出后面几行）</p>
<p>用法跟 head 的用法类似，只是显示的是后面几行。默认也是显示十行，若要显示非十行，就要加 -n number的选项即可。</p>
<p>当执行<code>tail -n +100 filename</code>时，代表该文件从100行以后都会被列出来</p>
</li>
</ol>
<h3 id="2-3-4-非纯文本文件：od"><a href="#2-3-4-非纯文本文件：od" class="headerlink" title="2.3.4 非纯文本文件：od"></a>2.3.4 非纯文本文件：od</h3><p>可以将数据文件（data file）或是二进制（binary file）的内容数据读出来。读出来的数值默认是使用非文本文件，亦即是十六进制的数值来显示，不过，可以通过-t c的选项与参数来将数据内的字符以ASCII类型的字符显示。</p>
<h3 id="2-3-5-修改文件时间或创建新文件：touch"><a href="#2-3-5-修改文件时间或创建新文件：touch" class="headerlink" title="2.3.5 修改文件时间或创建新文件：touch"></a>2.3.5 修改文件时间或创建新文件：touch</h3><p>每个文件有三个主要的变动时间：</p>
<ul>
<li><p><strong>修改时间</strong>（modification time，mtime）：</p>
<p>当该文件的【内容数据】变更时，就会更新这个时间，内容数据指的是文件的内容，而不是文件的属性或权限。</p>
</li>
<li><p><strong>状态时间</strong>（status time，ctime）：</p>
<p>当该文件的【状态 】改变时，就会更新这个时间，举例来说，像是权限与属性被更改了，都会更新这个时间。</p>
</li>
<li><p><strong>读取时间</strong>（access time，atime）：</p>
<p>当【该文件的内容被读取】时，就会更新这个读取时间（access），举例来说，我们使用 cat 去读取一个文件，就会更新该文件的atime。</p>
</li>
</ul>
<p>这个命令最常被使用的情况是：</p>
<ul>
<li><strong>建立一个空文件</strong></li>
<li><strong>将某个文件日期自定义为目前</strong>（mtime与atime）</li>
</ul>
<h2 id="2-4-文件与目录的默认权限与隐藏权限"><a href="#2-4-文件与目录的默认权限与隐藏权限" class="headerlink" title="2.4 文件与目录的默认权限与隐藏权限"></a>2.4 文件与目录的默认权限与隐藏权限</h2><h3 id="2-4-1-文件默认权限：umask"><a href="#2-4-1-文件默认权限：umask" class="headerlink" title="2.4.1 文件默认权限：umask"></a>2.4.1 文件默认权限：umask</h3><p>umask是指定<strong>目前用户在建立文件或目录时候的权限默认值</strong>。</p>
<p>查看的方式有两种，一种可以直接输入umask，就可以看到数字类型的权限设置值，一种则是加入-S（Symbolic）这个选项，就会以符号类型的方式来显示出权限了。第一种显示数字：第一组是特殊权限用的，后面三组就是常用的。默认情况如下：</p>
<ul>
<li>若用户建立为文件则默认没有可执行（x）权限，即只有 rw 这两个权限，也就是最大为666。</li>
<li>若用户建立为目录，则由于 x 与是否可以进入此目录有关，因此默认为所有权限均开放，即777</li>
</ul>
<p>umask的数字指的是<strong>该默认值需要减掉的权限</strong>。那么当用户：</p>
<ul>
<li>建立文件时：（-rw-rw-rw-) - (—–w–w-) ==&gt; -rw-r–r–</li>
<li>建立目录是：（drwxrwxrwx) - (d—-w–w-) ==&gt; drwxr-xr-x  </li>
</ul>
<h3 id="2-4-2-文件隐藏属性"><a href="#2-4-2-文件隐藏属性" class="headerlink" title="2.4.2 文件隐藏属性"></a>2.4.2 文件隐藏属性</h3><ul>
<li><p>chattr（配置文件隐藏属性）</p>
<p>chattr命令只能在ext2、ext3、ext4的Linux传统文件按系统上面完整生效，其他文件系统可能无法完整的支持这个命令。这个命令对于系统的数据安全上面很重要。由于这些属性是隐藏的性质，所有需要以 lsattr 才能看到该属性。</p>
</li>
<li><p>lsattr（显示文件隐藏属性）</p>
</li>
</ul>
<h3 id="2-4-3-文件特殊权限：SUID、SGID、SBIT"><a href="#2-4-3-文件特殊权限：SUID、SGID、SBIT" class="headerlink" title="2.4.3 文件特殊权限：SUID、SGID、SBIT"></a>2.4.3 文件特殊权限：SUID、SGID、SBIT</h3><ol>
<li><p>Set UID</p>
<p>当 s 这个标志出现在文件拥有者的 x 权限上时，此时就被称为 Set UID ，简称SUID的特殊权限，基本上SUID有这样的限制与功能：</p>
<ul>
<li><strong>SUID权限仅对二进制程序有效</strong></li>
<li><strong>执行者对于该程序需要具有 x 的可执行权限</strong></li>
<li><strong>本权限仅在执行该程序的过程中有效</strong></li>
<li><strong>执行者将具有该程序拥有者（owner）的权限</strong></li>
</ul>
<p>SUID仅可用在二进制程序上，不能够用在shell脚本上。因为shell脚本只是将很多的二进制文件调用执行而已。</p>
</li>
<li><p>Set GID</p>
<p>当 s 出现在用户组的 x 时则称为 Set GID（SGID），SGID可以针对文件或目录来设置。如果是对文件来说，SGID有如下的功能：</p>
<ul>
<li><strong>SGID对二进制程序有用</strong>；</li>
<li><strong>程序执行者对于该程序来说，需要具备 x 的权限</strong></li>
<li><strong>执行者在执行的过程中将会获得该程序用户组的支持</strong></li>
</ul>
<p>当一个目录设置了SGID的权限后，它将具有如下的功能：</p>
<ul>
<li><strong>用户若对于此目录具有 r 和 x 的权限时，该用户能够进入此目录</strong></li>
<li><strong>用户在此目录下的有效用户组（effective group）将会变成该目录的用户组</strong></li>
<li><strong>用途：若用户在此目录下具有 w 的权限（可以新建文件），则用户所建立的新文件，该新文件的用户组与此目录的用户组相同</strong>。</li>
</ul>
</li>
<li><p>Sticky Bit</p>
<p>权限标志为 t 出现在 x 权限上，这个目前只针对目录有效，对于文件已经没有效果了。SBIT对于目录的作用是：</p>
<ul>
<li><p><strong>当用户对于此目录具有 w、x 权限，即具有写入的权限</strong></p>
</li>
<li><p><strong>当用户在该目录下建立文件或目录时，仅有自己与root才有权力删除该文件</strong></p>
<p>就是说：当甲用户对于A目录具有用户组或其他人的身份，且拥有该目录 w 的权限，这表示甲用户对该目录内任何人建立的目录或文件均可删除、更名、移动等操作。但将A目录加上SBIT得到权限时，则甲只能够针对自己建立的文件或目录删除、更名、移动等操作，而无法删除他人的文件。</p>
</li>
</ul>
</li>
<li><p>SUID/SGID/SBIT权限设置</p>
<p>用数字表示：普通权限的数字表示的方式为【三个数字】的组合，如果在这三个数字之前再加上一个数字的话，最前面的那个数字就代表这几个权限了。</p>
<ul>
<li>4为SUID</li>
<li>2为SGID</li>
<li>1为SBIT</li>
</ul>
<p>假设要将一个文件权限改为【-rwsr-xr-x】时，由于 s 在用户权限中，所以时SUID，因此，在原先的755之前还要加上4，也就是【chmod 4755 filename】来设置。<strong>此外还有大 S 和大 T 的产生，s和t都是取代 x 这个权限，实际原文件都具有 x 权限，而 S 与 T 代表的就是空的，没有 x 这个执行权限</strong></p>
</li>
</ol>
<h3 id="6-4-4-观察文件类型：file"><a href="#6-4-4-观察文件类型：file" class="headerlink" title="6.4.4 观察文件类型：file"></a>6.4.4 观察文件类型：file</h3><p>【file】这个命令可以简单地先判断这个文件的格式是什么。比如文件的压缩方式、是属于ASCII或是数据文件等。</p>
<h2 id="2-5-命令与文件的查找"><a href="#2-5-命令与文件的查找" class="headerlink" title="2.5 命令与文件的查找"></a>2.5 命令与文件的查找</h2><h3 id="2-5-1-脚本文件的查找"><a href="#2-5-1-脚本文件的查找" class="headerlink" title="2.5.1 脚本文件的查找"></a>2.5.1 脚本文件的查找</h3><ol>
<li><p>which / type（查找【执行文件】）</p>
<p>这个命令是根据【PATH】这个环境变量所规范的路径，去查找执行文件的文件名，所以，重点是找出执行文件而已，且which后面接的是完整的文件名。</p>
</li>
</ol>
<h3 id="2-5-2-文件的查找"><a href="#2-5-2-文件的查找" class="headerlink" title="2.5.2 文件的查找"></a>2.5.2 文件的查找</h3><p>通过 find 不常用。除速度慢之外，也影响磁盘性能。一般都是先使用 whereis 或是 locate 来检查，如果真找不到了，才用 find 来查找。</p>
<p>whereis只找系统中某些特定目录下面的文件而已，locate则是利用数据库来查找文件名，两者就相当的速度，并且没有实际查找硬盘内的文件系统状态，比较省时间。</p>
<ol>
<li><p>whereis （由一些特定的目录中查找文件）</p>
<p>whereis可以加入选项来查找相关的数据，例如，如果你要找可执行文件（binary），那么加上 -b 就可以。不加任何选项，就将所有的数据显示出来。whereis主要针对 /bin/sbin下面的执行文件，以及 /usr/share/man 下面的 man page文件，跟几个比较特定的目录来处理而已。</p>
</li>
<li><p>locate / updatedb</p>
<p>这个locate的使用直接在后面输入文件的部分名称后，就能得到结果。查找文件时经由数据库来查找，而数据库的建立默认时在每天执行一次（每个Linux发行版都不同，CentOS 7.x是每天更新数据库一次），当新建的文件还未更新数据库时，就可以手动更新，直接输入【updatedb】就可以。</p>
<ul>
<li><strong>updatedb：根据 /etc/updatedb.conf 的设置去查找系统硬盘内的文件，并更新 /var/lib/mlocate 内的数据库文件；因为updatedb会去查找硬盘，所以执行时可能要等待数分钟</strong></li>
<li><strong>locate：依据 /var/lib/mlocate内的数据库记录，找出用户所输入关键词的文件名。</strong></li>
</ul>
</li>
<li><p>find</p>
<p>find的选项与参数参考P204页。</p>
<p>find的特殊功能就是能够进行额外的操作（action），比如：</p>
<ul>
<li>{} 代表的是由find找到的内容，如上图所示，find的结果会放置到 {} 位置中</li>
<li>-exec一直到 \；是关键词，代表 find 额外操作的开始（-exec）到结束（;），在这中间的就是 find 命令内的额外操作。在本例中就是【ls -l {}】</li>
<li>因为【 ; 】在bash环境下是有特殊意义的，因此利用反斜杠来转义</li>
</ul>
<p>如果要找的文件是具有特殊属性的，例如SUID、文件的拥有者、文件大小等，locate没有办法完成查找，就需要find，find 还可以利用通配符来查找文件名。</p>
</li>
</ol>
<h1 id="三、Linux磁盘与文件系统管理"><a href="#三、Linux磁盘与文件系统管理" class="headerlink" title="三、Linux磁盘与文件系统管理"></a>三、Linux磁盘与文件系统管理</h1><h2 id="3-1-认识Linux文件系统"><a href="#3-1-认识Linux文件系统" class="headerlink" title="3.1 认识Linux文件系统"></a>3.1 认识Linux文件系统</h2><h3 id="3-1-1-文件系统特性"><a href="#3-1-1-文件系统特性" class="headerlink" title="3.1.1 文件系统特性"></a>3.1.1 文件系统特性</h3><ol>
<li><p>磁盘分区格式化的意义：因为每个操作系统所设置的文件属性/权限并不相同，为了存放这些文件所需的数据，因此就需要将分区进行格式化，已成为操作系统能够利用的文件系统格式。</p>
</li>
<li><p>Linux的正版文件系统为 ext2（Linux second Extended file system，ext2fs）。此外，在默认的情况下，Windows操作系统不支持Linux的 ext2 文件系统。</p>
</li>
<li><p>一个可被挂载的数据为一个文件系统而不是一个分区</p>
</li>
<li><p>文件系统通常会将权限与属性放置到 inode 中，实际数据则放置到数据区块中，这两部份的数据分别存放在不同的区块。另外，还有一个超级区块会记录整个文件系统的整体信息，包括 inode 与数据区块的总量、使用量、剩余量等。</p>
<ol>
<li><p><strong>超级区块：记录此文件系统的整体信息，包括 inode 与数据区块的总量、使用量、剩余量，以及文件系统的格式与相关信息等</strong>；</p>
</li>
<li><p><strong>inode：记录文件的属性，一个文件占用一个 inode，同时记录此文件的数据所在的区块号码</strong></p>
</li>
<li><p><strong>数据区块：实际记录文件的内容，若文件太大是，会占用多个区块。</strong></p>
</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ的安装与启动</title>
    <url>/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/</url>
    <content><![CDATA[<h2 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h2><h3 id="1-1-消息-Message"><a href="#1-1-消息-Message" class="headerlink" title="1.1 消息(Message)"></a>1.1 消息(Message)</h3><p><strong>消息</strong>是指，消息系统所传输信息的物理载体，生产和消费数据的最小单位，<em>每条消息必须属于一个主题</em>。</p>
<span id="more"></span>

<h3 id="1-2-主题-Topic"><a href="#1-2-主题-Topic" class="headerlink" title="1.2 主题(Topic)"></a>1.2 主题(Topic)</h3><img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/topic.png" class="">

<p><code>Topic表示一类消息的集合</code>，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。 topic:message 1:n   message:topic 1:1</p>
<p>一个生产者可以同时发送多种Topic的消息；而一个消费者只对某种特定的Topic感兴趣，即只可以订阅和消费一种Topic的消息。 producer:topic 1:n   topic:consumer 1:1</p>
<blockquote>
<p>topic和consumer是一对一的原因是：</p>
<p>在 <code>subscribeTable</code> 和 <code>subscriptionInner</code> 方法中，是使用 Map 集合的方式存储topic订阅者，存储格式大概为{group: topic}, Map 的特性就是 Key 不能重复，所以相同的 Key 会直接替换，即后者注册的消费者会顶替之前注册的消费者，但可以创建1多个消费组，同时订阅一个topic。</p>
</blockquote>
<h3 id="1-3-标签-Tag"><a href="#1-3-标签-Tag" class="headerlink" title="1.3 标签(Tag)"></a>1.3 标签(Tag)</h3><p>为消息设置的标签，用于同一主题下区分不同类型的消息。来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同标签。标签能够有效地保持代码的清晰度和连贯性，并优化RocketMQ提供的查询系统。消费者可以根据Tag实现对不同子主题的不同消费逻辑，实现更好的扩展性。</p>
<p>Topic是消息的一级分类，Tag是消息的二级分类。</p>
<blockquote>
<p>Topic：货物</p>
<p>tag=上海</p>
<p>tag=江苏</p>
<p>tag=浙江</p>
<p>——- 消费者 —–</p>
<p>topic=货物 tag = 上海</p>
<p>topic=货物 tag = 上海|浙江</p>
<p>topic=货物 tag = *</p>
</blockquote>
<h3 id="1-4-队列-Queue"><a href="#1-4-队列-Queue" class="headerlink" title="1.4 队列(Queue)"></a>1.4 队列(Queue)</h3><p>存储消息的物理实体。一个Topic中可以包含多个Queue，每个Queue中存放的就是该Topic的消息。一个Topic的Queue也被称为一个Topic中消息的分区（Partition）。</p>
<p><strong>分区=queue</strong>，一个Topic的Queue中的消息只能被一个消费者组中的一个消费者消费。一个Queue中的消息不允许同一个消费者组中的多个消费者同时消费。</p>
<img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/queue.png" class="">

<p>在学习参考其它相关资料时，还会看到一个概念：<code>分片</code>（Sharding）。分片不同于分区。在RocketMQ中，分片指的是存放相应Topic的Broker。每个分片中会创建出相应数量的分区，即Queue，每个Queue的大小都相同的。</p>
<img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/sharding.png" class="">

<h3 id="1-5-消息标识-MessageId-Key"><a href="#1-5-消息标识-MessageId-Key" class="headerlink" title="1.5 消息标识(MessageId/Key)"></a>1.5 消息标识(MessageId/Key)</h3><p>RocketMQ中每个消息拥有唯一的MessageId(<code>有可能重复</code>)，且可以携带具有业务标识的Key，以方便对消息的查询。不过需要注意的是，MessageId有两个：在生产者send()消息时会自动生成一个MessageId（msgId)，当消息到达Broker后，Broker也会自动生成一个MessageId(offsetMsgId)。<strong>msgId、offsetMsgId与key都称为消息标识。</strong></p>
<ul>
<li><p>msgId：由producer端生成，其生成规则为：</p>
<blockquote>
<p>producerIp + 进程pid + MessageClientIDSetter类的ClassLoader的hashCode +当前时间 + AutomicInteger自增计数器</p>
</blockquote>
</li>
<li><p>offsetMsgId：由broker端生成，其生成规则为：</p>
<blockquote>
<p>brokerIp + 物理分区的offset（Queue中的偏移量）</p>
</blockquote>
</li>
<li><p>key：由用户指定的业务相关的唯一标识</p>
</li>
</ul>
<h2 id="二、系统架构"><a href="#二、系统架构" class="headerlink" title="二、系统架构"></a>二、系统架构</h2><img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/construct.png" class="">

<p><strong>RocketMQ架构上主要分为四部分构成</strong>：</p>
<h3 id="2-1-Producer"><a href="#2-1-Producer" class="headerlink" title="2.1 Producer"></a>2.1 Producer</h3><p>消息生产者，负责生产消息。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。</p>
<blockquote>
<p>例如，业务系统产生的日志写入到MQ的过程，就是消息生产的过程<br>再如，电商平台中用户提交的秒杀请求写入到MQ的过程，就是消息生产的过程</p>
</blockquote>
<p>RocketMQ中的消息生产者都是<code>以生产者组（Producer Group）的形式</code>出现的。生产者组是同一类生产者的集合，这类Producer发送相同Topic类型的消息。<em>一个生产者组可以同时发送<code>多个主题</code>的消息</em>。</p>
<h3 id="2-2-Consumer"><a href="#2-2-Consumer" class="headerlink" title="2.2 Consumer"></a>2.2 Consumer</h3><p>消息消费者，负责消费消息。一个消息消费者会从Broker服务器中获取到消息，并对消息进行相关业务处理。</p>
<blockquote>
<p>例如，QoS系统从MQ中读取日志，并对日志进行解析处理的过程就是消息消费的过程。<br>再如，电商平台的业务系统从MQ中读取到秒杀请求，并对请求进行处理的过程就是消息消费的过程。</p>
</blockquote>
<p>RocketMQ中的消息消费者都是以消费者组（Consumer Group）的形式出现的。消费者组是同一类消费者的集合，这类Consumer消费的是同一个Topic类型的消息。消费者组使得在消息消费方面，实现<strong>负载均衡</strong>（将一个Topic中的不同的Queue平均分配给同一个Consumer Group的不同的Consumer，注意，他是对queue的负载均衡，不是将消息负载均衡）和<strong>容错</strong>（一个Consmer挂了，该Consumer Group中的其它Consumer可以接着消费原Consumer消费的Queue）的目标变得非常容易。</p>
<img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/consumer.png" class="">

<p><code>一个消费者可以消费多个queue，一个queue只能被一个消费者消费</code></p>
<p>消费者组中Consumer的数量应该小于等于订阅Topic的Queue数量。如果超出Queue数量，则多出的Consumer将不能消费消息。</p>
<img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/consumer1.png" class="">

<p><em>不过，一个Topic类型的消息可以被多个消费者组同时消费。</em></p>
<blockquote>
<p>注意:</p>
<p>1）消费者组只能消费一个Topic的消息，不能同时消费多个Topic消息<br>2）一个消费者组中的消费者必须订阅完全相同的Topic</p>
</blockquote>
<h3 id="2-3-Name-Server"><a href="#2-3-Name-Server" class="headerlink" title="2.3 Name Server"></a>2.3 Name Server</h3><h4 id="2-3-1-功能介绍"><a href="#2-3-1-功能介绍" class="headerlink" title="2.3.1 功能介绍"></a>2.3.1 功能介绍</h4><p>NameServer是一个Broker与Topic路由的注册中心，支持Broker的动态注册与发现。</p>
<blockquote>
<p>RocketMQ的思想来自于Kafka，而Kafka是依赖了Zookeeper的。所以，在RocketMQ的早期版本，即在MetaQ v1.0与v2.0版本中，也是依赖于Zookeeper的。从MetaQ v3.0，即RocketMQ开始去掉了Zookeeper依赖，使用了自己的NameServer。</p>
</blockquote>
<p>主要包括两个功能：</p>
<ul>
<li><p><strong>Broker管理：</strong></p>
<p>接受Broker集群的注册信息并且保存下来作为路由信息的基本数据；提供心跳检测机制，检查Broker是否还存活。</p>
</li>
<li><p><strong>路由信息管理：</strong></p>
<p>每个NameServer中都保存着Broker集群的整个路由信息和用于客户端查询的队列信息。Producer和Conumser通过NameServer可以获取整个Broker集群的路由信息，从而进行消息的投递和消费。</p>
</li>
</ul>
<h4 id="2-3-2-路由注册"><a href="#2-3-2-路由注册" class="headerlink" title="2.3.2 路由注册"></a>2.3.2 路由注册</h4><p>NameServer通常也是以集群的方式部署，不过，NameServer是无状态的，即NameServer集群中的各个节点间是无差异的，各节点间相互不进行信息通讯。那各节点中的数据是如何进行数据同步的呢？在Broker节点启动时，轮询NameServer列表，与每个NameServer节点建立长连接，发起注册请求。在NameServer内部维护着⼀个Broker列表，用来动态存储Broker的信息。<strong>NameServer集群之间没有数据通讯。</strong></p>
<blockquote>
<p>注意，这是与其它像zk、Eureka、Nacos等注册中心不同的地方。</p>
<p>这种NameServer的无状态方式，有什么优缺点：</p>
<p>优点：NameServer集群搭建简单，扩容简单。</p>
<p>缺点：对于Broker，必须明确指出所有NameServer地址。否则未指出的将不会去注册。也正因为如此，NameServer并不能随便扩容。因为，若Broker不重新配置，新增的NameServer对于Broker来说是不可见的，其不会向这个NameServer进行注册。</p>
</blockquote>
<p>Broker节点为了证明自己是活着的，为了维护与NameServer间的长连接，会将最新的信息以心跳包的方式上报给NameServer，每30秒发送一次心跳。心跳包中包含 BrokerId、Broker地址(IP+Port)、Broker名称、Broker所属集群名称等等 。NameServer在接收到心跳包后，会更新心跳时间戳，记录这个Broker的最新存活时间。</p>
<h4 id="2-3-3-路由剔除"><a href="#2-3-3-路由剔除" class="headerlink" title="2.3.3 路由剔除"></a>2.3.3 路由剔除</h4><p>由于Broker关机、宕机或网络抖动等原因，NameServer没有收到Broker的心跳，NameServer可能会将其从Broker列表中剔除。NameServer中有⼀个定时任务，每隔10秒就会扫描⼀次Broker表，查看每一个Broker的最新心跳时间戳距离当前时间是否超过120秒，如果超过，则会判定Broker失效，然后将其从Broker列表中剔除。</p>
<blockquote>
<p>扩展：<br>对于RocketMQ日常运维工作，例如Broker升级，需要停掉Broker的工作。OP需要怎么做？</p>
<p>OP需要将Broker的读写权限禁掉。一旦client(Consumer或Producer)向broker发送请求，都会收到broker的NO_PERMISSION响应，然后client会进行对其它Broker的重试。当OP观察到这个Broker没有流量后，再关闭它，实现Broker从NameServer的移除。</p>
<p>OP：运维工程师<br>SRE: Site Reliability Engineer，现场可靠性工程师</p>
</blockquote>
<h4 id="2-3-4-路由发现"><a href="#2-3-4-路由发现" class="headerlink" title="2.3.4 路由发现"></a>2.3.4 路由发现</h4><p><code>RocketMQ的路由发现采用的是Pull模型</code>。当Topic路由信息出现变化时，NameServer不会主动推送给客户端，而是客户端定时拉取主题最新的路由。默认客户端每30秒会拉取一次最新的路由。</p>
<blockquote>
<p>扩展：<br>1）Push模型：<br>推送模型。其实时性较好，是一个“发布-订阅”模型，需要维护一个长连接。而长连接的维护是需要资源成本。该模型适合于的场景：实时性要求较高Client数量不多，Server数据变化较频繁<br>2）Pull模型：<br>拉取模型。存在的问题是，实时性较差。<br>3）Long Polling模型：<br>长轮询模型。其是对Push与Pull模型的整合，充分利用了这两种模型的优势，屏蔽了它们的劣势。（客户端请求服务端消息，如果没有，保存30s的长连接，期间有消息就返回；30s后就关闭长连接，不断重复该过程）</p>
</blockquote>
<h4 id="2-3-5-客户端NameServer选择策略"><a href="#2-3-5-客户端NameServer选择策略" class="headerlink" title="2.3.5 客户端NameServer选择策略"></a>2.3.5 客户端NameServer选择策略</h4><blockquote>
<p><em>这里的客户端指的是Producer与Consumer</em></p>
</blockquote>
<p>客户端在配置时必须要写上NameServer集群的地址，那么客户端到底连接的是哪个NameServer节点呢？</p>
<p>客户端首先会生产一个随机数，然后再与NameServer节点数量取模，此时得到的就是所要连接的节点索引，然后就会进行连接。如果连接失败，则会采用round-robin策略，逐个尝试着去连接其它节点。首先采用的是<code>随机策略</code>进行的选择，失败后采用的是<code>轮询策略</code>。</p>
<blockquote>
<p>扩展：Zookeeper Client是如何选择Zookeeper Server的？</p>
<p>简单来说就是，经过两次shuffle（打散zkserver列表），然后选择第一台Zookeeper Server。</p>
<p>详细说就是，将配置文件中的zk server地址进行第一次shuffle，然后随机选择一个。这个选择出的一般都是一个hostname。然后获取到该hostname对应的所有ip，再对这些ip进行第二次shuffle，从shuffle过的结果中取第一个server地址进行连接。</p>
</blockquote>
<h3 id="2-4-Broker"><a href="#2-4-Broker" class="headerlink" title="2.4 Broker"></a>2.4 Broker</h3><h4 id="2-4-1-功能介绍"><a href="#2-4-1-功能介绍" class="headerlink" title="2.4.1 功能介绍"></a>2.4.1 功能介绍</h4><p>Broker充当着 <em>消息中转角色，负责存储消息、转发消息</em>。Broker在RocketMQ系统中负责接收并存储从生产者发送来的消息，同时为消费者的拉取请求作准备。Broker同时也存储着消息相关的元数据，包括消费者组消费进度偏移offset、主题、队列等。</p>
<blockquote>
<p>Kafka 0.8版本之后，offset是存放在Broker中的，之前版本是存放在Zookeeper中的。</p>
</blockquote>
<h4 id="2-4-2-模块构成"><a href="#2-4-2-模块构成" class="headerlink" title="2.4.2 模块构成"></a>2.4.2 模块构成</h4><img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/broker.png" class="" title="Broker功能模块示意图">

<ul>
<li><p><strong>Remoting Module</strong>：整个Broker的实体，负责处理来自clients端的请求。而这个Broker实体则由以下模块构成。</p>
</li>
<li><p><strong>Client Manager</strong>：客户端管理器。负责接收、解析客户端(Producer/Consumer)请求，管理客户端。例如，维护Consumer的Topic订阅信息</p>
</li>
<li><p><strong>Store Service</strong>：存储服务。提供方便简单的API接口，处理消息存储到物理硬盘和消息查询功能。</p>
</li>
<li><p><strong>HA Service</strong>：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。</p>
</li>
<li><p><strong>Index Service</strong>：索引服务。根据特定的Message key，对投递到Broker的消息进行索引服务，同时也提供根据Message Key对消息进行快速查询的功能。</p>
</li>
</ul>
<h4 id="2-4-3-集群部署"><a href="#2-4-3-集群部署" class="headerlink" title="2.4.3 集群部署"></a>2.4.3 集群部署</h4><img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/construct.png" class="">

<p>为了增强Broker性能与吞吐量，Broker一般都是以集群形式出现的。各集群节点中可能存放着相同Topic的不同Queue。不过，这里有个问题，如果某Broker节点宕机，如何保证数据不丢失呢？其解决方案是，将每个Broker集群节点进行横向扩展，即将Broker节点再建为一个HA集群，解决单点问题。</p>
<p>Broker节点集群是一个主从集群，即集群中具有Master与Slave两种角色。Master负责处理读写操作请求，Slave负责对Master中的数据进行备份(平常操作都是操作Master)。当Master挂掉了，Slave则会自动切换为Master去工作。所以这个Broker集群是主备集群。一个Master可以包含多个Slave，但一个Slave只能隶属于一个Master。Master与Slave 的对应关系是通过指定相同的BrokerName、不同的BrokerId 来确定的。BrokerId为0表示Master，非0表示Slave。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。</p>
<h3 id="2-5-工作流程"><a href="#2-5-工作流程" class="headerlink" title="2.5 工作流程"></a>2.5 工作流程</h3><h4 id="2-5-1-具体流程"><a href="#2-5-1-具体流程" class="headerlink" title="2.5.1 具体流程"></a>2.5.1 具体流程</h4><ol>
<li>启动NameServer，NameServer启动后开始监听端口，等待Broker、Producer、Consumer连接。</li>
<li>启动Broker时，Broker会与所有的NameServer建立并保持长连接，然后每30秒向NameServer定时发送心跳包。(注册)</li>
<li>发送消息前，可以先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，当然，在创建Topic时也会将Topic与Broker的关系写入到NameServer中。不过，这步是可选的，也可以在发送消息时自动创建Topic。</li>
<li>Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取路由信息，即当前发送的Topic消息的Queue与Broker的地址（IP+Port）的映射关系。然后根据算法策略从队选择一个Queue，与队列所在的Broker建立长连接从而向Broker发消息。当然，在获取到路由信息后，Producer会首先将路由信息缓存到本地，再每30秒从NameServer更新一次路由信息。</li>
<li>Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取其所订阅Topic的路由信息，然后根据算法策略从路由信息中获取到其所要消费的Queue，然后直接跟Broker建立长连接，开始消费其中的消息。Consumer在获取到路由信息后，同样也会每30秒从NameServer更新一次路由信息。不过不同于Producer的是，Consumer还会向Broker发送心跳，以确保Broker的存活状态。</li>
</ol>
<h4 id="2-5-2-Topic的创建模式"><a href="#2-5-2-Topic的创建模式" class="headerlink" title="2.5.2 Topic的创建模式"></a>2.5.2 Topic的创建模式</h4><p>手动创建Topic时，有两种模式：</p>
<ul>
<li><code>集群模式</code>：该模式下创建的Topic在该集群中，所有Broker中的Queue数量是相同的。<code>(全局定义)</code></li>
<li><code>Broker模式</code>：该模式下创建的Topic在该集群中，每个Broker中的Queue数量可以不同。</li>
</ul>
<p>自动创建Topic时，<code>默认采用的是Broker模式</code>，会为每个Broker默认创建4个Queue。</p>
<h4 id="2-5-3-读-写队列"><a href="#2-5-3-读-写队列" class="headerlink" title="2.5.3 读/写队列"></a>2.5.3 读/写队列</h4><p>从物理上来讲，读/写队列是同一个队列。所以，不存在读/写队列数据同步问题。读/写队列是逻辑上进行区分的概念。一般情况下，读/写队列数量是相同的。</p>
<p>例如，创建Topic时设置的写队列数量为8，读队列数量为4，此时系统会创建8个Queue，分别是0 1 2 3 4 5 6 7。Producer会将消息写入到这8个队列，但Consumer只会消费0 1 2 3这4个队列中的消息，4 5 6 7中的消息是不会被消费到的。</p>
<p>再如，创建Topic时设置的写队列数量为4，读队列数量为8，此时系统会创建8个Queue，分别是0 1 2 3 4 5 6 7。Producer会将消息写入到0 1 2 3 这4个队列，但Consumer只会消费0 1 2 3 4 5 6 7这8个队列中的消息，但是4 5 6 7中是没有消息的。此时假设Consumer Group中包含两个Consumer，Consumer1消费0 1 2 3，而Consumer2消费4 5 6 7。但实际情况是，Consumer2是没有消息可消费的。也就是说，当读/写队列数量设置不同时，总是有问题的。那么，为什么要这样设计呢？其这样设计的目的是为了，<code>方便Topic的Queue的缩容</code>。</p>
<p>例如，原来创建的Topic中包含16个Queue，如何能够使其Queue缩容为8个，还不会丢失消息？可以动态修改写队列数量为8，读队列数量不变。此时新的消息只能写入到前8个队列，而消费都消费的却是16个队列中的数据。当发现后8个Queue中的消息消费完毕后，就可以再将读队列数量动态设置为8。整个缩容过程，没有丢失任何消息。</p>
<p><em>缩容过程：先设置小写queue，16到8，那就只写入0-7；此时消费者消费之前的0-15，当后面8个的queue没有消息了，就关闭掉，再将读queue从16设置为8，就完成了缩容</em></p>
<p>perm用于设置对当前创建Topic的操作权限：2表示只写，4表示只读，6表示读写。</p>
<h2 id="三、单机安装与启动"><a href="#三、单机安装与启动" class="headerlink" title="三、单机安装与启动"></a>三、单机安装与启动</h2><h3 id="3-1-准备工作"><a href="#3-1-准备工作" class="headerlink" title="3.1 准备工作"></a>3.1 准备工作</h3><ul>
<li>软硬件需求</li>
</ul>
<p>​        <img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/prerequisite.png" class=""></p>
<ul>
<li><p>下载RocketMQ安装包</p>
</li>
</ul>
<h3 id="3-2-修改初始内存"><a href="#3-2-修改初始内存" class="headerlink" title="3.2 修改初始内存"></a>3.2 修改初始内存</h3>

<ol>
<li><p>修改runserver.sh</p>
<p>使用vim命令打开bin/runserver.sh文件，将这些值修改为如下：</p>
<img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/runserver.png" class=""></li>
<li><p>修改runbroker.sh</p>
<p>使用vim命令打开bin/runbroker.sh文件，将这些值修改为如下：</p>
<img src="/2021/11/16/RocketMQ%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%90%AF%E5%8A%A8/runserver.png" class=""></li>
</ol>
<h3 id="3-3-启动"><a href="#3-3-启动" class="headerlink" title="3.3 启动"></a>3.3 启动</h3><h4 id="3-3-1-启动NameServer"><a href="#3-3-1-启动NameServer" class="headerlink" title="3.3.1 启动NameServer"></a>3.3.1 启动NameServer</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohuop sh bin/mqnamesrv &amp; #后台运行 nameserver</span><br><span class="line">tail -f ~/logs/rocketmqlogs/namesrv.log #监听nameserver日志文件</span><br></pre></td></tr></table></figure>

<h4 id="3-3-1-启动Broker"><a href="#3-3-1-启动Broker" class="headerlink" title="3.3.1 启动Broker"></a>3.3.1 启动Broker</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup sh mqbroker -n localhost:9876 &amp;</span><br><span class="line">tail -f ~/logs/rocketmqlogs/broker.log</span><br></pre></td></tr></table></figure>

<h3 id="3-4-消息测试"><a href="#3-4-消息测试" class="headerlink" title="3.4 消息测试"></a>3.4 消息测试</h3><h4 id="3-4-1-发送消息"><a href="#3-4-1-发送消息" class="headerlink" title="3.4.1 发送消息"></a>3.4.1 发送消息</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export NAMESRV_ADDR=localhost:9876 #设置环境变量</span><br><span class="line">sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer</span><br></pre></td></tr></table></figure>

<h4 id="3-4-2-接收消息"><a href="#3-4-2-接收消息" class="headerlink" title="3.4.2 接收消息"></a>3.4.2 接收消息</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer</span><br></pre></td></tr></table></figure>

<h3 id="3-5-关闭"><a href="#3-5-关闭" class="headerlink" title="3.5 关闭"></a>3.5 关闭</h3><p>无论是关闭name server还是broker，都是使用<code>bin/mqshutdown</code>命令。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@study rocketmq4.9.0]# sh bin/mqshutdown broker</span><br><span class="line">The mqbroker(1298) is running...</span><br><span class="line">Send shutdown request to mqbroker(1298) OK</span><br><span class="line"></span><br><span class="line">[root@s1 rocketmq4.9.0]# sh bin/mqshutdown namesrv</span><br><span class="line">The mqnamesrv(1258) is running...</span><br><span class="line">Send shutdown request to mqnamesrv(1258) OK</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP协议详解</title>
    <url>/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="一、TCP概述"><a href="#一、TCP概述" class="headerlink" title="一、TCP概述"></a>一、TCP概述</h2><ol>
<li><p>TCP被称为是<strong>面向连接的可靠的运输协议</strong>，即两个进程之间必须互相发送某些预备报文段，已建立确保数据传输的参数。</p>
</li>
<li><p>TCP连接是一条逻辑连接，其共同状态只保留TCP进程两端中，而不存在中间的网络元素（路由器和链路层交换机）中运行。提供<strong>全双工服务</strong>（即数据流通是双向的），连接也总是<strong>点对点</strong>，<code>即在单个发送方与单个接送方之间的连接</code>，所谓的“多播”，对于TCP来说是不可能的。</p>
</li>
<li><p>发送和接送缓存。TCP可从缓存中取出并放入报文段的数据数量受限于**最大报文段长度(MSS)**，MSS通常由本地主机的最大链路层帧长度(<strong>最大传输单元，MTU</strong>)来设置。</p>
<blockquote>
<p>以太网和链路层协议都具有1500字节的MTU，TCP/IP首部长度通常为40字节，所以MSS的典型值为1460字节。</p>
</blockquote>
<span id="more"></span>

<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/TCP%E7%BC%93%E5%AD%98.png" class=""></li>
</ol>
<h2 id="二、TCP报文段结构"><a href="#二、TCP报文段结构" class="headerlink" title="二、TCP报文段结构"></a>二、TCP报文段结构</h2><p>TCP报文段由首部字段和一个数据字段组成。数据字段包含一块应用数据，TCP的首部一般是20字节（比UDP首部多12个字节）</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/TCP%E6%8A%A5%E6%96%87%E6%AE%B5.png" class="">

<ul>
<li><strong>序号字段</strong>和<strong>确认号字段</strong>。用于实现可靠数据传输服务</li>
<li>16比特的<strong>接送窗口字段</strong>，该字段用于流量控制，指示接收方愿意接受的字节数量。</li>
<li>4比特的<strong>首部长度字段</strong>，该字段指示以32比特的字为单位的TCP首部长度。由于选项字段的原因，TCP首部的长度是可变的。(通常选项字段为空，所以TCP首部的典型长度为20字节)。</li>
<li>可选与变长的<strong>选项字段</strong>，该字段用于发送发与接收方协商最大报文段长度时，或在高速网络环境下用作窗口调节因子使用。</li>
<li>6比特的<strong>标志字段</strong>。<strong>ACK</strong>用于指示该报文段已被成功接送的确认，<strong>RST、SYN和FIN</strong>比特用于连接建立与拆除。</li>
</ul>
<h3 id="2-1-序号和确认号"><a href="#2-1-序号和确认号" class="headerlink" title="2.1 序号和确认号"></a>2.1 序号和确认号</h3><p><strong>序号</strong>(Seq)：报文段首字节的字节流的编号</p>
<p><strong>确认号</strong>(ACK)：期望从另一方接送到的下一个字节的序号，累积确认。</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/%E5%BA%8F%E5%8F%B7%E5%92%8C%E7%A1%AE%E8%AE%A4%E5%8F%B7.png" class="">

<p>TCP连接的双方均可随机的选择初始序号。这样可以减少将那些仍在网络中存在的来自两台主机之间先前已终止的连接的报文段，误认为是后来这两台主机之间新建连接所产生的有效报文段的可能性（它碰巧与旧连接使用了相同的端口号）。</p>
<h2 id="三、可靠数据传输"><a href="#三、可靠数据传输" class="headerlink" title="三、可靠数据传输"></a>三、可靠数据传输</h2><h3 id="3-1-可靠数据传输原理"><a href="#3-1-可靠数据传输原理" class="headerlink" title="3.1 可靠数据传输原理"></a>3.1 可靠数据传输原理</h3><p>在今天的计算机网络中，数据传输中会出现比特受损、低层信道丢包，那怎么检测丢包以及发生丢包后怎么做呢？（比特受损可以通过校验和字段来检测比特差错）</p>
<h4 id="3-1-1-构建可靠数据传输协议"><a href="#3-1-1-构建可靠数据传输协议" class="headerlink" title="3.1.1 构建可靠数据传输协议"></a>3.1.1 构建可靠数据传输协议</h4><p>假设发送方传输一个数据分组，该分组或者接收方对该分组的ACK发生了丢失。在这两种情况下，发送方都不会收到应当到来的接收方的响应。我们需要设置一个等待时间来确定已丢失了，就需要重传该分组。</p>
<blockquote>
<p>等待时间至少为：发送方与接送方之间的一个往返时延加上接收方处理一个分组所需的时间</p>
</blockquote>
<p>实现基于时间的重传机制，需要一个<strong>倒计数定时器</strong>，在一个给定的时间量过期后，可中断发送发。因此，发送方需要能做到：</p>
<ol>
<li>每次发送一个分组(包括第一次分组和重传分组)时，启动一个定时器</li>
<li>响应定时器中断</li>
<li>终止定时器</li>
</ol>
<p>经具有比特差错的丢包信道的可靠数据传输(rdt3.0)的发送方<strong>有限状态机(FSM)</strong></p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/rdt3.0.png" class="">

<p>下图显示了在没有丢包和延迟分组情况下协议运作的情况，以及是如何处理数据分组丢失的。</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/%E6%AF%94%E7%89%B9%E4%BA%A4%E6%9B%BF%E5%8D%8F%E8%AE%AE.png" class="">

<h4 id="3-1-2-流水线可靠数据传输协议"><a href="#3-1-2-流水线可靠数据传输协议" class="headerlink" title="3.1.2 流水线可靠数据传输协议"></a>3.1.2 流水线可靠数据传输协议</h4><p>rdt3.0是一个功能正确的协议，但它的性能问题的核心在于它是一个<strong>停等协议</strong></p>
<blockquote>
<p>停等协议：发送一个分组后发送方处于等待ACK或NAK分组状态，将不能发送新的分组。</p>
</blockquote>
<p>一个简单解决方法是：不以停等方式运行，允许发送方发送多个分组而无需等待确认，这种方式可以被看成是填充到一条流水线中，故这种技术被称为<strong>流水线</strong>。</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/%E6%B5%81%E6%B0%B4%E7%BA%BF%E6%93%8D%E4%BD%9C.png" class="">

<p>流水线技术对可靠数据传输协议可带来如下影响：</p>
<ul>
<li><p>必须增加序号范围，因为每个输送中的分组（不计算重传的）必须有一个唯一的序号，而且也许有多个在输送中的未确认报文。</p>
</li>
<li><p>在发送方、接收方要有缓冲区</p>
<ul>
<li>发送方缓冲：未得到确认，可能需要重传</li>
<li>接收方缓冲：上层用户取用数据的速率!=接收到的数据速率；接收到的数据可能乱序，排序交付（可靠）</li>
</ul>
</li>
<li><p>所需序号范围和对缓冲的要求取决于数据传输协议如何处理丢失、损坏及延时过大的数组。解决流水线的差错恢复有两种基本方法是：<strong>回退N步（GBN）</strong>和选择<strong>重传（SR）</strong></p>
</li>
</ul>
<h4 id="3-1-3-回退N步"><a href="#3-1-3-回退N步" class="headerlink" title="3.1.3 回退N步"></a>3.1.3 回退N步</h4><p><strong>回退N步协议</strong>允许发送方发送多个分组(当有多个分组可用时)而不需要等待确认，但它受限于在流水线中未确认的分组数不能超过窗口长度N。</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/GBN.png" class="">

<p>如上图所示，那些已被发送但还未被确认的分组的许可序号范围可以被看成是一个在序号范围内长度为N的窗口。随着协议的运行，该窗口在序号空间向前滑动。因此，<strong>GBN协议也常称为滑动窗口协议。</strong></p>
<blockquote>
<p>为什么要限制这些被发送的、未被确认的分组的数目为N呢？为什么不允许这些分组为无限制的数目呢？</p>
<p>这个原因是要在接下来说的TCP拥塞控制时分析的一个原因；流量控制是对发送方施加限制的原因之一。</p>
</blockquote>
<p><strong>滑动窗口协议：</strong></p>
<ul>
<li>发送缓冲区：<ul>
<li>形式：内存中的一个区域，落入缓冲区的分组可以发送</li>
<li>功能：用于存放已发送，但是没有得到确认的分组</li>
<li>必要性：需要重发时可用</li>
</ul>
</li>
<li>发送缓冲区的大小：一次最多可以发送多少个未经确认的分组<ul>
<li>停止等待协议等于1</li>
<li>流水线协议大于1，合理的值不能很大，链路利用率不能超过100%</li>
</ul>
</li>
<li>发送缓冲区中的分组：<ul>
<li>未发送的：落入发送缓冲区的分组，可以连续发送出</li>
<li>已经发送出去的、等待对方确认的分组：发送缓冲区的分组只有得到确认才能删除。</li>
</ul>
</li>
</ul>
<p><strong>GBN发送方必须响应三种类型的事件</strong>：</p>
<ul>
<li><code>上层的调用</code>。当上层调用rdt_ send()时，发送方首先检查发送窗口是否已满，即是否有N个已发送但未被确认的分组。如果窗口未满，则产生一个分组并将其发送，并相应地更新变量。如果窗口已满，发送方只需将数据返回给上层，隐式地指示上层该窗口已满。然后上层可能会过一会儿再试。在实际实现中，发送方更可能缓存(并不立刻发送)这些数据，或者使用同步机制(如一个信号量或标志)允许上层在仅当窗口不满时才调用rdt_send()。</li>
<li><code>收到一个ACK</code>。在GBN协议中，对序号为n的分组的确认采用累积确认的方式，表明接受发已正确接收到序号为n的以前包括n在内的所有分组。</li>
<li><code>超时事件</code>。如果出现超时，发送方重传所有已发送但还未被确认过的分组。发送方仅使用一个定时器，它可被当作是最早的已发送但未被确认的分组所使用的定时器。如果收到一个ACK,但仍有已发送但未被确认的分组，则定时器被重新启动。如果没有已发送但未被确认的分组，停止该定时器。</li>
</ul>
<p><strong>GBN接收方响应的事件：</strong></p>
<ul>
<li><code>发送一个ACK</code>。如果一个序号为n的分组被正确接收到，并且按序(即上次交付给上层的数据是序号为n-1的分组)，则接收方为分组n发送一个ACK,并将该分组中的数据部分交付到上层。在所有其他情况下，接收方丢弃该分组，并为最近按序接收的分组重新发送ACK。</li>
<li><code>丢弃失序分组</code>。在GBN协议中，接收方丢弃所有失序分组。尽管丢弃一个正确接收(但失序)的分组有点愚蠢和浪费，但接收方必须按序将数据交付给上层。因此，接收方只需丢弃即可。这种方法的优点是接收缓存简单，即接收方不需要缓存任何失序分组。</li>
</ul>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/GBN%E8%BF%90%E8%A1%8C.png" class="">

<h4 id="3-1-4-选择重传"><a href="#3-1-4-选择重传" class="headerlink" title="3.1.4 选择重传"></a>3.1.4 选择重传</h4><p>GBN协议避免了停等协议中所提到的信道利用率问题。然而GBN在当窗口长度和带宽时延积都很大时，单个分组的差错就能够引起GBN重传大量分组，许多分组根本没有必要重传。</p>
<p><strong>选择重传（SR）</strong>协议通过让发送发仅重传那些它怀疑在接收方出错（即丢失或受损）的分组而避免了不必要的重传。</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/SR%E7%9A%84%E5%BA%8F%E5%8F%B7%E7%A9%BA%E9%97%B4.png" class="">

<p><strong>SR发送方的事件与动作：</strong></p>
<ol>
<li><code>从上层收到数据</code>。当从上层接收到数据后，SR发送方检查下一个可用于该分组的序号。如果序号位于发送方的窗口内，则将数据打包并发送;否则就像在GBN中一样，要么将数据缓存，要么将其返回给上层以便以后传输。</li>
<li><code>超时</code>。定时器再次被用来防止丢失分组。然而，现在每个分组必须拥有其自己的逻辑定时器，因为超时发生后只能发送-一个分组。可以使用单个硬件定时器模拟多个逻辑定时器的操作</li>
<li><code>收到ACK</code>。如果收到ACK，倘若该分组序号在窗口内，则SR发送方将那个被确认的分组标记为已接收。如果该分组的序号等于send _base, 则窗口基序号向前移动到具有最小序号的未确认分组处。如果窗口移动了并且有序号落在窗口内的未发送分组，则发送这些分组。</li>
</ol>
<p><strong>SR接收方的事件与动作：</strong></p>
<ol>
<li><p>序号在[rev_base, rev_ base+N-1] 内的分组被正确接收。在此情况下，收到的分组落在接收方的窗口内，一个选择ACK被回送给发送方。如果该分组以前没收到过，则缓存该分组。如果该分组的序号等于接收窗口的基序号(rev_ base)，则该分组以及以前缓存的序号连续的(起始于rev_ base的)分组交付给上层。然后，接收窗口按向前移动分组的编号向上交付这些分组。</p>
</li>
<li><p>序号在[rev_ base - N, rev_base-1] 内的分组被正确收到。在此情况下，必须产生一个ACK,即使该分组是接收方以前已确认过的分组。</p>
<blockquote>
<p>接收方重新确认（而不是忽略）已收到过的那些序号小于当前窗口基序号？</p>
<p>如果分组send_base的ACK没有从接收方传播回发送方，则发送方最终会超时重传分组send_base，即使接收方已经正确收到该分组。如果接收方不确认该分组ACK，则发送方窗口将永远不能向前滑动。<strong>说明了SR协议对于哪些分组已经正确接收，哪些没有，发送方和接收方并不总是能看到相同的结果，意味着它们的窗口并不总是一致。</strong></p>
</blockquote>
</li>
<li><p>其他情况。忽略该分组。</p>
</li>
</ol>
<p><strong>窗口长度设置：</strong></p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/%E6%8E%A5%E6%94%B6%E7%AA%97%E5%8F%A3.png" class="">

<p>图a表示，对前三个分组的ACK丢失，因此发送方重传这些分组。</p>
<p>图b表示，对前三个分组的ACK都被正确交付。因此发送方向前移动窗口并发送4、5、6个分组，其序号分别为3、0、1，序号为3的分组丢失，但序号为0的分组到达（一个包含新数据的分组）。图a、b都会出现没有办法区分是第一个分组的重传还是第五个分组的初次传输的问题。于是我们<strong>对于SR协议而言，窗口长度必须小于或等于序号空间大小的一半。</strong></p>
<h4 id="3-1-5-对比GBN与SR"><a href="#3-1-5-对比GBN与SR" class="headerlink" title="3.1.5 对比GBN与SR"></a>3.1.5 对比GBN与SR</h4><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">GBN</th>
<th align="center">SR</th>
</tr>
</thead>
<tbody><tr>
<td align="center">发送缓冲区(SW)</td>
<td align="center">大于1</td>
<td align="center">大于1</td>
</tr>
<tr>
<td align="center">接收缓冲区(RW)</td>
<td align="center">等于1</td>
<td align="center">大于1</td>
</tr>
<tr>
<td align="center">优点</td>
<td align="center">简单，所需资源少(接收方一个缓存单元)</td>
<td align="center">出错时，重传一个代价小</td>
</tr>
<tr>
<td align="center">缺点</td>
<td align="center">一旦出错，回退N步代价大</td>
<td align="center">复杂，所需资源多(接收方多个缓存单元)</td>
</tr>
</tbody></table>
<p>适用范围：</p>
<ul>
<li>出错率低：比较适合GBN，出错非常罕见，没有必要用复杂的SR，为罕见的事件做日常的准备和复杂处理</li>
<li>链路容量大(延迟大、带宽大)：比较适合SR而不是GBN，一点出错代价太大。</li>
</ul>
<h3 id="3-2-TCP可靠数据传输"><a href="#3-2-TCP可靠数据传输" class="headerlink" title="3.2 TCP可靠数据传输"></a>3.2 TCP可靠数据传输</h3><p><strong>TCP在IP不可靠的尽力而为服务之上创建了一种可靠数据传输服务</strong>。TCP的可靠数据传输服务确保一个进程从其接收缓存中读出的数据流是无损坏、无间隙、非冗余和按序的数据流；即该字节流与连接的另一端系统发送的字节流是完全相同。</p>
<h4 id="3-2-1-常见重传情况"><a href="#3-2-1-常见重传情况" class="headerlink" title="3.2.1 常见重传情况"></a>3.2.1 常见重传情况</h4><img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/TCP%E9%87%8D%E4%BC%A0.png" class="">

<ol>
<li><p>第一种情况：由于确认丢失而重传</p>
</li>
<li><p>第二种情况：报文段100没有重传</p>
<p>当超时事件发生时，主机A重传序号92的第一个报文段，并重启定时器。只要第二个报文段的ACK在新的超时发生以前到达，则第二个报文段将不会被重传。</p>
<blockquote>
<p>前面所说的可靠数据传输技术，假定每一个已发送但未被确认的报文段都有一个定时器相关联，但这种定时器的管理却需要相当大的开销。因此，在TCP协议仅使用<strong>单一的重传定时器</strong>，即使有多个已发送但还未被确认的报文段。所以第二个报文段不会被重传。</p>
</blockquote>
</li>
<li><p>第三种情况：累积确认避免之前的报文段重传</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/%E7%B4%AF%E7%A7%AF%E7%A1%AE%E8%AE%A4%E9%81%BF%E5%85%8D%E9%87%8D%E4%BC%A0.png" class="">

<p>第一个报文段的确认报文在网络丢失，但在超时事件发生之前主机A收到一个确认号为120的确认报文。主机A因而知道主机B已经收到了序号为119及之前的所有字节;所以主机A不会重传这两个报文段中的任何一个。</p>
</li>
</ol>
<h4 id="3-2-2-超时间隔加倍"><a href="#3-2-2-超时间隔加倍" class="headerlink" title="3.2.2 超时间隔加倍"></a>3.2.2 超时间隔加倍</h4><p>TCP重传具有最小序号的还未被确认的报文段。只是每次TCP重传时都会将下一次的超时间隔设为先前值的两倍。超时间隔在每次重传后会呈现指数型增长。然而，每当定时器在另两个事件（即收到上层应用的数据和收到ACK）中的任意一个启动时，TimeoutInterval由最近的EstimatedRTT值与DevRTT值推算得到。</p>
<h4 id="3-2-3-快速重传"><a href="#3-2-3-快速重传" class="headerlink" title="3.2.3 快速重传"></a>3.2.3 快速重传</h4><p>超时触发重传存在的问题之一是超时周期可能相对较长。当一个报文段丢失时，这种长超时周期迫使发送方延迟重传丢失的分组，因而增加了端到端时延。幸运的是，发送方通常可在超时事件发生之前通过注意所谓冗余ACK来较好地检测到丟包情况。<strong>冗余ACK</strong> ( duplicate ACK)就是再次确认某个报文段的ACK，而发送方先前已经收到对该报文段的确认。</p>
<p>因为发送方经常一个接一个地发送大量的报文段，如果一个报文段丢失，就很可能引起许多一个接一个的冗余ACK。如果TCP发送方接收到对相同数据的3个冗余ACK,它把这当作一种指示，说明跟在这个已被确认过3次的报文段之后的报文段已经丢失。一旦收到<strong>3个冗余ACK</strong>, TCP就执行<strong>快速重传</strong>( fast retransmit)，即在该报文段的定时器过期之前重传丢失的报文段。</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.png" class="">

<h4 id="3-2-4-是回退N步还是选择重传"><a href="#3-2-4-是回退N步还是选择重传" class="headerlink" title="3.2.4 是回退N步还是选择重传"></a>3.2.4 是回退N步还是选择重传</h4><p>TCP确认是累积式的，正确接收但失序的报文段是不会被接收方逐个确认的。TCP发送方仅需维持已发送过但未被确认的字节的最小序号和下一个要发送的字节序号。在这种意义下，TCP看起来更像一个GBN协议。但对TCP提出的一种修改意见是所谓的<strong>选择确认</strong>( selective acknowledgment) ，它允许TCP接收方有选择地确认失序报文段，而不是累积地确认最后一个正确接收的有序报文段。当将该机制与选择重传机制结合起来使用时( 即跳过重传那些已被接收方选择性地确认过的报文段)，TCP看起来就很像我们通常的SR协议。因此，<strong>TCP的差错恢复机制也许最好被分类为GBN协议与SR协议的混合体</strong>。</p>
<h2 id="四、流量控制"><a href="#四、流量控制" class="headerlink" title="四、流量控制"></a>四、流量控制</h2><p>一条TCP连接的每一侧都有设置缓存。如果某应用程序读取数据时相对缓慢，而发送方发送得太多、太快，发送的数据就会很容易地使该连接的接收缓存溢出。</p>
<p>TCP为应用程序提供了<strong>流量控制服务</strong>以消除发送方使接收方缓存溢出的可能性。它使发送方的速率和接收方的读取速率相匹配，它与拥塞控制采取的动作非常相似（对发送方遏制），但它们是针对完全不同的原因而采用的措施。</p>
<p>TCP在连接两端的发送方都各自维护一个<strong>接收窗口变量</strong>（给发送方一个指示——该接收方还有多少可用的缓存空间)，假设主机A通过一条TCP向主机B发送一个大文件，用RcvBuffer来表示缓存大小。还定义一下变量：</p>
<ul>
<li>LastByteRead：主机B上的应用进程从缓存读出的数据流的最后一个字节的编号</li>
<li>LastByteRcvd：从网络中到达的并且已放入主机B接收缓存中的数据流的最后一个字节的编号。</li>
</ul>
<p>由于TCP不允许已分配的缓存溢出，下式必须成立：</p>
<center>LastByteRcvd - LastByteRead <= RcvBuffer</center>

<p>接收窗口用rwnd表示，根据缓存可用空间的数量来设置：</p>
<center>rwnd = Rcvd - (LastByteRcvd - LastByteRead) </center>

<p>由于该空间是随时间变化的，所以rwnd是动态的。如图所示：</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/rwnd.png" class="">

<blockquote>
<p>假设主机B的接收缓存已经存满，使得rwnd=0，在将rwnd=0通告给主机A之后，还要假设主机B没有任何数据要发给主机A，此时会发生情况呢？</p>
<p>主机B上的应用进程将缓存清空，TCP并不向主机A发送带有rwnd新值的新报文段;事实上，TCP仅当在它有数据或有确认要发时才会发送报文段给主机A。这样，主机A不可能知道主机B的接收缓存已经有新的空间了，即主机A被阻塞而不能再发送数据!为了解决这个问题，TCP 规范中要求:<strong>当主机B的接收窗口为0时，主机A继续发送只有一个字节数据的报文段</strong>。这些报文段将会被接收方确认。最终缓存将开始清空，并且确认报文里将包含一个非0的rwnd值。</p>
</blockquote>
<p><strong>UDP并不提供流量控制，报文段由于缓存溢出可能在接收方丢失。</strong></p>
<h2 id="五、TCP连接管理"><a href="#五、TCP连接管理" class="headerlink" title="五、TCP连接管理"></a>五、TCP连接管理</h2><h3 id="5-1-建立连接"><a href="#5-1-建立连接" class="headerlink" title="5.1 建立连接"></a>5.1 建立连接</h3><p>客户机中的TCP会用以下方式与服务器中的TCP建立一条TCP连接：（<strong>三次握手</strong>）</p>
<ol>
<li><code>第一步</code>: 客户端的TCP首先向服务器端的TCP发送<code>一个特殊的TCP报文段</code>。该报文段中<code>不包含应用层数据</code>。但是在<strong>报文段的首部中的一个标志位(即SYN比特)被置为1</strong>。因此，这个特殊报文段被称为SYN报文段。另外，客户会随机地选择一个初始序号( client_ isn), 并将此编号放置于该起始的TCP SYN报文段的序号字段中。该报文段会被封装在一个IP数据报中，并发送给服务器。为了避免某些安全性攻击，在适当地随机化选择client_isn。</li>
<li><code>第二步</code>: 一旦包含TCP SYN报文段的IP数据报到达服务器主机，服务器会从该数据报中提取出TCP SYN报文段，为该TCP连接分配TCP缓存和变量，并向该客户TCP发送允许连接的报文段。(在完成三次握手的第三步之前分配这些缓存和变量，使得TCP易于受到称为SYN洪泛的拒绝服务攻击）这个允许连接的报文段也不包含应用层数据。但是，在报文段的首部却包含3个重要的信息。首先，SYN比特被置为1。其次，该TCP报文段首部的确认号字段被置为client _ isn + 1。最后，服务器选择自己的初始序号(server_ isn)， 并将其放置到TCP报文段首部的序号字段中。该允许连接的报文段被称为SYNACK报文段( SYNACK segment)。</li>
<li><code>第三步</code>: 在收到SYNACK报文段后，客户也要给该连接分配缓存和变量。客户主机则向服务器发送另外一个报文段；这最后一个报文段对服务器的允许连接的报文段进行了确认(该客户通过将值server_ isn+1放置到TCP报文段首部的确认字段中来完成此项工作)。因为连接已经建立了，所以该SYN比特被置为0。<strong>该三次握手的第三个阶段可以在报文段负载中携带客户到服务器的数据</strong>。</li>
</ol>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png" class="">

<p>Q：在网络中，两次握手建立连接可行吗？</p>
<p>A：不可行，会带来：1、服务器维持了虚假的连接（半连接）；2、服务器将旧数据当成新数据</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/2%E6%AC%A1%E6%8F%A1%E6%89%8B.png" class="">

<h3 id="5-2-关闭连接"><a href="#5-2-关闭连接" class="headerlink" title="5.2 关闭连接"></a>5.2 关闭连接</h3><p>当连接结束后，主机中的“资源”(即缓存和变量)将被释放。（<strong>四次挥手</strong>）</p>
<ol>
<li><p>客户端，服务器分别关闭它自己这一侧的连接：发送FIN=1的TCP段</p>
</li>
<li><p>一旦接收到FIN，用ACK回应：收到FIN段，ACK可以和它自己发出的FIN段一起发送。</p>
</li>
<li><p>可以处理同时的FIN交换</p>
<img src="/2021/03/25/TCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png" class=""></li>
</ol>
<p>假设客户应用程序决定要关闭该连接。(注意到服务器也能选择关闭该连接。)这引起客户TCP发送一个带有FIN比特被置为1的TCP报文段，并进入FIN_ WAIT_ 1状态。当处在FIN_ WAIT_ 1状态时，客户TCP等待一个来自服务器的带有确认的TCP报文段。当它收到该报文段时，客户TCP进入FIN WAIT 2状态。当处在FIN <em>WAIT</em> 2状态时，客户等待来自服务器的FIN比特被置为1的另一个报文段;当收到该报文段后，客户TCP对服务器的报文段进行确认，并进人TIME_ WAIT状态。假定ACK丢失，TIME_ WAIT状态使TCP客户重传最后的确认报文。在TIME_ WAIT 状态中所消耗的时间是与具体实现有关的，而典型的值是30秒、1分钟或2分钟。经过等待后，连接就正式关闭，客户端所有资源(包括端口号)将被释放。</p>
<h3 id="5-3-SYN洪泛攻击"><a href="#5-3-SYN洪泛攻击" class="headerlink" title="5.3 SYN洪泛攻击"></a>5.3 SYN洪泛攻击</h3><p>如果某客户不发送ACK来完成该三次握手的第三步，最终(通常在一分多钟之后)服务器将终止该半开连接并回收资源。这种TCP连接管理协议为经典的DoS攻击即<strong>SYN洪泛攻击</strong>(SYN flood attack)提供了环境。在这种攻击中，攻击者发送大量的TCP SYN报文段，而不完成第三次握手的步骤。这将导致服务器不断为这些半开连接分配资源，导致服务器的连接资源被消耗殆尽。</p>
<p>现在有一种有效的防御系统称为<strong>SYN cookie</strong>，它的工作方式：</p>
<ul>
<li>当服务器接收到一个SYN报文段时，服务器生成一个<strong>初始TCP序列号</strong>，该序列号是SYN报文段的<strong>源和目的IP地址与端口号以及仅有该服务器知道的秘密数的一个复杂函数(散列函数)<strong>。这种精心制作的初始序列号被称为“cookie”。 服务器则发送具有这种</strong>特殊初始序列号的SYNACK分组</strong>。<strong>重要的是，服务器并不记忆该cookie或任何对应于SYN的其他状态信息。</strong></li>
<li>如果客户是合法的，则它将返回一个ACK报文段。当服务器收到该ACK,需要验证该ACK是与前面发送的某些SYN相对应的。而服务器没有维护有关SYN报文段的记忆，它是借助于cookie 来做到的。前面讲过对于一个合法的ACK，在<strong>确认字段中的值等于在SYNACK字段(此时为cookie值)中的值加1</strong>。服务器则将使用在SYNACK报文段中的源和目的地IP地址与端口号(它们与初始的SYN中的相同)以及秘密数运行相同的散列函数。如果该函数的结果加1与在客户的SYNACK中的确认(cookie) 值相同的话，服务器认为该ACK对应于较早的SYN报文段，因此它是合法的。服务器则生成一个具有套接字的全开的连接。</li>
<li>如果客户没有返回一个ACK报文段，则初始的SYN并没有对服务器产生危害，因为服务器没有为它分配任何资源。</li>
</ul>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch进阶</title>
    <url>/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[<h2 id="一-核心概念"><a href="#一-核心概念" class="headerlink" title="一. 核心概念"></a>一. 核心概念</h2><p>Elasticsearch中的一些概念与MySQL中的可以类比,如下图:</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/es%E6%A6%82%E5%BF%B5%E5%AF%B9%E6%AF%94.png" class="">

<span id="more"></span>

<h3 id="1-1-索引-Index"><a href="#1-1-索引-Index" class="headerlink" title="1.1 索引(Index)"></a>1.1 索引(Index)</h3><p>一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名字来标识（必须全部是小写字母），并且当我们要对这个索引中的文档进行索引、搜索、更新和删除（CRUD）的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索引。能搜索的数据必须索引，这样的好处是可以提高查询速度，比如：新华字典前面的目录就是索引的意思，目录可以提高查询速度。<strong>在es中一个索引可以类比为MySQL中的一个数据库</strong></p>
<h3 id="1-2-类型-Type"><a href="#1-2-类型-Type" class="headerlink" title="1.2 类型(Type)"></a>1.2 类型(Type)</h3><p>在一个索引中, 你可以定义一种或多种类型.</p>
<p>一个类型是你的索引的一个逻辑上的分类/分区, 其语义完全由你来定义. 通常, 会为具有一组共同字段的文档定义一个类型. 不同的版本, 类型发生了不同的变化.</p>
<table>
<thead>
<tr>
<th>版本</th>
<th align="center">Type</th>
</tr>
</thead>
<tbody><tr>
<td>5.x</td>
<td align="center">支持多种 type</td>
</tr>
<tr>
<td>6.x</td>
<td align="center">只能有一种 type</td>
</tr>
<tr>
<td>7.x</td>
<td align="center">默认不再支持自定义索引类型（默认类型为： _doc）</td>
</tr>
</tbody></table>
<h3 id="1-3-文档-Document"><a href="#1-3-文档-Document" class="headerlink" title="1.3 文档(Document)"></a>1.3 文档(Document)</h3><p>一个文档是一个可被索引的基础信息单元，也就是一条数据。比如：你可以拥有某一个客户的文档，某一个产品的一个文档，当然，也可以拥有某个订单的一个文档。文档以 JSON（Javascript Object Notation）格式来表示，而 JSON 是一个到处存在的互联网数据交互格式。</p>
<p>在一个 index/type 里面，你可以存储任意多的文档。</p>
<h3 id="1-4-字段-Field"><a href="#1-4-字段-Field" class="headerlink" title="1.4 字段(Field)"></a>1.4 字段(Field)</h3><p>相当于是数据表的字段，对文档数据根据不同属性进行的分类标识。</p>
<h3 id="1-5-映射-Mapping"><a href="#1-5-映射-Mapping" class="headerlink" title="1.5 映射(Mapping)"></a>1.5 映射(Mapping)</h3><p>mapping 是处理数据的方式和规则方面做一些限制，如：某个字段的数据类型、默认值、分析器、是否被索引等等。这些都是映射里面可以设置的，其它就是处理 ES 里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。</p>
<h3 id="1-6-分片-Shards"><a href="#1-6-分片-Shards" class="headerlink" title="1.6 分片(Shards)"></a>1.6 分片(Shards)</h3><p>一个索引可以存储超出单个节点硬件限制的大量数据。比如，一个具有 10 亿文档数据的索引占据 1TB 的磁盘空间，而任一节点都可能没有这样大的磁盘空间。 或者单个节点处理搜索请求，响应太慢。为了解决这个问题，<strong>Elasticsearch 提供了将索引划分成多份的能力，每一份就称之为分片。</strong>当你创建一个索引的时候，你可以指定你想要的分片的数量。<strong>每个分片本身也是一个功能完善并且独立的“索引”</strong>，这个“索引”可以被放置到集群中的任何节点上。</p>
<p>分片很重要，主要有两方面的原因：</p>
<ol>
<li>允许你水平分割 / 扩展你的内容容量。</li>
<li>允许你在分片之上进行分布式的、并行的操作，进而提高性能/吞吐量。</li>
</ol>
<p>至于一个分片怎样分布，它的文档怎样聚合和搜索请求，是完全由 Elasticsearch 管理的，对于作为用户的你来说，这些都是透明的，无需过分关心。</p>
<p>被混淆的概念是，一个 Lucene 索引 我们在 Elasticsearch 称作 分片 。 一个Elasticsearch 索引 是分片的集合。 当 Elasticsearch 在索引中搜索的时候， 他发送查询到每一个属于索引的分片（Lucene 索引），然后合并每个分片的结果到一个全局的结果集。</p>
<h3 id="1-7-副本-Replicas"><a href="#1-7-副本-Replicas" class="headerlink" title="1.7 副本(Replicas)"></a>1.7 副本(Replicas)</h3><p>在一个网络 / 云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的， Elasticsearch 允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片(副本)。</p>
<p>复制分片之所以重要，有两个主要原因：</p>
<ul>
<li>在分片/节点失败的情况下，<strong>提供了高可用性</strong>。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。</li>
<li>扩展你的搜索量/吞吐量，因为搜索可以在所有的副本上并行运行。</li>
</ul>
<p>总之，每个索引可以被分成多个分片。一个索引也可以被复制 0 次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。<strong>在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。</strong></p>
<p>默认情况下，Elasticsearch 中的每个索引被分片 1 个主分片和 1 个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有 1 个主分片和另外 1 个复制分片（1 个完全拷贝），这样的话每个索引总共就有 2 个分片， 我们需要根据索引需要确定分片个数。</p>
<h3 id="1-8-分配-Allocation"><a href="#1-8-分配-Allocation" class="headerlink" title="1.8 分配(Allocation)"></a>1.8 分配(Allocation)</h3><p>将分片分配给某个节点的过程，包括分配主分片或者副本。如果是副本，还包含从主分片复制数据的过程。这个过程是由 master 节点完成的。</p>
<h2 id="二-系统架构简介"><a href="#二-系统架构简介" class="headerlink" title="二. 系统架构简介"></a>二. 系统架构简介</h2><img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B.png" class="">

<p>一个运行中的 Elasticsearch 实例称为一个节点，而集群是由一个或者多个拥有相同cluster.name 配置的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。<br>当一个节点被选举成为主节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。我们的示例集群就只有一个节点，所以它同时也成为了主节点。<br>作为用户，我们可以将请求发送到集群中的任何节点 ，包括主节点。 每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。</p>
<h3 id="2-1-单节点集群"><a href="#2-1-单节点集群" class="headerlink" title="2.1 单节点集群"></a>2.1 单节点集群</h3><p>假如我们在包含一个空节点的集群内创建名为users的索引,我们将分配 3个主分片和一份副本（每个主分片拥有一个副本分片）。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">#PUT http:<span class="comment">//127.0.0.1:9300/users</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;settings&quot;</span> : &#123;</span><br><span class="line">        <span class="attr">&quot;number_of_shards&quot;</span> : <span class="number">3</span>,</span><br><span class="line">        <span class="attr">&quot;number_of_replicas&quot;</span> : <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>集群现在是拥有一个索引的单节点集群。所有 3 个主分片都被分配在 node-1 。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/node1.png" class="">

<p>通过 elasticsearch-head 插件（一个Chrome插件）查看集群情况 。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/cluster.png" class="">

<ul>
<li>集群健康值:yellow( 3 of 6 )：表示当前集群的全部主分片都正常运行，但是副本分片没有全部处在正常状态。</li>
<li>绿色的三个主分片表示正常(<strong>黑色框加粗表示主分片</strong>)</li>
<li>灰色的是3个副本分片都是Unassigned, 它们都没有被分配到任何节点。 在同 一个节点上既保存原始数据又保存副本是没有意义的，因为一旦失去了那个节点，我们也将丢失该节点 上的所有副本数据。</li>
</ul>
<p><strong>当前集群是可以正常运行的，但存在丢失数据的风险。</strong></p>
<h3 id="2-2-故障转移"><a href="#2-2-故障转移" class="headerlink" title="2.2 故障转移"></a>2.2 故障转移</h3><p>当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失。当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。之所以配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。</p>
<p>如果启动了第二个节点，集群将会拥有两个节点 : 所有主分片和副本分片都重新分配 。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/node2.png" class="">

<ul>
<li>集群健康值:green( 3 of 6 )：表示所有 6 个分片（包括 3 个主分片和 3 个副本分片）都在正常运行。</li>
<li>第二个节点加入到集群后， 3 个副本分片将会分配到这个节点上——每 个主分片对应一个副本分片。这意味着当集群内任何一个节点出现问题时，我们的数据都完好无损。所 有新近被索引的文档都将会保存在主分片上，然后被并行的复制到对应的副本分片上。这就保证了我们 既可以从主分片又可以从副本分片上获得文档。</li>
</ul>
<h3 id="2-3-水平扩容"><a href="#2-3-水平扩容" class="headerlink" title="2.3 水平扩容"></a>2.3 水平扩容</h3><p>当启动了第三个节点，我们的集群将会拥有三个节点的集群 : 为了分散负载而对分片进行重新分配 。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/node3.png" class="">

<p>Node 1 和 Node 2 上各有一个分片被迁移到了新的 Node 3 节点，现在每个节点上都拥有 2 个分片， 而不是之前的 3 个。 这表示每个节点的硬件资源（CPU, RAM, I/O）将被更少的分片所共享，每个分片 的性能将会得到提升。</p>
<p>分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。 我们这个拥有 6 个分 片（3 个主分片和 3 个副本分片）的索引可以最大扩容到 6 个节点，每个节点上存在一个分片，并且每个 分片拥有所在节点的全部资源。</p>
<p><strong>但是如果我们想要扩容超过 6 个节点怎么办呢？</strong></p>
<p>主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够<br>存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作——<br>搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片<br>时，也将拥有越高的吞吐量。在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把副本数从默认的 1 增加到 2。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">#PUT http:<span class="comment">//127.0.0.1:9300/users/_settings</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;number_of_replicas&quot;</span> : <span class="number">2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-故障应对"><a href="#2-4-故障应对" class="headerlink" title="2.4 故障应对"></a>2.4 故障应对</h3><p>我们关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生的第一件事情就是选举一个新的主节点： Node 2 。在我们关闭 Node 1 的同时也失去了主分片 1 和 2 ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。</p>
<p>幸运的是，在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片， 此时集群的状态将会为yellow。这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/guzhang.png" class="">

<p>虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应 2 份副本分片，而此<br>时只存在一份副本分片。 所以集群不能为 green 的状态，不过我们不必过于担心：如果我<br>们同样关闭了 Node 2 ，我们的程序 依然 可以保持在不丢任何数据的情况下运行，因为<br>Node 3 为每一个分片都保留着一份副本。如果想回复原来的样子，要确保Node-1的配置文件有如下配置：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">discovery.seed_hosts: [<span class="string">&quot;localhost:9302&quot;</span>, <span class="string">&quot;localhost:9303&quot;</span>]<span class="comment">//其他主机上的es服务器地址</span></span><br></pre></td></tr></table></figure>

<p>重启Node-1, 集群可以将缺失的副本分片再次进行分配，那么集群的状态也将恢复成之前的状态。 如果 Node 1 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。和之前的集群相比，只是 Master 节点切换了。</p>
<h2 id="三-路由与分片"><a href="#三-路由与分片" class="headerlink" title="三. 路由与分片"></a>三. 路由与分片</h2><h3 id="3-1-路由计算"><a href="#3-1-路由计算" class="headerlink" title="3.1 路由计算"></a>3.1 路由计算</h3><p>当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片 1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shard = hash(routing) % number_of_primary_shards</span><br></pre></td></tr></table></figure>

<blockquote>
<p>routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。</p>
</blockquote>
<p>这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量: 因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。</p>
<p>所有的文档API ( get . index . delete 、 bulk , update以及 mget ）都接受一个叫做routing 的路由参数，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档, 例如所有属于同一个用户的文档——都被存储到同一个分片中。</p>
<h3 id="3-2-分片控制"><a href="#3-2-分片控制" class="headerlink" title="3.2 分片控制"></a>3.2 分片控制</h3><p>我们可以发送请求到集群中的任一节点。每个节点都有能力处理任意请求。每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。在下面的例子中，如果将所有的请求发送到Node 1001，我们将其称为协调节点<strong>coordinating node</strong>。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/coordinate_node.png" class="">

<p>当发送请求的时候， 为了扩展负载，更好的做法是轮询集群中所有的节点。</p>
<h2 id="四-数据操作"><a href="#四-数据操作" class="headerlink" title="四. 数据操作"></a>四. 数据操作</h2><h3 id="4-1-数据写流程"><a href="#4-1-数据写流程" class="headerlink" title="4.1 数据写流程"></a>4.1 数据写流程</h3><p>新建、索引和删除请求都是写操作， 必须在主分片上面完成之后才能被复制到相关的副本分片。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/data_write.png" class="">

<p>在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。有一些可选的<strong>请求参数</strong>允许您影响这个过程，可能以数据安全为代价提升性能。这些选项很少使用，因为 Elasticsearch 已经很快，但是为了完整起见， 请参考下文：</p>
<ol>
<li><p>consistency</p>
<blockquote>
<p>即一致性。在默认设置下，即使仅仅是在试图执行一个写操作之前，主分片都会要求必须要有规定数量quorum（或者换种说法，也即必须要有大多数）的分片副本处于活跃可用状态，才会去执行写操作（其中分片副本 可以是主分片或者副本分片）。这是为了避免在发生网络分区故障（network partition）的时候进行写操作，进而导致数据不一致。 规定数量即： <strong>int((primary + number_of_replicas) / 2 ) + 1</strong></p>
</blockquote>
<pre><code>  consistency 参数的值可以设为：
      one ：只要主分片状态 ok 就允许执行写操作。
      all：必须要主分片和所有副本分片的状态没问题才允许执行写操作。
      quorum：默认值为quorum , 即大多数的分片副本状态没问题就允许执行写操作。
</code></pre>
<p>   注意，规定数量的计算公式中number_of_replicas指的是在索引设置中的设定副本分片数，而不是指当前处理    活动状态的副本分片数。如果你的索引设置中指定了当前索引拥有3个副本分片，那规定数量的计算结果即：               int((1 primary + 3 replicas) / 2) + 1 = 3，如果此时你只启动两个节点，那么处于活跃状态的分片副本数量就达    不到规定数量，也因此您将无法索引和删除任何文档。</p>
</li>
<li><p>timeout<br>如果没有足够的副本分片会发生什么？Elasticsearch 会等待，希望更多的分片出现。默认情况下，它最多等待 1 分钟。 如果你需要，你可以使用timeout参数使它更早终止：100是100 毫秒，30s是30秒。</p>
</li>
</ol>
<p>新索引默认有1个副本分片，这意味着为满足规定数量应该需要两个活动的分片。 但是，这些默认的设置会阻止我们在单一节点上做任何事情。为了避免这个问题，要求只有当number_of_replicas 大于1的时候，规定数量才会执行。</p>
<h3 id="4-2-数据读流程"><a href="#4-2-数据读流程" class="headerlink" title="4.2 数据读流程"></a>4.2 数据读流程</h3><img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/data_read.png" class="">

<p>在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。</p>
<h3 id="4-3-数据更新流程"><a href="#4-3-数据更新流程" class="headerlink" title="4.3 数据更新流程"></a>4.3 数据更新流程</h3><h4 id="4-3-1-更新流程"><a href="#4-3-1-更新流程" class="headerlink" title="4.3.1 更新流程"></a>4.3.1 更新流程</h4><p>部分更新一个文档结合了先前说明的读取和写入流程：</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/data_update.png" class="">

<ol>
<li>客户端向Node 1发送更新请求。</li>
<li>它将请求转发到主分片所在的Node 3 。</li>
<li>Node 3从主分片检索文档，修改_source字段中的JSON，并且尝试重新索引主分片的文档。如果文档已经被另一个进程修改,它会重试步骤3 ,超过retry_on_conflict次后放弃。</li>
<li>如果 Node 3成功地更新文档，它将新版本的文档并行转发到Node 1和 Node 2上的副本分片，重新建立索引。一旦所有副本分片都返回成功，Node 3向协调节点也返回成功，协调节点向客户端返回成功。</li>
</ol>
<p>当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果 Elasticsearch 仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。</p>
<h4 id="4-3-2-批量操作流程"><a href="#4-3-2-批量操作流程" class="headerlink" title="4.3.2 批量操作流程"></a>4.3.2 批量操作流程</h4><p><strong>mget和 bulk API的模式类似于单文档模式。</strong>区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成每个分片的多文档请求，并且将这些请求并行转发到每个参与节点。</p>
<p>协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端。</p>
<p><strong>用单个 mget 请求取回多个文档所需的步骤顺序:</strong></p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/data_update1.png" class="">

<ol>
<li>客户端向 Node 1 发送 mget 请求。</li>
<li>Node 1为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复，Node 1 构建响应并将其返回给客户端。</li>
</ol>
<p>可以对docs数组中每个文档设置routing参数。</p>
<p>bulk API， 允许在单个批量请求中执行多个创建、索引、删除和更新请求。</p>
<p><strong>bulk API 步骤顺序执行：</strong></p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/data_update2.png" class="">

<ol>
<li>客户端向Node 1 发送 bulk请求。</li>
<li>Node 1为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。</li>
<li>主分片一个接一个按顺序执行每个操作。当每个操作成功时,主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</li>
</ol>
<h2 id="五-文档"><a href="#五-文档" class="headerlink" title="五. 文档"></a>五. 文档</h2><h3 id="5-1-倒排索引"><a href="#5-1-倒排索引" class="headerlink" title="5.1 倒排索引"></a>5.1 倒排索引</h3><p>传统的数据库每个字段存储单个值，但这对全文检索并不够。文本字段中的每个单词需要被搜索，对数据库意味着需要单个字段有索引多值的能力。最好的支持是一个字段多个值需求的数据结构是<strong>倒排索引</strong>。</p>
<p>Elasticsearch使用一种称为倒排索引的结构，它适用于快速的全文搜索。所谓的倒排索引是将文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。</p>
<p>一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。例如，假设我们有两个文档，每个文档的content域包含如下内容：</p>
<ul>
<li>The quick brown fox jumped over the lazy dog</li>
<li>Quick brown foxes leap over lazy dogs in summer</li>
</ul>
<p>为了创建倒排索引，我们首先将每个文档的content域拆分成单独的词（我们称它为词条或tokens )，创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示：</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/daopai.png" class="">

<h4 id="5-1-1-不可变的倒排索引"><a href="#5-1-1-不可变的倒排索引" class="headerlink" title="5.1.1 不可变的倒排索引"></a>5.1.1 不可变的倒排索引</h4><p>早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。</p>
<p>倒排索引被写入磁盘后是不可改变的：它永远不会修改。</p>
<ol>
<li>不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。</li>
<li>一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。</li>
<li>其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。</li>
<li>写入单个大的倒排索引允许数据被压缩，减少磁盘IO和需要被缓存到内存的索引的使用量。</li>
</ol>
<p>当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。</p>
<h4 id="5-1-2-动态更新索引"><a href="#5-1-2-动态更新索引" class="headerlink" title="5.1.2 动态更新索引"></a>5.1.2 动态更新索引</h4><p>如何在保留不变性的前提下实现倒排索引的更新？</p>
<p>答案是：用更多的索引。通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到,从最早的开始查询完后再对结果进行合并。</p>
<p>Elasticsearch基于Lucene，这个java库引入了<strong>按段搜索</strong>的概念。每一段本身都是一个倒排索引，但索引在 Lucene 中除表示所有段的集合外，还增加了提交点的概念—一个列出了所有已知段的文件。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/commit_point.png" class="">

<p>按段搜索会以如下流程执行：</p>
<ol>
<li><p>新文档被收集到内存索引缓存。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/commit_point1.png" class=""></li>
<li><p>不时地, 缓存被提交</p>
<ol>
<li>一个新的段，一个追加的倒排索引，被写入磁盘。</li>
<li>一个新的包含新段名字的提交点被写入磁盘。</li>
<li>磁盘进行同步，所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件</li>
</ol>
</li>
<li><p>新的段被开启，让它包含的文档可见以被搜索。</p>
</li>
<li><p>内存缓存被清空，等待接收新的文档。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/commit_point2.png" class=""></li>
</ol>
<p>当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。这种方式可以用相对较低的成本将新文档添加到索引。<br>段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。取而代之的是，每个提交点会包含一个.del 文件，文件中会列出这些被删除文档的段信息。<br>一个<strong>文档被“删除”</strong>时，它实际上只是在 .del 文件中被标记删除。一个被标记删除的文档仍然可以被查询匹配到，但它会在最终结果被返回前从结果集中移除。<br><strong>文档更新</strong>也是类似的操作方式:当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。</p>
<h3 id="5-2-文档刷新"><a href="#5-2-文档刷新" class="headerlink" title="5.2 文档刷新"></a>5.2 文档刷新</h3><img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/doc.png" class="">

<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/doc1.png" class="">

<h4 id="5-2-1-近实时搜索"><a href="#5-2-1-近实时搜索" class="headerlink" title="5.2.1 近实时搜索"></a>5.2.1 近实时搜索</h4><p>随着按段（per-segment）搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。磁盘在这里成为了瓶颈。提交（Commiting）一个新的段到磁盘需要一个fsync来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。但是fsync操作代价很大；如果每次索引一个文档都去执行一次的话会造成很大的性能问题。</p>
<p>我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着fsync要从整个过程中被移除。在Elasticsearch和磁盘之间是文件系统缓存。像之前描述的一样，在内存索引缓冲区中的文档会被写入到一个新的段中。但是这里新段会被先写入到文件系统缓存—这一步代价会比较低，稍后再被刷新到磁盘—这一步代价比较高。不过只要文件已经在缓存中，就可以像其它文件一样被打开和读取了。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/commit_point1.png" class="">

<p>Lucene允许新段被写入和打开，使其包含的文档在未进行一次完整提交时便对搜索可见。这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/commit_point3.png" class="">

<p>在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做refresh。默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch是近实时搜索：文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。</p>
<p>这些行为可能会对新用户造成困惑：他们索引了一个文档然后尝试搜索它，但却没有搜到。这个问题的解决办法是用refresh API执行一次手动刷新：/usersl_refresh</p>
<p>尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候，手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。相反，你的应用需要意识到Elasticsearch 的近实时的性质，并接受它的不足。</p>
<p>并不是所有的情况都需要每秒刷新。可能你正在使用Elasticsearch索引大量的日志文件，你可能想优化索引速度而不是近实时搜索，可以通过设置refresh_interval ，降低每个索引的刷新频率</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;settings&quot;</span>: &#123;</span><br><span class="line">    	<span class="attr">&quot;refresh_interval&quot;</span>: <span class="string">&quot;30s&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>refresh_interval可以在既存索引上进行动态更新。在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 关闭自动刷新</span><br><span class="line">PUT /users/_settings</span><br><span class="line">&#123; &quot;refresh_interval&quot;: -1 &#125;</span><br><span class="line"></span><br><span class="line"># 每一秒刷新</span><br><span class="line">PUT /users/_settings</span><br><span class="line">&#123; &quot;refresh_interval&quot;: &quot;1s&quot; &#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-2-2-持久化变更"><a href="#5-2-2-持久化变更" class="headerlink" title="5.2.2 持久化变更"></a>5.2.2 持久化变更</h4><p>如果没有用fsync把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。在动态更新索引，我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。</p>
<p>即使通过每秒刷新(refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办?我们也不希望丢失掉这些数据。Elasticsearch 增加了一个translog ，或者叫事务日志，在每一次对Elasticsearch进行操作时均进行了日志记录。</p>
<p><strong>整个流程如下:</strong></p>
<ol>
<li><p>一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了 translog</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/commit_point4.png" class=""></li>
<li><p>刷新（refresh）使分片每秒被刷新（refresh）一次：</p>
<ul>
<li><p>这些在内存缓冲区的文档被写入到一个新的段中，且没有进行fsync操作。</p>
</li>
<li><p>这个段被打开，使其可被搜索。</p>
</li>
<li><p>内存缓冲区被清空。</p>
</li>
</ul>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/commit_point5.png" class=""></li>
<li><p>这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/commit_point6.png" class=""></li>
<li><p>每隔一段时间—例如translog变得越来越大，索引被刷新（flush）；一个新的translog被创建，并且一个全量提交被执行。</p>
<ul>
<li>所有在内存缓冲区的文档都被写入一个新的段。</li>
<li>缓冲区被清空。</li>
<li>一个提交点被写入硬盘。</li>
<li>文件系统缓存通过fsync被刷新（flush） 。</li>
<li>老的translog被删除。</li>
</ul>
</li>
</ol>
<p>translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当Elasticsearch启动的时候，它会从磁盘中使用最后一个提交点去恢复己知的段，并且会重放translog 中所有在最后一次提交后发生的变更操作。</p>
<p>translog 也被用来提供实时CRUD。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前，首先检查 translog任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/commit_point7.png" class="">

<p>执行一个提交并且截断translog 的行为在 Elasticsearch被称作一次flush。分片每30分钟被自动刷新（flush)，或者在 translog 太大的时候也会刷新。</p>
<p>你很少需要自己手动执行flush操作，通常情况下，自动刷新就足够了。这就是说，在重启节点或关闭索引之前执行 flush有益于你的索引。当Elasticsearch尝试恢复或重新打开一个索引，它需要重放translog中所有的操作，所以如果日志越短，恢复越快。</p>
<p>translog 的目的是保证操作不会丢失，在文件被fsync到磁盘前，被写入的文件在重启之后就会丢失。默认translog是每5秒被fsync刷新到硬盘，或者在每次写请求完成之后执行（e.g. index, delete, update, bulk）。这个过程在主分片和复制分片都会发生。最终，基本上，这意味着在整个请求被fsync到主分片和复制分片的translog之前，你的客户端不会得到一个200 OK响应。</p>
<p>在每次请求后都执行一个fsync会带来一些性能损失，尽管实践表明这种损失相对较小（特别是 bulk 导入，它在一次请求中平摊了大量文档的开销）。</p>
<p>但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次 fsync 。如果你决定使用异步translog 的话，你需要保证在发生 crash 时，丢失掉 sync_interval时间段的数据也无所谓。请在决定前知晓这个特性。如果你不确定这个行为的后果，最好是使用默认的参数{“index.translog.durability”: “request”}来避免数据丢失。</p>
<h3 id="5-3-段合并"><a href="#5-3-段合并" class="headerlink" title="5.3 段合并"></a>5.3 段合并</h3><p>由于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。每一个段都会消耗文件句柄、内存和 cpu运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。<br>Elasticsearch通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。<br>段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。<br>启动段合并不需要你做任何事。进行索引和搜索时会自动进行。</p>
<ol>
<li><p>当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。</p>
</li>
<li><p>合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p>
<img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/merger.png" class=""></li>
<li><p>一旦合并结束，老的段被删除</p>
<ul>
<li>新的段被刷新(flush)到了磁盘。</li>
<li>写入一个包含新段且排除旧的和较小的段的新提交点。</li>
<li>新的段被打开用来搜索。老的段被删除。</li>
</ul>
 <img src="/2021/11/01/Elasticsearch%E8%BF%9B%E9%98%B6/merger1.png" class=""></li>
</ol>
<p>合并大的段需要消耗大量的 I/O 和 CPU 资源，如果任其发展会影响搜索性能。 Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。</p>
]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ工作原理</title>
    <url>/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h2 id="一、消息的生产"><a href="#一、消息的生产" class="headerlink" title="一、消息的生产"></a>一、消息的生产</h2><h3 id="1-1-消息的生产过程"><a href="#1-1-消息的生产过程" class="headerlink" title="1.1 消息的生产过程"></a>1.1 消息的生产过程</h3><p>Producer可以将消息写入到某Broker中的某Queue中，其经历了如下过程：</p>
<ul>
<li>Producer发送消息之前，会先向NameServer发出获取消息Topic的路由信息的请求</li>
<li>NameServer返回该Topic的路由表及Broker列表</li>
<li>Producer根据代码中指定的Queue选择策略，从Queue列表中选出一个队列，用于后续存储消息</li>
<li>Produer对消息做一些特殊处理，例如，消息本身超过4M，则会对其进行压缩</li>
<li>Producer向选择出的Queue所在的Broker发出RPC请求，将消息发送到选择出的Queue</li>
</ul>
<span id="more"></span>

<blockquote>
<p>路由表：</p>
<p>实际是一个Map，key为Topic名称，value是一个QueueData实例列表。QueueData并不是一个Queue对应一个QueueData，而是一个Broker中该Topic的所有Queue对应一个QueueData。即，只要涉及到该Topic的Broker，一个Broker对应一个QueueData。QueueData中包含brokerName。简单来说，<code>路由表的key为Topic名称，value则为所有涉及该Topic的BrokerName列表</code>。</p>
<p>Broker列表：</p>
<p>其实际也是一个Map。key为brokerName，value为BrokerData。一个Broker对应一个BrokerData实例，对吗？不对。一套brokerName名称相同的Master-Slave小集群对应一个BrokerData。BrokerData中包含brokerName及一个map。该map的key为brokerId，value为该broker对应的地址。brokerId为0表示该broker为Master，非0表示Slave。</p>
</blockquote>
<h3 id="1-2-Queue选择算法"><a href="#1-2-Queue选择算法" class="headerlink" title="1.2 Queue选择算法"></a>1.2 Queue选择算法</h3><p>对于无序消息，其Queue选择算法，也称为消息投递算法，常见的有两种：</p>
<h4 id="1-2-1-轮询算法"><a href="#1-2-1-轮询算法" class="headerlink" title="1.2.1 轮询算法"></a>1.2.1 轮询算法</h4><p><em>默认选择算法。该算法保证了每个Queue中可以均匀的获取到消息</em></p>
<blockquote>
<p>该算法存在一个问题：由于某些原因，在某些Broker上的Queue可能投递延迟较严重。从而<code>导致Producer的缓存队列中出现较大的消息积压，影响消息的投递性能</code>。</p>
</blockquote>
<h4 id="1-2-2-最小投递延迟算法"><a href="#1-2-2-最小投递延迟算法" class="headerlink" title="1.2.2 最小投递延迟算法"></a>1.2.2 最小投递延迟算法</h4><p>该算法会统计每次消息投递的时间延迟，然后根据统计出的结果将消息投递到时间延迟最小的Queue。如果延迟相同，则采用轮询算法投递。该算法可以有效提升消息的投递性能。</p>
<blockquote>
<p>该算法也存在一个问题：消息在Queue上的<code>分配不均匀</code>。投递延迟小的Queue其可能会存在大量的消息。而对该Queue的消费者压力会增大，降低消息的消费能力，可能会<code>导致MQ中消息的堆积</code>。</p>
</blockquote>
<h2 id="二、消息的存储"><a href="#二、消息的存储" class="headerlink" title="二、消息的存储"></a>二、消息的存储</h2><p>RocketMQ中的消息存储在本地文件系统中，这些相关文件默认在当前用户主目录下的store目录中。</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/store.png" class="">

<ul>
<li>abort：该文件在Broker启动后会自动创建，正常关闭Broker，该文件会自动消失。若在没有启动Broker的情况下，发现这个文件是存在的，则说明之前Broker的关闭是非正常关闭。</li>
<li>checkpoint：其中存储着commitlog、consumequeue、index文件的最后刷盘时间戳</li>
<li>commitlog：其中存放着commitlog文件，而消息是写在commitlog文件中的</li>
<li>config：存放着Broker运行期间的一些配置数据</li>
<li>consumequeue：其中存放着consumequeue文件，队列就存放在这个目录中</li>
<li>index：其中存放着消息索引文件indexFile</li>
<li>lock：运行期间使用到的全局资源锁</li>
</ul>
<h3 id="2-1-commitlog文件"><a href="#2-1-commitlog文件" class="headerlink" title="2.1 commitlog文件"></a>2.1 commitlog文件</h3><p><strong>说明</strong>：在很多资料中commitlog目录中的文件简单就称为commitlog文件。但在源码中，该文件被命名为<code>mappedFile</code>。</p>
<h4 id="2-1-1-目录与文件"><a href="#2-1-1-目录与文件" class="headerlink" title="2.1.1 目录与文件"></a>2.1.1 目录与文件</h4><p><code>真正的消息是写在mappedFile中</code></p>
<p>commitlog目录中存放着很多的mappedFile文件，当前Broker中的所有消息都是落盘到这些mappedFile文件中的。<code>mappedFile文件大小为1G（小于等于1G）</code>，文件名由20位十进制数构成，表示当前文件的第一条消息的起始位移偏移量。</p>
<blockquote>
<p>第一个文件名一定是20位0构成的。因为第一个文件的第一条消息的偏移量commitlog offset为0当第一个文件放满时，则会自动生成第二个文件继续存放消息。假设第一个文件大小是1073741820字节（1G = 1073741824字节），则第二个文件名就是00000000001073741824。以此类推，第n个文件名应该是前(n-1)*G。一个Broker中所有mappedFile文件的commitlog offset是连续的</p>
</blockquote>
<p>需要注意的是，一个Broker中仅包含一个commitlog目录，所有的mappedFile文件都是存放在该目录中的。即无论当前Broker中存放着多少Topic的消息，这些消息都是被顺序写入到了mappedFile文件中的。也就是说，这些消息在Broker中存放时并没有被按照Topic进行分类存放。</p>
<blockquote>
<p><code>mappedFile文件是顺序读写</code>的文件，所有其访问效率很高，无论是SSD磁盘还是SATA磁盘，通常情况下，<code>顺序存取效率都会高于随机存取</code>。</p>
</blockquote>
<h4 id="2-1-2-消息单元"><a href="#2-1-2-消息单元" class="headerlink" title="2.1.2 消息单元"></a>2.1.2 消息单元</h4><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/mappedFile.png" class="">

<p>mappedFile文件内容由一个个的<code>消息单元</code>构成(每一行)。每个消息单元中包含消息总长度MsgLen、消息的物理位置physicalOffset、消息体内容Body、消息体长度BodyLength、消息主题Topic、Topic长度TopicLength、消息生产者BornHost、消息发送时间戳BornTimestamp、消息所在的队列QueueId、消息在Queue中存储的偏移量QueueOffset等近20余项消息相关属性。</p>
<blockquote>
<p>需要注意到，消息单元中是包含Queue相关属性的。所以，我们在后续的学习中，就需要十分留意commitlog与queue间的关系是什么？</p>
<p>一个mappedFile文件中第m+1个消息单元的commitlog offset偏移量L(m+1) = L(m) + MsgLen(m) (m &gt;= 0)</p>
</blockquote>
<h3 id="2-2-consumequeue"><a href="#2-2-consumequeue" class="headerlink" title="2.2 consumequeue"></a>2.2 consumequeue</h3><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/consumequeue.png" class="">

<h4 id="2-2-1-目录与文件"><a href="#2-2-1-目录与文件" class="headerlink" title="2.2.1 目录与文件"></a>2.2.1 目录与文件</h4><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/consumequeue1.png" class="">

<p>为了提高效率，会为每个Topic在~/store/consumequeue中创建一个目录，目录名为Topic名称。在该Topic目录下，会再为每个该Topic的Queue建立一个目录，目录名为queueId。每个目录中存放着若干consumequeue文件，consumequeue文件是commitlog的索引文件，可以根据consumequeue定位到具体的消息。</p>
<p>consumequeue文件名也由 20 位数字构成，表示当前文件的第一个索引条目的起始位移偏移量。与mappedFile文件名不同的是，其后续文件名是固定的。因为consumequeue文件大小是固定不变的。</p>
<h4 id="2-2-2-索引条目"><a href="#2-2-2-索引条目" class="headerlink" title="2.2.2 索引条目"></a>2.2.2 索引条目</h4><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/consumequeue_index.png" class="">

<p>每个consumequeue文件可以包含30w个索引条目，每个索引条目包含了三个消息重要属性：消息在mappedFile文件中的偏移量CommitLog Offset、消息长度、消息Tag的hashcode值。这三个属性占 20个字节，所以每个文件的大小是固定的30w * 20字节。</p>
<blockquote>
<p>一个consumequeue文件中所有消息的Topic一定是相同的。但每条消息的Tag可能是不同的。</p>
</blockquote>
<h3 id="2-3-文件的读写"><a href="#2-3-文件的读写" class="headerlink" title="2.3 文件的读写"></a>2.3 文件的读写</h3><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/message.png" class="">

<h4 id="2-3-1-消息写入"><a href="#2-3-1-消息写入" class="headerlink" title="2.3.1 消息写入"></a>2.3.1 消息写入</h4><p>一条消息进入到Broker后经历了以下几个过程才最终被持久化。</p>
<ul>
<li>Broker根据queueId，获取到该消息对应索引条目要在consumequeue目录中的写入偏移量，即QueueOffset</li>
<li>将queueId、queueOffset等数据，与消息一起封装为消息单元</li>
<li>将消息单元写入到commitlog</li>
<li>同时，形成消息索引条目，将消息索引条目分发到相应的consumequeue</li>
</ul>
<h4 id="2-3-2-消息拉取"><a href="#2-3-2-消息拉取" class="headerlink" title="2.3.2 消息拉取"></a>2.3.2 消息拉取</h4><ul>
<li><p>当Consumer来拉取消息时会经历以下几个步骤：</p>
<ul>
<li><p>Consumer获取到其要消费消息所在Queue的消费偏移量offset，计算出其要消费消息的消息offset</p>
<blockquote>
<p>消费offset即消费进度，consumer对某个Queue的消费offset，即消费到了该Queue的第几条消息<br>消息offset = 消费offset + 1</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Consumer向Broker发送拉取请求，其中会包含其要拉取消息的Queue、消息offset及消息Tag。</p>
</li>
<li><p>Broker计算在该consumequeue中的queueOffset。</p>
<blockquote>
<p>queueOffset = 消息offset * 20字节</p>
</blockquote>
</li>
<li><p>从该queueOffset处开始向后查找第一个指定Tag的索引条目。</p>
</li>
<li><p>解析该索引条目的前 8 个字节，即可定位到该消息在commitlog中的commitlog offset</p>
</li>
<li><p>从对应commitlog offset中读取消息单元，并发送给Consumer</p>
</li>
</ul>
<h4 id="2-3-3-性能提升"><a href="#2-3-3-性能提升" class="headerlink" title="2.3.3 性能提升"></a>2.3.3 性能提升</h4><p>RocketMQ中，无论是消息本身还是消息索引，都是存储在磁盘上的。其不会影响消息的消费吗？当然不会。其实RocketMQ的性能在目前的MQ产品中性能是非常高的。因为系统通过一系列相关机制大大提升了性能。</p>
<p>首先，RocketMQ对文件的读写操作是通过<code>mmap零拷贝</code>进行的，将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率。</p>
<p>其次，consumequeue中的数据是顺序存放的，还引入了<code>PageCache的预读取机制</code>，使得对consumequeue文件的读取几乎接近于内存读取，即使在有消息堆积情况下也不会影响性能。</p>
<blockquote>
<p>PageCache机制，页缓存机制，是OS对文件的缓存机制，用于加速对文件的读写操作。一般来说，程序对文件进行顺序读写的速度几乎接近于内存读写速度，主要原因是由于OS使用PageCache机制对读写访问操作进行性能优化，将一部分的内存用作PageCache。</p>
<p>1)写操作：OS会先将数据写入到PageCache中，随后会以异步方式由pdæush（page dirty æush)内核线程将Cache中的数据刷盘到物理磁盘<br>2)读操作：若用户要读取数据，其首先会从PageCache中读取，若没有命中，则OS在从物理磁盘上加载该数据到PageCache的同时，也会顺序 对其相邻数据块中的数据进行预读取。</p>
</blockquote>
<h2 id="三、indexFile"><a href="#三、indexFile" class="headerlink" title="三、indexFile"></a>三、indexFile</h2><p>除了通过通常的指定Topic进行消息消费外，RocketMQ还提供了根据key进行消息查询的功能。该查询是通过store目录中的index子目录中的indexFile进行索引实现的快速查询。当然，这个indexFile中的索引数据是在<code>包含了key的消息</code>被发送到Broker时写入的。如果消息中没有包含key，则不会写入。</p>
<h3 id="3-1-索引条目结构"><a href="#3-1-索引条目结构" class="headerlink" title="3.1 索引条目结构"></a>3.1 索引条目结构</h3><p>每个Broker中会包含一组indexFile，每个indexFile都是以一个<code>时间戳</code>命名的（这个indexFile被创建时的时间戳）。每个indexFile文件由三部分构成：indexHeader，slots槽位，indexes索引数据。每个 indexFile文件中包含500w个slot槽。而每个slot槽又可能会挂载很多的index索引单元。</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/indexFile.png" class="">

<p>indexHeader固定 40 个字节，其中存放着如下数据：</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/indexHeader.png" class="">

<ul>
<li>beginTimestamp：该indexFile中第一条消息的存储时间</li>
<li>endTimestamp：该indexFile中最后一条消息存储时间</li>
<li>beginPhyoffset：该indexFile中第一条消息在commitlog中的偏移量commitlog offset</li>
<li>endPhyoffset：该indexFile中最后一条消息在commitlog中的偏移量commitlog offset</li>
<li>hashSlotCount：已经填充有index的slot数量（并不是每个slot槽下都挂载有index索引单元，这里统计的是所有挂载了index索引单元的slot槽的数量）</li>
<li>indexCount：该indexFile中包含的索引单元个数（统计出当前indexFile中所有slot槽下挂载的所有index索引单元的数量之和）</li>
</ul>
<p>indexFile中最复杂的是Slots与Indexes间的关系。在实际存储时，Indexes是在Slots后面的，但为了便于理解，将它们的关系展示为如下形式：</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/indexes.png" class="">

<p><code>key的hash值 % 500w</code>的结果即为slot槽位，然后将该slot值修改为该index索引单元的indexNo，根据这个indexNo可以计算出该index单元在indexFile中的位置。不过，该<code>取模结果的重复率是很高</code>的，为了解决该问题，在每个index索引单元中增加了<code>preIndexNo</code>，<code>用于指定该slot中当前index索引单元的前一个index索引单元</code>。而<code>slot中始终存放的是其下最新的index索引单元的indexNo</code>，这样的话，只要找到了slot就可以找到其最新的index索引单元，而通过这个index索引单元就可以找到其之前的所有index索引单元。</p>
<blockquote>
<p>indexNo是一个在indexFile中的流水号，从 0 开始依次递增。即在一个indexFile中所有indexNo是以此递增的。indexNo在index索引单元中是没有体现的，其是通过indexes中依次数出来的。</p>
</blockquote>
<p>index索引单元默写 20 个字节，其中存放着以下四个属性：</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/indexUnit.png" class="">

<ul>
<li>keyHash：消息中指定的业务key的hash值</li>
<li>phyOffset：当前key对应的消息在commitlog中的偏移量commitlog offset</li>
<li>timeDiff：当前key对应消息的存储时间与当前indexFile创建时间的时间差</li>
<li>preIndexNo：当前slot下当前index索引单元的前一个index索引单元的indexNo</li>
</ul>
<h3 id="3-2-indexFile的创建"><a href="#3-2-indexFile的创建" class="headerlink" title="3.2 indexFile的创建"></a>3.2 indexFile的创建</h3><p>indexFile的文件名为当前文件<code>被创建时的时间戳</code>。这个时间戳有什么用处呢？</p>
<p>根据业务key进行查询时，查询条件除了key之外，还需要指定一个要查询的时间戳，表示要查询不大于该时间戳的最新的消息，即<code>查询指定时间戳之前存储的最新消息</code>。这个时间戳文件名可以简化查询，<code>提高查询效率</code>。具体后面会详细讲解。</p>
<p>indexFile文件是何时创建的？其<code>创建的条件（时机）</code>有两个：</p>
<ul>
<li><p>当第一条带key的消息发送来后，系统发现没有indexFile，此时会创建第一个indexFile文件</p>
</li>
<li><p>当一个indexFile中挂载的index索引单元数量超出2000w个时，会创建新的indexFile。当带key的消息发送到来后，系统会找到最新的indexFile，并从其indexHeader的最后4字节中读取到indexCount。若indexCount &gt;= 2000w时，会创建新的indexFile。</p>
<blockquote>
<p>由于可以推算出，<code>一个indexFile的最大大小是：(40 + 500w * 4 + 2000w * 20)字节</code></p>
</blockquote>
</li>
</ul>
<h3 id="3-3-查询流程"><a href="#3-3-查询流程" class="headerlink" title="3.3 查询流程"></a>3.3 查询流程</h3><p>当消费者通过业务key来查询相应的消息时，其需要经过一个相对较复杂的查询流程。不过，在分析查询流程之前，首先要清楚几个定位计算式子：</p>
<blockquote>
<p>计算指定消息key的slot槽位序号：<br>slot槽位序号 = key的hash % 500w         (式子1)</p>
<p>计算槽位序号为n的slot在indexFile中的起始位置：<br>slot(n)位置 = 40 + (n - 1) * 4         (式子2)</p>
<p>计算indexNo为m的indexs在indexFile中的位置：<br>index(m)位置 = 40 + 500w * 4 + (m - 1) * 20   (式子3)</p>
<p>40为indexFile中indexHeader的字节数，500w * 4 是所有slots所占的字节数</p>
</blockquote>
<p>具体查询流程如下：</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/process.png" class="">

<h2 id="四、消息的消费"><a href="#四、消息的消费" class="headerlink" title="四、消息的消费"></a>四、消息的消费</h2><p>消费者从Broker中获取消息的方式有两种：pull拉取方式和push推动方式。消费者组对于消息消费的模式又分为两种：集群消费Clustering和广播消费Broadcasting。</p>
<h3 id="4-1-获取消费类型"><a href="#4-1-获取消费类型" class="headerlink" title="4.1 获取消费类型"></a>4.1 获取消费类型</h3><h4 id="4-1-1-拉取式消费"><a href="#4-1-1-拉取式消费" class="headerlink" title="4.1.1 拉取式消费"></a>4.1.1 拉取式消费</h4><p>Consumer主动从Broker中拉取消息，主动权由Consumer控制。一旦获取了批量消息，就会启动消费过程。不过，该方式的<code>实时性较弱</code>，即Broker中有了新的消息时消费者并不能及时发现并消费。</p>
<blockquote>
<p><em>由于拉取时间间隔是由用户指定的，所以在设置该间隔时需要注意平稳：</em></p>
<p><em>间隔太短，空请求比例会增加(无用功)；间隔太长，消息的实时性太差</em></p>
</blockquote>
<h4 id="4-1-2-推送式消费"><a href="#4-1-2-推送式消费" class="headerlink" title="4.1.2 推送式消费"></a>4.1.2 推送式消费</h4><p>该模式下Broker收到数据后会主动推送给Consumer。该获取方式一般<code>实时性较高</code>。</p>
<p>该获取方式是典型的发布-订阅模式，即Consumer向其关联的Queue注册了监听器，一旦发现有新的消息到来就会触发回调的执行，回调方法是Consumer去Queue中拉取消息。而这些都是基于Consumer与Broker间的<code>长连接的</code>。<code>长连接的维护是需要消耗系统资源的</code>。</p>
<h4 id="4-1-3-对比"><a href="#4-1-3-对比" class="headerlink" title="4.1.3 对比"></a>4.1.3 对比</h4><ul>
<li><strong>pull</strong>：需要应用去实现对关联Queue的遍历，<code>实时性差</code>；但<code>便于应用控制消息的拉取</code></li>
<li><strong>push</strong>：封装了对关联Queue的遍历，<code>实时性强</code>，但会<code>占用较多的系统资源</code></li>
</ul>
<h3 id="4-2-消费模式"><a href="#4-2-消费模式" class="headerlink" title="4.2 消费模式"></a>4.2 消费模式</h3><h4 id="4-2-1-广播消费"><a href="#4-2-1-广播消费" class="headerlink" title="4.2.1 广播消费"></a>4.2.1 广播消费</h4><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/broadcast.png" class="">

<p>广播消费模式下，相同Consumer Group的每个Consumer实例<code>都接收同一个Topic的全量消息</code>。即每条消息都会被发送到Consumer Group中的每个Consumer。</p>
<h4 id="4-2-2-集群消费"><a href="#4-2-2-集群消费" class="headerlink" title="4.2.2 集群消费"></a>4.2.2 集群消费</h4><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/cluster.png" class="">

<p>集群消费模式下，相同Consumer Group的每个Consumer实例<code>平均分摊</code>同一个Topic的消息。即每条消息只会被发送到Consumer Group中的某个Consumer。</p>
<h4 id="4-2-3-消息进度保存"><a href="#4-2-3-消息进度保存" class="headerlink" title="4.2.3 消息进度保存"></a>4.2.3 消息进度保存</h4><ul>
<li>广播模式：消费进度保存在consumer端。因为广播模式下consumer group中每个consumer都会消费所有消息，但它们的消费进度是不同。所以consumer各自保存各自的消费进度。</li>
<li>集群模式：消费进度保存在broker中。consumer group中的所有consumer共同消费同一个Topic中的消息，同一条消息只会被消费一次。消费进度会参与到了消费的负载均衡中，故消费进度是需要共享的。</li>
</ul>
<p><em>下图是broker中存放的各个Topic的各个Queue的消费进度</em>。</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/consumeProcess.png" class="">

<h3 id="4-3-Rebalance机制"><a href="#4-3-Rebalance机制" class="headerlink" title="4.3 Rebalance机制"></a>4.3 Rebalance机制</h3><p><code>Rebalance机制</code>讨论的前提是：<code>集群消费</code>。</p>
<h4 id="4-3-1-什么是Rebalance"><a href="#4-3-1-什么是Rebalance" class="headerlink" title="4.3.1 什么是Rebalance"></a>4.3.1 什么是Rebalance</h4><p>Rebalance即再均衡，指的是，将⼀个Topic下的多个Queue在同⼀个Consumer Group中的多个Consumer间进行重新分配的过程。</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/rebalance.png" class="">

<p>Rebalance机制的本意是为了<code>提升消息的并行消费能力</code>。例如，⼀个Topic下5个队列，在只有1个消费者的情况下，这个消费者将负责消费这5个队列的消息。如果此时我们增加⼀个消费者，那么就可以给其中⼀个消费者分配2个队列，给另⼀个分配3个队列，从而提升消息的并行消费能力。</p>
<h4 id="4-3-2-Reblance限制"><a href="#4-3-2-Reblance限制" class="headerlink" title="4.3.2 Reblance限制"></a>4.3.2 Reblance限制</h4><p>由于⼀个队列最多分配给⼀个消费者，因此当某个消费者组下的消费者实例数量大于队列的数量时，多余的消费者实例将分配不到任何队列。</p>
<h4 id="4-3-3-Rebalance危害"><a href="#4-3-3-Rebalance危害" class="headerlink" title="4.3.3 Rebalance危害"></a>4.3.3 Rebalance危害</h4><p>Rebalance的在提升消费能力的同时，也带来一些问题：</p>
<ul>
<li><p><strong>消费暂停</strong>：在只有一个Consumer时，其负责消费所有队列；在新增了一个Consumer后会触发Rebalance的发生。此时原Consumer就需要暂停部分队列的消费，等到这些队列分配给新的Consumer后，这些暂停消费的队列才能继续被消费。</p>
</li>
<li><p><strong>消费重复</strong>：Consumer 在消费新分配给自己的队列时，必须接着之前Consumer 提交的消费进度的offset继续消费。然而默认情况下，offset是异步提交的，这个异步性导致提交到Broker的offset与Consumer实际消费的消息并不一致。这个不一致的差值就是可能会重复消费的消息。</p>
<blockquote>
<p>同步提交：</p>
<p>consumer提交了其消费完毕的一批消息的offset给broker后，需要等待broker的成功ACK。当收到ACK后，consumer才会继续获取并消费下一批消息。在等待ACK期间，consumer是阻塞的。</p>
<p>异步提交：</p>
<p>consumer提交了其消费完毕的一批消息的offset给broker后，不需要等待broker的成功ACK。consumer可以直接获取并消费下一批消息。</p>
<p>对于一次性读取消息的数量，需要根据具体业务场景选择一个相对均衡的是很有必要的。数量过大，系统性能提升了，但产生重复消费的消息数量可能会增加；数量过小，系统性能会下降，但被重复消费的消息数量可能会减少。</p>
</blockquote>
</li>
<li><p><strong>消费突刺</strong>：由于Rebalance可能导致重复消费，如果需要重复消费的消息过多，或者因为Rebalance暂停时间过长从而导致积压了部分消息。<code>消息积压</code>，那么有可能会导致在Rebalance结束之后<code>瞬间需要消费很多消息</code>。</p>
</li>
</ul>
<h4 id="4-3-4-Rebalance产生的原因"><a href="#4-3-4-Rebalance产生的原因" class="headerlink" title="4.3.4 Rebalance产生的原因"></a>4.3.4 Rebalance产生的原因</h4><p>导致Rebalance产生的原因，无非就两个：消费者所<code>订阅Topic的Queue数量发生变化</code>，或消费者组中<code>消费者的数量发生变化</code>。</p>
<ol>
<li><p>Queue数量发生变化的场景：</p>
<p>Broker扩容或缩容</p>
<p>Broker升级运维</p>
<p>Broker与NameServer间的网络异常</p>
<p>Queue扩容或缩容</p>
</li>
<li><p>消费者数量发生变化的场景：</p>
<p>Consumer Group扩容或缩容</p>
<p>Consumer升级运维</p>
<p>Consumer与NameServer间网络异常</p>
</li>
</ol>
<h4 id="4-3-5-Rebalance过程"><a href="#4-3-5-Rebalance过程" class="headerlink" title="4.3.5 Rebalance过程"></a>4.3.5 Rebalance过程</h4><p>在Broker中维护着多个Map集合，这些集合中动态存放着当前Topic中Queue的信息、Consumer Group中Consumer实例的信息。一旦发现消费者所订阅的Queue数量发生变化，或消费者组中消费者的数量发生变化，立即向Consumer Group中的每个实例发出Rebalance通知。</p>
<blockquote>
<p>TopicConfigManager：key是topic名称，value是TopicConfig。TopicConfig中维护着该Topic中所有Queue的数据。</p>
<p>ConsumerManager：key是Consumser Group Id，value是ConsumerGroupInfo。ConsumerGroupInfo中维护着该Group中所有Consumer实例数据。</p>
<p>ConsumerOffsetManager：key为Topic与订阅该Topic的Group的组合,即topic@group，value是一个内层Map。内层Map的key为QueueId，内层Map的value为该Queue的消费进度offset。</p>
</blockquote>
<p>Consumer实例在接收到通知后会采用<code>Queue分配算法</code>自己获取到相应的Queue，即由<code>Consumer实例自主进行Rebalance</code>。</p>
<h3 id="4-4-Queue分配算法"><a href="#4-4-Queue分配算法" class="headerlink" title="4.4 Queue分配算法"></a>4.4 Queue分配算法</h3><p>一个Topic中的Queue只能由Consumer Group中的一个Consumer进行消费，而一个Consumer可以同时消费多个Queue中的消息。那么Queue与Consumer间的配对关系是如何确定的，即Queue要分配给哪个Consumer进行消费，也是有算法策略的。常见的有四种策略。这些策略是通过在创建Consumer时的构造器传进去的。</p>
<h4 id="4-4-1-平均分配策略"><a href="#4-4-1-平均分配策略" class="headerlink" title="4.4.1 平均分配策略"></a>4.4.1 平均分配策略</h4><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/average.png" class="">

<p>该算法是要根据<code>avg = QueueCount / ConsumerCount</code>的计算结果进行分配的。如果能够整除，则按顺序将avg个Queue逐个分配Consumer；如果不能整除，则将多余出的Queue按照Consumer顺序逐个分配。</p>
<h4 id="4-4-2-环形平均策略"><a href="#4-4-2-环形平均策略" class="headerlink" title="4.4.2 环形平均策略"></a>4.4.2 环形平均策略</h4><p>环形平均算法是指，根据<code>消费者的顺序，依次在由queue队列组成的环形图中逐个分配</code>。</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/circuit.png" class="">

<blockquote>
<p>该算法<code>不用事先计算</code>，每个Consumer需要分配几个Queue，直接一个一个分即可。</p>
</blockquote>
<h4 id="4-4-3-一致性Hash策略"><a href="#4-4-3-一致性Hash策略" class="headerlink" title="4.4.3 一致性Hash策略"></a>4.4.3 一致性Hash策略</h4><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/hash.png" class="">

<p>该算法会将consumer的hash值作为Node节点存放到hash环上，然后将queue的hash值也放到hash环上，通过<code>顺时针方向</code>，距离queue最近的那个consumer就是该queue要分配的consumer。</p>
<blockquote>
<p>该算法存在的问题：<code>分配不均</code>。</p>
</blockquote>
<h4 id="4-4-4-同机房策略"><a href="#4-4-4-同机房策略" class="headerlink" title="4.4.4 同机房策略"></a>4.4.4 同机房策略</h4><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/house.png" class="">

<p>该算法会<code>根据queue的部署机房位置和consumer的位置</code>，过滤出当前consumer相同机房的queue。然后<code>按照平均分配策略或环形平均策略对同机房queue进行分配</code>。如果没有同机房queue，则按照平均分配策略或环形平均策略对所有queue进行分配。</p>
<h4 id="4-4-5-对比"><a href="#4-4-5-对比" class="headerlink" title="4.4.5 对比"></a>4.4.5 对比</h4><p><strong>一致性hash算法存在的问题</strong>：</p>
<p>两种平均分配策略的分配效率较高，一致性hash策略的较低。因为一致性hash算法较复杂。另外，一致性hash策略分配的结果也很大可能上存在不平均的情况。</p>
<p><strong>一致性hash算法存在的意义</strong>：</p>
<p>其可以<code>有效减少由于消费者组扩容或缩容所带来的大量的Rebalance</code>。避免减少Rebalance</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/rebalance1.png" class="">

<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/rebalance2.png" class="">

<p><strong>一致性hash算法的应用场景</strong>：</p>
<p>Consumer数量变化较频繁的场景。</p>
<h3 id="4-5-至少一次原则"><a href="#4-5-至少一次原则" class="headerlink" title="4.5 至少一次原则"></a>4.5 至少一次原则</h3><p>RocketMQ有一个原则：每条消息必须要被<code>成功消费</code>一次。</p>
<p>那么什么是成功消费呢？Consumer在消费完消息后会向其消费进度记录器提交其消费消息的offset，offset被成功记录到记录器中，那么这条消费就被成功消费了。</p>
<blockquote>
<p>什么是消费进度记录器？</p>
<p>对于<code>广播消费模式</code>来说，<code>Consumer</code>本身就是<code>消费进度记录器</code>。</p>
<p>对于<code>集群消费模式来</code>说，<code>Broker</code>是<code>消费进度记录器</code>。</p>
</blockquote>
<h2 id="五、订阅关系的一致性"><a href="#五、订阅关系的一致性" class="headerlink" title="五、订阅关系的一致性"></a>五、订阅关系的一致性</h2><p>订阅关系的一致性指的是，同一个消费者组（Group ID相同）下所有Consumer实例所订阅的Topic与Tag及对消息的处理逻辑必须完全一致。否则，消息消费的逻辑就会混乱，甚至导致消息丢失。</p>
<h3 id="5-1-正确订阅关系"><a href="#5-1-正确订阅关系" class="headerlink" title="5.1 正确订阅关系"></a>5.1 正确订阅关系</h3><p>多个消费者组订阅了多个Topic，并且每个消费者组里的多个消费者实例的订阅关系保持了一致。</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/group_consumer.png" class="">

<h3 id="5-2-错误订阅关系"><a href="#5-2-错误订阅关系" class="headerlink" title="5.2 错误订阅关系"></a>5.2 错误订阅关系</h3><p>一个消费者组订阅了多个Topic，但是该消费者组里的多个Consumer实例的订阅关系并没有保持一致。</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/group_consumer1.png" class="">

<h4 id="5-2-1-订阅了不同Topic"><a href="#5-2-1-订阅了不同Topic" class="headerlink" title="5.2.1 订阅了不同Topic"></a>5.2.1 订阅了不同Topic</h4><p>该例中的错误在于，同一个消费者组中的两个Consumer实例订阅了不同的Topic。</p>
<p>Consumer实例1-1：（订阅了topic为jodie_test_A，tag为所有的消息）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.put(PropertyKeyConst.GROUP_ID, <span class="string">&quot;GID_jodie_test_1&quot;</span>);</span><br><span class="line">Consumer consumer = ONSFactory.createConsumer(properties);</span><br><span class="line">consumer.subscribe(<span class="string">&quot;jodie_test_A&quot;</span>, <span class="string">&quot;*&quot;</span>, <span class="keyword">new</span> MessageListener() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Action <span class="title">consume</span><span class="params">(Message message, ConsumeContext context)</span> </span>&#123;</span><br><span class="line">        System.out.println(message.getMsgID());</span><br><span class="line">        <span class="keyword">return</span> Action.CommitMessage;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>Consumer实例1-2：（订阅了topic为jodie_test_B，tag为所有的消息）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.put(PropertyKeyConst.GROUP_ID, <span class="string">&quot;GID_jodie_test_1&quot;</span>);</span><br><span class="line">Consumer consumer = ONSFactory.createConsumer(properties);</span><br><span class="line">consumer.subscribe(<span class="string">&quot;jodie_test_B&quot;</span>, <span class="string">&quot;*&quot;</span>, <span class="keyword">new</span> MessageListener() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Action <span class="title">consume</span><span class="params">(Message message, ConsumeContext context)</span> </span>&#123;</span><br><span class="line">        System.out.println(message.getMsgID());</span><br><span class="line">        <span class="keyword">return</span> Action.CommitMessage;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);  </span><br></pre></td></tr></table></figure>

<h4 id="5-2-2-订阅了不同Tag"><a href="#5-2-2-订阅了不同Tag" class="headerlink" title="5.2.2 订阅了不同Tag"></a>5.2.2 订阅了不同Tag</h4><p>该例中的错误在于，同一个消费者组中的两个Consumer订阅了相同Topic的不同Tag。</p>
<p>Consumer实例2-1：（订阅了topic为jodie_test_A，tag为TagA的消息）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.put(PropertyKeyConst.GROUP_ID, <span class="string">&quot;GID_jodie_test_2&quot;</span>);</span><br><span class="line">Consumer consumer = ONSFactory.createConsumer(properties);</span><br><span class="line">consumer.subscribe(<span class="string">&quot;jodie_test_A&quot;</span>, <span class="string">&quot;TagA&quot;</span>, <span class="keyword">new</span> MessageListener() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Action <span class="title">consume</span><span class="params">(Message message, ConsumeContext context)</span> </span>&#123;</span><br><span class="line">        System.out.println(message.getMsgID());</span><br><span class="line">        <span class="keyword">return</span> Action.CommitMessage;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);  </span><br></pre></td></tr></table></figure>

<p>Consumer实例2-2：（订阅了topic为jodie_test_A，tag为所有的消息）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.put(PropertyKeyConst.GROUP_ID, <span class="string">&quot;GID_jodie_test_2&quot;</span>);</span><br><span class="line">Consumer consumer = ONSFactory.createConsumer(properties);</span><br><span class="line">consumer.subscribe(<span class="string">&quot;jodie_test_A&quot;</span>, <span class="string">&quot;*&quot;</span>, <span class="keyword">new</span> MessageListener() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Action <span class="title">consume</span><span class="params">(Message message, ConsumeContext context)</span> </span>&#123;</span><br><span class="line">        System.out.println(message.getMsgID());</span><br><span class="line">        <span class="keyword">return</span> Action.CommitMessage;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h4 id="5-2-3-订阅了不同数量的Topic"><a href="#5-2-3-订阅了不同数量的Topic" class="headerlink" title="5.2.3 订阅了不同数量的Topic"></a>5.2.3 订阅了不同数量的Topic</h4><p>该例中的错误在于，同一个消费者组中的两个Consumer订阅了不同数量的Topic。</p>
<p>Consumer实例3-1：（该Consumer订阅了两个Topic）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.put(PropertyKeyConst.GROUP_ID, <span class="string">&quot;GID_jodie_test_3&quot;</span>);</span><br><span class="line">Consumer consumer = ONSFactory.createConsumer(properties);</span><br><span class="line">consumer.subscribe(<span class="string">&quot;jodie_test_A&quot;</span>, <span class="string">&quot;TagA&quot;</span>, <span class="keyword">new</span> MessageListener() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Action <span class="title">consume</span><span class="params">(Message message, ConsumeContext context)</span> </span>&#123;</span><br><span class="line">        System.out.println(message.getMsgID());</span><br><span class="line">        <span class="keyword">return</span> Action.CommitMessage;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">consumer.subscribe(<span class="string">&quot;jodie_test_B&quot;</span>, <span class="string">&quot;TagB&quot;</span>, <span class="keyword">new</span> MessageListener() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Action <span class="title">consume</span><span class="params">(Message message, ConsumeContext context)</span> </span>&#123;</span><br><span class="line">        System.out.println(message.getMsgID());</span><br><span class="line">        <span class="keyword">return</span> Action.CommitMessage;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>Consumer实例3-2：（该Consumer订阅了一个Topic）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.put(PropertyKeyConst.GROUP_ID, <span class="string">&quot;GID_jodie_test_3&quot;</span>);</span><br><span class="line">Consumer consumer = ONSFactory.createConsumer(properties);</span><br><span class="line">consumer.subscribe(<span class="string">&quot;jodie_test_A&quot;</span>, <span class="string">&quot;TagB&quot;</span>, <span class="keyword">new</span> MessageListener() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Action <span class="title">consume</span><span class="params">(Message message, ConsumeContext context)</span> </span>&#123;</span><br><span class="line">        System.out.println(message.getMsgID());</span><br><span class="line">        <span class="keyword">return</span> Action.CommitMessage;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;); </span><br></pre></td></tr></table></figure>

<h2 id="六、offset管理"><a href="#六、offset管理" class="headerlink" title="六、offset管理"></a>六、offset管理</h2><blockquote>
<p>这里的offset指的是<code>Consumer的消费进度offset</code>。</p>
</blockquote>
<p>消费进度offset是用来记录每个Queue的不同消费组的消费进度的。根据消费进度记录器的不同，可以分为两种模式：<code>本地模式</code>和<code>远程模式</code>。</p>
<h3 id="6-1-offset本地管理模式"><a href="#6-1-offset本地管理模式" class="headerlink" title="6.1 offset本地管理模式"></a>6.1 offset本地管理模式</h3><p>当消费模式为<code>广播消费</code>时，offset使用<code>本地模式存储</code>。因为每条消息会被所有的消费者消费，每个消费者管理自己的消费进度，各个消费者之间不存在消费进度的交集。<em>所以每个消费者都将消费进度记录在自己本地。</em></p>
<p>Consumer在广播消费模式下offset相关数据以json的形式持久化到<code>Consumer本地磁盘文件</code>中，默认文件路径为当前用户主目录下的.rocketmq_offsets/${clientId}/${group}/Offsets.json。其中clientId为当前消费者id ， 默认为ip@DEAFAULT； {clientId}为当前消费者id，默认为ip@DEFAULT；clientId为当前消费者id，默认为ip@DEFAULT；{group}为消费者组名称。</p>
<h3 id="6-2-offset远程管理模式"><a href="#6-2-offset远程管理模式" class="headerlink" title="6.2 offset远程管理模式"></a>6.2 offset远程管理模式</h3><p>当消费模式为<code>集群消费</code>时，offset使用<code>远程模式管理</code>。因为所有Cosnumer实例对消息采用的是<code>均衡消费</code>，<code>所有Consumer共享Queue的消费进度</code>。消费进度被记录在broker中。</p>
<p>Consumer在集群消费模式下offset相关数据以json的形式持久化到<code>Broker磁盘文件</code>中，文件路径为当前用户主目录下的store/config/consumerOffset.json。</p>
<p>Broker启动时会加载这个文件，并写入到一个双层Map（ConsumerOffsetManager）。外层map的key为topic@group，value为内层map。内层map的key为queueId，value为offset。当发生Rebalance时，新的Consumer会从该Map中获取到相应的数据来继续消费。</p>
<p>集群模式下offset采用远程管理模式，主要是为了保证Rebalance机制，不然新的consumer就无法获取到之前consumer的消费进度。</p>
<h3 id="6-3-offset用途"><a href="#6-3-offset用途" class="headerlink" title="6.3 offset用途"></a>6.3 offset用途</h3><p>消费者是如何从最开始持续消费消息的？消费者要消费的第一条消息的起始位置是用户自己通过consumer.setConsumeFromWhere()方法指定的。在Consumer启动后，其要消费的第一条消息的起始位置常用的有三种，这三种位置可以通过枚举类型常量设置。这个枚举类型为ConsumeFromWhere。</p>
<img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/consumerFromWhere.png" class="">

<blockquote>
<p>CONSUME_FROM_LAST_OFFSET：从queue的当前最后一条消息开始消费</p>
<p>CONSUME_FROM_FIRST_OFFSET：从queue的第一条消息开始消费</p>
<p>CONSUME_FROM_TIMESTAMP：从指定的具体时间戳位置的消息开始消费。这个具体时间戳是通过另外一个语句指定的 。consumer.setConsumeTimestamp(“20210701080000”) yyyyMMddHHmmss</p>
</blockquote>
<p>当消费完一批消息后，Consumer会提交其消费进度offset给Broker，Broker在收到消费进度后会将其更新到那个双层Map（ConsumerOffsetManager）及consumerOffset.json文件中，然后向该Consumer进行ACK，而ACK内容中包含三项数据：当前消费队列的最小offset（minOffset）、最大offset（maxOffset）、及下次消费的起始offset（nextBeginOffset）。</p>
<h3 id="6-4-重试队列"><a href="#6-4-重试队列" class="headerlink" title="6.4 重试队列"></a>6.4 重试队列</h3><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/retry.png" class="">

<p>当rocketMQ对消息的消费出现异常时，会将发生异常的消息的offset提交到Broker中的<code>重试队列</code>。系统在发生消息消费异常时会为当前的topic@group创建一个重试队列，该队列以<code>%RETRY%</code>开头，到达重试时间后进行消费重试。</p>
<h3 id="6-5-offset的同步与异步提交"><a href="#6-5-offset的同步与异步提交" class="headerlink" title="6.5 offset的同步与异步提交"></a>6.5 offset的同步与异步提交</h3><p>集群消费模式下，Consumer消费完消息后会向Broker提交消费进度offset，其提交方式分为两种：</p>
<ul>
<li><p><strong>同步提交</strong></p>
<p>消费者在消费完一批消息后会向broker提交这些消息的offset，然后等待broker的成功响应。若在等待超时之前收到了成功响应，则继续读取下一批消息进行消费（从ACK中获取nextBeginOffset）。若没有收到响应，则会重新提交，直到获取到响应。而在这个等待过程中，消费者是阻塞的。其严重影响了消费者的吞吐量。</p>
</li>
<li><p><strong>异步提交</strong></p>
<p>消费者在消费完一批消息后向broker提交offset，但无需等待Broker的成功响应，可以继续读取并消费下一批消息。这种方式增加了消费者的吞吐量。但需要注意，broker在收到提交的offset后，还是会向消费者进行响应的。可能还没有收到ACK，此时Consumer会从Broker中直接获取nextBeginOffset。</p>
</li>
</ul>
<h2 id="七、消费幂等"><a href="#七、消费幂等" class="headerlink" title="七、消费幂等"></a>七、消费幂等</h2><h3 id="7-1-什么是消费幂等"><a href="#7-1-什么是消费幂等" class="headerlink" title="7.1 什么是消费幂等"></a>7.1 什么是消费幂等</h3><p>当出现消费者对某条消息重复消费的情况时，重复消费的结果与消费一次的结果是相同的，并且多次消费并未对业务系统产生任何负面影响，那么这个消费过程就是消费幂等的。</p>
<blockquote>
<p><strong>幂等</strong>：<code>若某操作执行多次与执行一次对系统产生的影响是相同的，则称该操作是幂等的</code>。</p>
</blockquote>
<p>在互联网应用中，尤其在网络不稳定的情况下，消息很有可能会出现重复发送或重复消费。如果重复的消息可能会影响业务处理，那么就应该对消息做幂等处理。</p>
<h3 id="7-2-消息重复的场景分析"><a href="#7-2-消息重复的场景分析" class="headerlink" title="7.2 消息重复的场景分析"></a>7.2 消息重复的场景分析</h3><p>什么情况下可能会出现消息被重复消费呢？最常见的有以下<code>三种情况</code>：</p>
<ul>
<li><p>发送时消息重复</p>
<p>当一条消息已被成功发送到Broker并完成持久化，此时出现了网络闪断，从而导致Broker对Producer应答失败。 如果此时Producer意识到消息发送失败并尝试再次发送消息，此时Broker中就可能会出现两条内容相同并且Message ID也相同的消息（此时的msgId不是生存的，而是刚才没发送成功是msgId），那么后续Consumer就一定会消费两次该消息。</p>
</li>
<li><p>消费时消息重复</p>
<p>消息已投递到Consumer并完成业务处理，当Consumer给Broker反馈应答时网络闪断，Broker没有接收到消费成功响应。为了保证消息至少被消费一次的原则，Broker将在网络恢复后再次尝试投递之前已被处理过的消息。此时消费者就会收到与之前处理过的内容相同、Message ID也相同的消息。</p>
</li>
<li><p>Rebalance时消息重复</p>
<p>当Consumer Group中的Consumer数量发生变化时，或其订阅的Topic的Queue数量发生变化时，会触发Rebalance，此时Consumer可能会收到曾经被消费过的消息。</p>
</li>
</ul>
<h3 id="7-3-通用解决方案"><a href="#7-3-通用解决方案" class="headerlink" title="7.3 通用解决方案"></a>7.3 通用解决方案</h3><ul>
<li><p>两要素</p>
<p>幂等解决方案的设计中涉及到两项要素：<em>幂等令牌</em>，与 <em>唯一性处理</em>。只要充分利用好这两要素，就可以设计出好的幂等解决方案。</p>
<ul>
<li><code>幂等令牌</code>：是生产者和消费者两者中的既定协议，通常指具备<code>唯⼀业务标识的字符串</code>。例如，订单号、流水号。一般由Producer随着消息一同发送来的。</li>
<li><code>唯一性处理</code>：服务端通过采用⼀定的算法策略，保证同⼀个业务逻辑不会被重复执行成功多次。例如，对同一笔订单的多次支付操作，只会成功一次。</li>
</ul>
</li>
<li><p>解决方案</p>
<p>对于常见的系统，幂等性操作的通用性解决方案是：</p>
<ol>
<li><p>首先通过缓存去重。在缓存中如果已经存在了某幂等令牌，则说明本次操作是重复性操作；若缓存没有命中，则进入下一步。</p>
</li>
<li><p>在唯一性处理之前，先在数据库中查询幂等令牌作为索引的数据是否存在。若存在，则说明本次操作为重复性操作；若不存在，则进入下一步。</p>
</li>
<li><p>在同一事务中完成三项操作：唯一性处理后，将幂等令牌写入到缓存，并将幂等令牌作为唯一索引的数据写入到DB中。</p>
</li>
</ol>
<blockquote>
<p>第1步已经判断过是否是重复性操作了，为什么第2步还要再次判断？能够进入第2步，说明已经不是重复操作了，第2次判断是否重复？</p>
<p>当然不重复。一般<code>缓存中的数据是具有有效期</code>的。缓存中数据的有效期一旦过期，就是发生缓存穿透，使请求直接就到达了DBMS。<code>减轻DB的压力</code></p>
</blockquote>
</li>
</ul>
<h3 id="7-4-解决方案举例"><a href="#7-4-解决方案举例" class="headerlink" title="7.4 解决方案举例"></a>7.4 解决方案举例</h3><p>以支付场景为例：</p>
<ol>
<li><p>当支付请求到达后，首先在Redis缓存中却获取key为支付流水号的缓存value。</p>
<p>若value不空，则说明本次支付是重复操作，业务系统直接返回调用侧重复支付标识；</p>
<p>若value为空，则进入下一步操作</p>
</li>
<li><p>到DBMS中根据支付流水号查询是否存在相应实例。</p>
<p>若存在，则说明本次支付是重复操作，业务系统直接返回调用侧重复支付标识；</p>
<p>若不存在，则说明本次操作是首次操作，进入下一步完成唯一性处理</p>
</li>
<li><p>在分布式事务中完成【唯一性处理】三项操作：</p>
<ol>
<li>完成支付任务</li>
<li>将当前支付流水号作为key，任意字符串作为value，通过set(key, value, expireTime)将数据写入到Redis缓存</li>
<li>将当前支付流水号作为主键，与其它相关数据共同写入到DBMS</li>
</ol>
</li>
</ol>
<h3 id="7-5-消费幂等的实现"><a href="#7-5-消费幂等的实现" class="headerlink" title="7.5 消费幂等的实现"></a>7.5 消费幂等的实现</h3><p>消费幂等的解决方案很简单：为消息指定不会重复的唯一标识。因为Message ID有可能出现重复的情况，所以真正安全的幂等处理，不建议以Message ID作为处理依据。最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息Key设置。以支付场景为例，可以将消息的Key设置为订单号，作为幂等处理的依据。具体代码示例如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Message message = <span class="keyword">new</span> Message();</span><br><span class="line">message.setKey(<span class="string">&quot;ORDERID_100&quot;</span>);<span class="comment">//唯一订单号</span></span><br><span class="line">SendResult sendResult = producer.send(message);</span><br></pre></td></tr></table></figure>

<p>消费者收到消息时可以根据消息的Key即订单号来实现消费幂等：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs,ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(MessageExt msg:msgs)&#123;</span><br><span class="line">            String key = msg.getKeys();</span><br><span class="line">            <span class="comment">// 根据业务唯一标识Key做幂等处理</span></span><br><span class="line">            <span class="comment">// ……</span></span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="comment">//返回处理成功响应</span></span><br><span class="line">        <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>RocketMQ能够保证消息不丢失，但不能保证消息不重复。</p>
</blockquote>
<h2 id="八、消息堆积与消费延迟"><a href="#八、消息堆积与消费延迟" class="headerlink" title="八、消息堆积与消费延迟"></a>八、消息堆积与消费延迟</h2><h3 id="8-1-概念"><a href="#8-1-概念" class="headerlink" title="8.1 概念"></a>8.1 概念</h3><p>消息处理流程中，如果Consumer的消费速度跟不上Producer的发送速度，MQ中未处理的消息会越来越多（<code>进的多出的少</code>），这部分消息就被称为<code>堆积消息</code>。消息出现堆积进而会造成消息的<code>消费延迟</code>。</p>
<p>以下场景需要重点关注消息堆积和消费延迟问题：</p>
<ul>
<li><code>业务系统上下游能力不匹配</code>造成的持续堆积，且无法自行恢复。</li>
<li>业务系统对消息的<code>消费实时性要求较高</code>，即使是短暂的堆积造成的消费延迟也无法接受。</li>
</ul>
<h3 id="8-2-产生原因分析"><a href="#8-2-产生原因分析" class="headerlink" title="8.2 产生原因分析"></a>8.2 产生原因分析</h3><img src="/2022/01/19/RocketMQ%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/delay.png" class="">

<p>Consumer使用<code>长轮询Pull模式</code>消费消息时，分为以下两个阶段：</p>
<h4 id="8-2-1-消息拉取"><a href="#8-2-1-消息拉取" class="headerlink" title="8.2.1 消息拉取"></a>8.2.1 消息拉取</h4><p>Consumer通过长轮询Pull模式批量拉取的方式从服务端获取消息，将拉取到的消息缓存到本地缓冲队列中。对于拉取式消费，在内网环境下会有很高的吞吐量，所以这一阶段一般不会成为消息堆积的瓶颈。</p>
<blockquote>
<p><em>一个单线程单分区的低规格主机(Consumer，4C8G)，其可达到几万的TPS。</em></p>
<p>*<em>如果是多个分区多个线程，则可以轻松达到几十万的TPS。</em></p>
</blockquote>
<h4 id="8-2-2-消息消费"><a href="#8-2-2-消息消费" class="headerlink" title="8.2.2 消息消费"></a>8.2.2 消息消费</h4><p>Consumer将本地缓存的消息提交到消费线程中，使用业务消费逻辑对消息进行处理，处理完毕后获取到一个结果。这是真正的消息消费过程。</p>
<p>此时Consumer的消费能力就完全依赖于消息的消费耗时和消费并发度了。如果由于业务处理逻辑复杂等原因，导致处理单条消息的耗时较长，则整体的消息吞吐量肯定不会高，此时就会导致Consumer本地缓冲队列达到上限，停止从服务端拉取消息。</p>
<p><strong>结论</strong></p>
<p>消息堆积的主要瓶颈在于<code>客户端的消费能力</code>，而消费能力由<code>消费耗时和消费并发度</code>决定。注意，消费耗时的优先级要高于消费并发度。即在保证了消费耗时的合理性前提下，再考虑消费并发度问题。</p>
<h3 id="8-3-消费耗时"><a href="#8-3-消费耗时" class="headerlink" title="8.3 消费耗时"></a>8.3 消费耗时</h3><p>影响消息处理时长的主要因素是<code>代码逻辑</code>。</p>
<p>代码逻辑中可能会影响处理时长代码主要有两种类型：</p>
<ul>
<li>CPU内部计算型代码</li>
<li>外部I/O操作型代码。</li>
</ul>
<p>通常情况下代码中如果没有复杂的递归和循环的话，内部计算耗时相对外部I/O操作来说几乎可以忽略。所以外部IO型代码是影响消息处理时长的主要症结所在。</p>
<blockquote>
<p>外部IO操作型代码举例：</p>
<p>读写外部数据库，例如对远程MySQL的访问</p>
<p>读写外部缓存系统，例如对远程Redis的访问</p>
<p>下游系统调用，例如Dubbo的RPC远程调用，Spring Cloud的对下游系统的Http接口调用</p>
</blockquote>
<blockquote>
<p>关于下游系统调用逻辑需要进行提前梳理，掌握每个调用操作预期的耗时，这样做是为了能够判断消费逻辑中IO操作的耗时是否合理。</p>
<p>通常消息堆积是由于下游系统出现了 服务异常 或达到了DBMS容量限制 ，导致消费耗时增加。</p>
<ul>
<li><p>服务异常，并不仅仅是系统中出现的类似500这样的代码错误，而可能是更加隐蔽的问题。例如，网络带宽问题。</p>
</li>
<li><p>达到了DBMS容量限制，其也会引发消息的消费耗时增加。只能去提升DBMS的容量</p>
</li>
</ul>
</blockquote>
<h3 id="8-4-消费并发度"><a href="#8-4-消费并发度" class="headerlink" title="8.4 消费并发度"></a>8.4 消费并发度</h3><p>一般情况下，消费者端的消费并发度由单节点线程数和节点数量共同决定，其值为<code>单节点线程数*节点数量</code>。不过，通常需要优先调整单节点的线程数，若单机硬件资源达到了上限，则需要通过横向扩展增加节点数量（consumer数量）来提高消费并发度。</p>
<blockquote>
<p>单节点线程数，即单个Consumer所包含的线程数量</p>
<p>节点数量，即Consumer Group所包含的Consumer数量</p>
</blockquote>
<blockquote>
<p>对于普通消息、延时消息及事务消息，并发度计算都是单节点线程数*节点数量。</p>
<p>但对于顺序消息则是不同的。顺序消息的消费并发度等于Topic的Queue分区数量。</p>
<p>1）全局顺序消息：该类型消息的Topic只有一个Queue分区。其可以保证该Topic的所有消息被顺序消费。为了保证这个全局顺序性，Consumer Group中在同一时刻只能有一个Consumer的一个线程进行消费。所以其并发度为1。</p>
<p>2）分区顺序消息：该类型消息的Topic有多个Queue分区。其仅可以保证该Topic的每个Queue分区中的消息被顺序消费，不能保证整个Topic中消息的顺序消费。为了保证这个分区顺序性，每个Queue分区中的消息在Consumer Group中的同一时刻只能有一个Consumer的一个线程进行消费。即，在同一时刻最多会出现多个Queue分蘖有多个Consumer的多个线程并行消费。所以其并发度为Topic的分区数量`。</p>
</blockquote>
<h3 id="8-5-单机线程数计算"><a href="#8-5-单机线程数计算" class="headerlink" title="8.5 单机线程数计算"></a>8.5 单机线程数计算</h3><p>对于一台主机中线程池中线程数的设置需要谨慎，不能盲目直接调大线程数，设置过大的线程数反而会带来大量的线程切换的开销。理想环境下单节点的最优线程数计算模型为：<code>C *（T1 + T2）/ T1</code>。</p>
<ul>
<li>C：CPU内核数</li>
<li>T1：CPU内部逻辑计算耗时</li>
<li>T2：外部IO操作耗时</li>
</ul>
<blockquote>
<p>最优线程数 = C *（T1 + T2）/ T1 = C * T1/T1 + C * T2/T1 = C + C * T2/T1</p>
<p>如果C=3，T1=1，T2=9；那上面的计算结果为30线程</p>
<p>30代表，三个核心每个核心10个线程，t1用1个线程，t2用9个线程</p>
</blockquote>
<blockquote>
<p>注意，该计算出的数值是理想状态下的理论数据，<em>在生产环境中，不建议直接使用</em>。<em>而是根据当前环境，<code>先设置一个比该值小的数值然后观察其压测效果</code>，然后<code>再根据效果逐步调大线程数，直至找到在该环境中性能最佳时的值</code>。</em></p>
</blockquote>
<h3 id="8-5-如何避免"><a href="#8-5-如何避免" class="headerlink" title="8.5 如何避免"></a>8.5 如何避免</h3><p>为了避免在业务使用时出现非预期的消息堆积和消费延迟问题，需要在前期设计阶段对整个业务逻辑进行完善的排查和梳理。其中最重要的就是<code>梳理消息的消费耗时</code>和<code>设置消息消费的并发度</code>。</p>
<h4 id="8-5-1-梳理消息的消费耗时"><a href="#8-5-1-梳理消息的消费耗时" class="headerlink" title="8.5.1 梳理消息的消费耗时"></a>8.5.1 梳理消息的消费耗时</h4><p>通过压测获取消息的消费耗时，并对耗时较高的操作的代码逻辑进行分析。梳理消息的消费耗时需要关注以下信息：</p>
<ul>
<li>消息消费逻辑的计算复杂度是否过高，代码是否存在无限循环和递归等缺陷。</li>
<li>消息消费逻辑中的I/O操作是否是必须的，能否用本地缓存等方案规避。</li>
<li>消费逻辑中的复杂耗时的操作是否可以做异步化处理。如果可以，是否会造成逻辑错乱。</li>
</ul>
<h4 id="8-5-2-设置消费并发度"><a href="#8-5-2-设置消费并发度" class="headerlink" title="8.5.2 设置消费并发度"></a>8.5.2 设置消费并发度</h4><p>对于消息消费并发度的计算，可以通过以下两步实施：</p>
<ul>
<li>逐步调大单个Consumer节点的线程数，并观测节点的系统指标，得到单个节点最优的消费线程数和消息吞吐量。</li>
<li>根据上下游链路的<code>流量峰值</code>计算出需要设置的节点数</li>
</ul>
<blockquote>
<p>节点数 = 流量峰值 / 单个节点消息吞吐量</p>
</blockquote>
<h2 id="九、消息清理"><a href="#九、消息清理" class="headerlink" title="九、消息清理"></a>九、消息清理</h2><p>消息被消费过后会被清理掉吗？不会的。</p>
<p>消息是被顺序存储在commitlog文件的，且消息大小不定长，所以消息的清理是不可能以消息为单位进行清理的，而是以commitlog文件为单位进行清理的。否则会急剧下降清理效率，并实现逻辑复杂。</p>
<p>commitlog文件存在一个过期时间，默认为72小时，即三天。除了用户手动清理外，在以下情况下也会被自动清理，无论文件中的消息是否被消费过：</p>
<ul>
<li>文件过期，且到达清理时间点（默认为凌晨4点）后，自动清理过期文件</li>
<li>文件过期，且磁盘空间占用率已达过期清理警戒线（默认75%）后，无论是否达到清理时间点，都会自动清理过期文件</li>
<li>磁盘占用率达到清理警戒线（默认85%）后，开始按照设定好的规则清理文件，无论是否过期。默认会从最老的文件开始清理</li>
<li>磁盘占用率达到系统危险警戒线（默认90%）后，Broker将拒绝消息写入</li>
</ul>
<blockquote>
<p>需要注意以下几点：</p>
<p>1）对于RocketMQ系统来说，删除一个1G大小的文件，是一个压力巨大的IO操作。在删除过程中，系统性能会骤然下降。所以，其默认清理时间点为凌晨4点，访问量最小的时间。也正因如果，我们要保障磁盘空间的空闲率，不要使系统出现在其它时间点删除commitlog文件的情况。</p>
<p>2）官方建议RocketMQ服务的Linux文件系统采用ext4。因为对于文件删除操作，ext4要比ext3性能更好</p>
</blockquote>
]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ应用</title>
    <url>/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<h2 id="一、普通消息"><a href="#一、普通消息" class="headerlink" title="一、普通消息"></a>一、普通消息</h2><h3 id="1-1-消息发送分类"><a href="#1-1-消息发送分类" class="headerlink" title="1.1 消息发送分类"></a>1.1 消息发送分类</h3><p>Producer对于消息的发送方式也有多种选择，不同的方式会产生不同的系统效果。</p>
<h4 id="1-1-1-同步发送消息"><a href="#1-1-1-同步发送消息" class="headerlink" title="1.1.1 同步发送消息"></a>1.1.1 同步发送消息</h4><p>同步发送消息是指，Producer发出⼀条消息后，会在收到MQ返回的ACK之后才发下⼀条消息。该方式的消息可靠性最高，但消息发送效率太低。</p>
<span id="more"></span>

<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/synchronization.png" class="">

<h4 id="1-1-2-异步发送消息"><a href="#1-1-2-异步发送消息" class="headerlink" title="1.1.2 异步发送消息"></a>1.1.2 异步发送消息</h4><p>异步发送消息是指，Producer发出消息后无需等待MQ返回ACK，直接发送下⼀条消息。该方式的消息可靠性可以得到保障，消息发送效率也可以。</p>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/asynchronous.png" class="">

<h4 id="1-1-3-单项发送消息"><a href="#1-1-3-单项发送消息" class="headerlink" title="1.1.3 单项发送消息"></a>1.1.3 单项发送消息</h4><p>单向发送消息是指，Producer仅负责发送消息，不等待、不处理MQ的ACK。该发送方式时MQ也不返回ACK。该方式的消息发送效率最高，但消息可靠性较差。</p>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/single.png" class="">

<h3 id="1-2-代码举例"><a href="#1-2-代码举例" class="headerlink" title="1.2 代码举例"></a>1.2 代码举例</h3><p>消息发送的状态</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 消息发送的状态</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">SendStatus</span> </span>&#123;</span><br><span class="line">    SEND_OK,       <span class="comment">// 发送成功</span></span><br><span class="line">    FLUSH_DISK_TIMEOUT,  <span class="comment">// 刷盘超时。当Broker设置的刷盘策略为同步刷盘时才可能出现这种异常状态。异步刷盘不会出现</span></span><br><span class="line">    FLUSH_SLAVE_TIMEOUT, <span class="comment">// Slave同步超时。当Broker集群设置的Master-Slave的复制方式为同步复制时才可能出现这种异常状态。异步复制不会出现</span></span><br><span class="line">    SLAVE_NOT_AVAILABLE, <span class="comment">// 没有可用的Slave。当Broker集群设置为Master-Slave的复制方式为同步复制时才可能出现这种异常状态。异步复制不会出现</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="1-2-1-同步消息发送"><a href="#1-2-1-同步消息发送" class="headerlink" title="1.2.1 同步消息发送"></a>1.2.1 同步消息发送</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SyncProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 创建一个producer，参数为Producer Group名称</span></span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定nameServer地址</span></span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        <span class="comment">// 设置当发送失败时重试发送的次数，默认为2次</span></span><br><span class="line">        producer.setRetryTimesWhenSendFailed(<span class="number">3</span>);</span><br><span class="line">        <span class="comment">// 设置发送超时时限为5s，默认3s</span></span><br><span class="line">        producer.setSendMsgTimeout(<span class="number">5000</span>);</span><br><span class="line">        <span class="comment">// 开启生产者</span></span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="comment">// 生产并发送100条消息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] body = (<span class="string">&quot;Hi,&quot;</span> + i).getBytes();</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;someTopic&quot;</span>, <span class="string">&quot;someTag&quot;</span>, body);</span><br><span class="line">            <span class="comment">// 为消息指定key</span></span><br><span class="line">            msg.setKeys(<span class="string">&quot;key-&quot;</span> + i);</span><br><span class="line">            <span class="comment">// 发送消息</span></span><br><span class="line">            SendResult sendResult = producer.send(msg);</span><br><span class="line">            System.out.println(sendResult);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 关闭producer</span></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="1-2-2-异步消息发送"><a href="#1-2-2-异步消息发送" class="headerlink" title="1.2.2 异步消息发送"></a>1.2.2 异步消息发送</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AsyncProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定异步发送失败后不进行重试发送</span></span><br><span class="line">        producer.setRetryTimesWhenSendAsyncFailed(<span class="number">0</span>);</span><br><span class="line">        <span class="comment">// 指定新创建的Topic的Queue数量为2，默认为4</span></span><br><span class="line">        producer.setDefaultTopicQueueNums(<span class="number">2</span>);</span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] body = (<span class="string">&quot;Hi,&quot;</span> + i).getBytes();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;myTopicA&quot;</span>, <span class="string">&quot;myTag&quot;</span>, body);</span><br><span class="line">                <span class="comment">// 异步发送。指定回调</span></span><br><span class="line">                producer.send(msg, <span class="keyword">new</span> SendCallback() &#123;</span><br><span class="line">                    <span class="comment">// 当producer接收到MQ发送来的ACK后就会触发该回调方法的执行</span></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(SendResult sendResult)</span> </span>&#123;</span><br><span class="line">                        System.out.println(sendResult);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onException</span><span class="params">(Throwable e)</span> </span>&#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="comment">// end-for</span></span><br><span class="line">        <span class="comment">// sleep一会儿</span></span><br><span class="line">        <span class="comment">// 由于采用的是异步发送，所以若这里不sleep，</span></span><br><span class="line">        <span class="comment">// 则消息还未发送就会将producer给关闭，报错</span></span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">3</span>);</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="1-2-3-单向消息发送"><a href="#1-2-3-单向消息发送" class="headerlink" title="1.2.3 单向消息发送"></a>1.2.3 单向消息发送</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OnewayProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] body = (<span class="string">&quot;Hi,&quot;</span> + i).getBytes();</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;single&quot;</span>, <span class="string">&quot;someTag&quot;</span>, body);</span><br><span class="line">            <span class="comment">// 单向发送</span></span><br><span class="line">            producer.sendOneway(msg);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">        System.out.println(<span class="string">&quot;producer shutdown&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="1-2-4-定义消息消费者"><a href="#1-2-4-定义消息消费者" class="headerlink" title="1.2.4 定义消息消费者"></a>1.2.4 定义消息消费者</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SomeConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">        <span class="comment">// 定义一个pull消费者</span></span><br><span class="line">        <span class="comment">// DefaultLitePullConsumer consumer = new DefaultLitePullConsumer(&quot;cg&quot;);</span></span><br><span class="line">        <span class="comment">// 定义一个push消费者</span></span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;cg&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定nameServer</span></span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定从第一条消息开始消费</span></span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line">        <span class="comment">// 指定消费topic与tag</span></span><br><span class="line">        consumer.subscribe(<span class="string">&quot;someTopic&quot;</span>, <span class="string">&quot;*&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定采用“广播模式”进行消费，默认为“集群模式”</span></span><br><span class="line">        <span class="comment">// consumer.setMessageModel(MessageModel.BROADCASTING);</span></span><br><span class="line">        <span class="comment">// 注册消息监听器</span></span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">            <span class="comment">// 一旦broker中有了其订阅的消息就会触发该方法的执行，</span></span><br><span class="line">            <span class="comment">// 其返回值为当前consumer消费的状态</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus</span></span><br><span class="line"><span class="function">                <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs,ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">                <span class="comment">// 逐条消费消息</span></span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : msgs) &#123;</span><br><span class="line">                    System.out.println(msg);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 返回消费状态：消费成功</span></span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 开启消费者消费</span></span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.println(<span class="string">&quot;Consumer Started&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="二、顺序消息"><a href="#二、顺序消息" class="headerlink" title="二、顺序消息"></a>二、顺序消息</h2><h3 id="2-1-什么是顺序消息"><a href="#2-1-什么是顺序消息" class="headerlink" title="2.1 什么是顺序消息"></a>2.1 什么是顺序消息</h3><p>顺序消息指的是，严格按照消息的<code>发送顺序</code>进行<code>消费</code>的消息(FIFO)。</p>
<p>默认情况下生产者会把消息以Round Robin轮询方式发送到不同的Queue分区队列；而消费消息时会从多个Queue上拉取消息，这种情况下的发送和消费是不能保证顺序的。如果将消息仅发送到同一个Queue中，消费时也只从这个Queue上拉取消息，就严格保证了消息的顺序性。</p>
<h3 id="2-2-为什么需要顺序消息"><a href="#2-2-为什么需要顺序消息" class="headerlink" title="2.2 为什么需要顺序消息"></a>2.2 为什么需要顺序消息</h3><p>例如，现在有TOPIC ORDER_STATUS(订单状态)，其下有4个Queue队列，该Topic中的不同消息用于描述当前订单的不同状态。假设订单有状态：未支付、已支付、发货中、发货成功、发货失败。</p>
<p>根据以上订单状态，生产者从时序上可以生成如下几个消息：</p>
<p>订单T0000001:未支付 –&gt; 订单T0000001:已支付 –&gt; 订单T0000001:发货中 –&gt; 订单T0000001:发货失败消息发送到MQ中之后，Queue的选择如果采用轮询策略，消息在MQ的存储可能如下：</p>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/topic_sale_order.png" class="">

<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/notice_order.png" class="">

<p>这种情况下，我们希望Consumer消费消息的顺序和我们发送是一致的，然而上述MQ的投递和消费方式，我们无法保证顺序是正确的。对于顺序异常的消息，Consumer即使设置有一定的状态容错，也不能完全处理好这么多种随机出现组合情况。</p>


<p>基于上述的情况，可以设计如下方案：对于<code>相同订单号</code>的消息，通过<code>一定的策略</code>，将其放置在<code>一个Queue中</code>，然后<code>消费者再采用一定的策略</code>（例如，一个线程独立处理一个queue，保证处理消息的顺序性），能够保证消费的<code>顺序性</code>。</p>
<h3 id="2-3-有序性分类"><a href="#2-3-有序性分类" class="headerlink" title="2.3 有序性分类"></a>2.3 有序性分类</h3><p>根据有序范围的不同，RocketMQ可以严格地保证两种消息的有序性：<code>分区有序</code>与<code>全局有序</code>。</p>
<h4 id="2-3-1-全局有序"><a href="#2-3-1-全局有序" class="headerlink" title="2.3.1 全局有序"></a>2.3.1 全局有序</h4><img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/global_sequence.png" class="">

<p>当发送和消费参与的<code>Queue只有一个</code>时所保证的有序是整个Topic中消息的顺序， 称为<code>全局有序</code>。</p>
<blockquote>
<p>在创建Topic时指定Queue的数量。有三种指定方式：</p>
<p>1）在代码中创建Producer时，可以指定其自动创建的Topic的Queue数量</p>
<p>2）在RocketMQ可视化控制台中手动创建Topic时指定Queue数量</p>
<p>3）使用mqadmin命令手动创建Topic时指定Queue数量</p>
</blockquote>
<h4 id="2-3-2-分区有序"><a href="#2-3-2-分区有序" class="headerlink" title="2.3.2 分区有序"></a>2.3.2 分区有序</h4><img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/local_sequence.png" class="">

<p>如果有<code>多个Queue</code>参与，其仅可保证在该Queue分区队列上的消息顺序，则称为<code>分区有序</code>。</p>
<blockquote>
<p><strong>如何实现Queue的选择？</strong></p>
<p>在定义Producer时我们可以指定消息队列选择器，而这个选择器是我们自己实现了MessageQueueSelector接口定义的。</p>
<p>在定义选择器的选择算法时，一般需要使用选择key。这个选择key可以是消息key也可以是其它数据。但无论谁做选择key，都不能重复，都是唯一的。</p>
<p>一般性的选择算法是，让选择key（或其hash值）与该Topic所包含的Queue的数量取模，其结果即为选择出的Queue的QueueId。</p>
<p>取模算法存在一个问题：不同选择key与Queue数量取模结果可能会是相同的，即不同选择key的消息可能会出现在相同的Queue，即同一个Consuemr可能会消费到不同选择key的消息。</p>
<p>这个问题如何解决？一般性的作法是，从消息中获取到选择key，对其进行判断。若是当前Consumer需要消费的消息，则直接消费，否则，什么也不做。这种做法要求选择key要能够随着消息一起被Consumer获取到。此时使用消息key作为选择key是比较好的做法。</p>
<p>以上做法会不会出现如下新的问题呢？不属于那个Consumer的消息被拉取走了，那么应该消费该消息的Consumer是否还能再消费该消息呢？同一个Queue中的消息不可能被同一个Group中的不同Consumer同时消费。所以，消费现一个Queue的不同选择key的消息的Consumer一定属于不同的Group。而不同的Group中的Consumer间的消费是相互隔离的，互不影响的。</p>
</blockquote>
<h3 id="2-4-代码举例"><a href="#2-4-代码举例" class="headerlink" title="2.4 代码举例"></a>2.4 代码举例</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderedProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">            Integer orderId = i;</span><br><span class="line">            <span class="keyword">byte</span>[] body = (<span class="string">&quot;Hi,&quot;</span> + i).getBytes();</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;TopicA&quot;</span>, <span class="string">&quot;TagA&quot;</span>, body);</span><br><span class="line">            SendResult sendResult = producer.send(msg, <span class="keyword">new</span> MessageQueueSelector() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> MessageQueue <span class="title">select</span><span class="params">(List&lt;MessageQueue&gt; mqs,Message msg, Object arg)</span></span>&#123;</span><br><span class="line">                    Integer id = (Integer) arg;</span><br><span class="line">                    <span class="keyword">int</span> index = id % mqs.size();</span><br><span class="line">                    <span class="keyword">return</span> mqs.get(index);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, orderId);</span><br><span class="line">            System.out.println(sendResult);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="三、延时消息"><a href="#三、延时消息" class="headerlink" title="三、延时消息"></a>三、延时消息</h2><h3 id="3-1-什么是延时消息"><a href="#3-1-什么是延时消息" class="headerlink" title="3.1 什么是延时消息"></a>3.1 什么是延时消息</h3><p>当消息写入到Broker后，在指定的时长后才可被消费处理的消息，称为<code>延时消息</code>。</p>
<p>采用RocketMQ的延时消息可以实现<code>定时任务</code>的功能，而无需使用定时器。典型的应用场景是，电商交易中超时未支付关闭订单的场景，12306平台订票超时未支付取消订票的场景。</p>
<blockquote>
<p>在电商平台中，订单创建时会发送一条延迟消息。这条消息将会在30分钟后投递给后台业务系统（Consumer），后台业务系统收到该消息后会判断对应的订单是否已经完成支付。如果未完成，则取消订单，将商品再次放回到库存；如果完成支付，则忽略。</p>
<p>在12306平台中，车票预订成功后就会发送一条延迟消息。这条消息将会在45分钟后投递给后台业务系统（Consumer），后台业务系统收到该消息后会判断对应的订单是否已经完成支付。如果未完成，则取消预订，将车票再次放回到票池；如果完成支付，则忽略。</p>
</blockquote>
<h3 id="3-2-延时等级"><a href="#3-2-延时等级" class="headerlink" title="3.2 延时等级"></a>3.2 延时等级</h3><p>延时消息的延迟时长<code>不支持随意时长的延迟</code>，是通过特定的延迟等级来指定的。延时等级定义在<code>RocketMQ服务</code>端的<code>MessageStoreConfig类</code>中的如下变量中：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> String messageDelayLevel = <span class="string">&quot;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>即，若指定的延时等级为3，则表示延迟时长为10s，即延迟等级是从1开始计数的。</p>
<p>当然，如果需要自定义的延时等级，可以通过在broker加载的配置中新增如下配置（例如下面增加了1天这个等级1d）。配置文件在RocketMQ安装目录下的conf目录中。</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">messageDelayLevel</span> = <span class="string">1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 1d</span></span><br></pre></td></tr></table></figure>

<h3 id="3-3-延时消息实现原理"><a href="#3-3-延时消息实现原理" class="headerlink" title="3.3 延时消息实现原理"></a>3.3 延时消息实现原理</h3><img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/delayMessage.png" class="">

<p>具体实现方案是:</p>
<p><strong>修改消息</strong></p>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/delayMessage1.png" class="">

<p>Producer将消息发送到Broker后，Broker会首先将消息写入到commitlog文件，然后需要将其分发到相应的consumequeue。不过，在分发之前，系统会先判断消息中是否带有延时等级。若没有，则直接正常分发；若有则需要经历一个复杂的过程：</p>
<ul>
<li><p>修改消息的Topic为SCHEDULE_TOPIC_XXXX</p>
</li>
<li><p>根据延时等级，在consumequeue目录中SCHEDULE_TOPIC_XXXX主题下创建出相应的queueId</p>
<ul>
<li><p>延迟等级delayLevel与queueId的对应关系为queueId = delayLevel -1</p>
<p>需要注意，在创建queueId目录时，并<code>不是一次性地将所有延迟等级对应的目录全部创建完毕</code>，而是<code>用到哪个延迟等级创建哪个目录</code></p>
</li>
</ul>
</li>
<li><p>修改消息索引单元内容。索引单元中的Message Tag HashCode部分原本存放的是消息的Tag的Hash值。现修改为消息的投递时间。投递时间是指该消息被重新修改为原Topic后再次被写入到commitlog中的时间。投递时间 = 消息存储时间 + 延时等级时间。消息存储时间指的是消息被发送到Broker时的时间戳。</p>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/delayMessage2.png" class=""></li>
<li><p>将消息索引写入到SCHEDULE_TOPIC_XXXX主题下相应的consumequeue中</p>
<ul>
<li>SCHEDULE_TOPIC_XXXX目录中各个延时等级Queue中的消息是如何排序的？<br>是按照消息投递时间排序的。一个Broker中同一等级的所有延时消息会被写入到consumequeue目录中SCHEDULE_TOPIC_XXXX目录下相同Queue中。即一个Queue中消息投递时间的延迟等级时间是相同的。那么投递时间就取决于于消息存储时间了。即按照消息被发送到Broker的时间进行排序的。</li>
</ul>
</li>
<li><p>投递延时消息</p>
<ul>
<li><p>Broker内部有⼀个延迟消息服务类ScheuleMessageService，其会消费SCHEDULE_TOPIC_XXXX中的消息，即按照每条消息的投递时间，将延时消息投递到⽬标Topic中。不过，在投递之前会从commitlog中将原来写入的消息再次读出，并将其原来的延时等级设置为0，即原消息变为了一条不延迟的普通消息。然后再次将消息投递到目标Topic中。</p>
<blockquote>
<p>ScheuleMessageService在Broker启动时，会创建并启动一个定时器TImer，用于执行相应的定时任务。系统会根据延时等级的个数，定义相应数量的TimerTask，每个TimerTask负责一个延迟等级消息的消费与投递。每个TimerTask都会检测相应Queue队列的第一条消息是否到期。若第一条消息未到期，则后面的所有消息更不会到期（消息是按照投递时间排序的）；若第一条消息到期了，则将该消息投递到目标Topic，即消费该消息。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>将消息重新写入commitlog</p>
<ul>
<li>延迟消息服务类ScheuleMessageService将延迟消息再次发送给了commitlog，并再次形成新的消息索引条目，分发到相应Queue。</li>
</ul>
</li>
</ul>
<p>这其实就是一次普通消息发送。只不过这次的消息Producer是延迟消息服务类ScheuleMessageService。</p>
<h3 id="3-4-代码举例"><a href="#3-4-代码举例" class="headerlink" title="3.4 代码举例"></a>3.4 代码举例</h3><ul>
<li><p><strong>定义DelayProducer类</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DelayProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] body = (<span class="string">&quot;Hi,&quot;</span> + i).getBytes();</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;TopicB&quot;</span>, <span class="string">&quot;someTag&quot;</span>, body);</span><br><span class="line">            <span class="comment">// 指定消息延迟等级为3级，即延迟10s</span></span><br><span class="line">            <span class="comment">// msg.setDelayTimeLevel(3);</span></span><br><span class="line">            SendResult sendResult = producer.send(msg);</span><br><span class="line">            <span class="comment">// 输出消息被发送的时间</span></span><br><span class="line">            System.out.print(<span class="keyword">new</span> SimpleDateFormat(<span class="string">&quot;mm:ss&quot;</span>).format(<span class="keyword">new</span> Date()));</span><br><span class="line">            System.out.println(<span class="string">&quot; ,&quot;</span> + sendResult);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>定义OtherConsumer类</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OtherConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span></span><br><span class="line">            DefaultMQPushConsumer(<span class="string">&quot;cg&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line"></span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET</span><br><span class="line">                                    );</span><br><span class="line">        consumer.subscribe(<span class="string">&quot;TopicB&quot;</span>, <span class="string">&quot;*&quot;</span>);</span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus</span></span><br><span class="line"><span class="function">                <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : msgs) &#123;</span><br><span class="line">                    <span class="comment">// 输出消息被消费的时间</span></span><br><span class="line">                    System.out.print(<span class="keyword">new</span> SimpleDateFormat(<span class="string">&quot;mm:ss&quot;</span>).format(<span class="keyword">new</span> Date()));</span><br><span class="line">                    System.out.println(<span class="string">&quot; ,&quot;</span> + msg);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.println(<span class="string">&quot;Consumer Started&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="四、事务消息"><a href="#四、事务消息" class="headerlink" title="四、事务消息"></a>四、事务消息</h2><h3 id="4-1-问题引入"><a href="#4-1-问题引入" class="headerlink" title="4.1 问题引入"></a>4.1 问题引入</h3><p>这里的一个需求场景是：工行用户A向建行用户B转账1万元。</p>
<p>我们可以使用同步消息来处理该需求场景：</p>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/TransactionMessage.png" class="">

<ol>
<li>工行系统发送一个给B增款1万元的同步消息M给Broker</li>
<li>消息被Broker成功接收后，向工行系统发送成功ACK</li>
<li>工行系统收到成功ACK后从用户A中扣款1万元</li>
<li>建行系统从Broker中获取到消息M</li>
<li>建行系统消费消息M，即向用户B中增加1万元</li>
</ol>
<blockquote>
<p>这其中是有问题的：若第3步中的扣款操作失败，但消息已经成功发送到了Broker。对于MQ来说，只要消息写入成功，那么这个消息就可以被消费。此时建行系统中用户B增加了1万元。出现了<code>数据不一致问题</code>。</p>
</blockquote>
<h3 id="4-2-解决思路"><a href="#4-2-解决思路" class="headerlink" title="4.2 解决思路"></a>4.2 解决思路</h3><p>解决思路是，让第1、2、3步具有原子性，要么全部成功，要么全部失败。即消息发送成功后，必须要保证扣款成功。如果扣款失败，则回滚发送成功的消息。而该思路即使用<code>事务消息</code>。这里要使用<code>分布式事务解决方案</code>。</p>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/TransactionMessage1.png" class="">

<p>使用事务消息来处理该需求场景：</p>
<ol>
<li><p>事务管理器TM向事务协调器TC发起指令，开启全局事务</p>
</li>
<li><p>工行系统发一个给B增款1万元的事务消息M给TC</p>
</li>
<li><p>TC会向Broker发送半事务消息prepareHalf，将消息M预提交到Broker。此时的建行系统是看<br>不到Broker中的消息M的</p>
</li>
<li><p>Broker会将预提交执行结果Report给TC。</p>
</li>
<li><p>如果预提交失败，则TC会向TM上报预提交失败的响应，全局事务结束；</p>
</li>
<li><p>如果预提交成功，TC会调用工行系统的回调操作，去完成工行用户A的预扣款1万元的操作</p>
</li>
<li><p>工行系统会向TC发送预扣款执行结果，即本地事务的执行状态</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 描述本地事务执行状态</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">LocalTransactionState</span> </span>&#123;</span><br><span class="line">   COMMIT_MESSAGE,  <span class="comment">// 本地事务执行成功</span></span><br><span class="line">   ROLLBACK_MESSAGE,  <span class="comment">// 本地事务执行失败</span></span><br><span class="line">   UNKNOW,  <span class="comment">// 不确定，表示需要进行回查以确定本地事务的执行结果</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>TC收到预扣款执行结果后，会将结果上报给TM。</p>
<ol>
<li>若预扣款成功（本地事务状态为COMMIT_MESSAGE），则TM向TC发送Global Commit指令</li>
<li>若预扣款失败（本地事务状态为ROLLBACK_MESSAGE），则TM向TC发送Global Rollback指令</li>
<li>若现未知状态（本地事务状态为UNKNOW），则会触发工行系统的本地事务状态回查操作。回查操作会将回查结果，即COMMIT_MESSAGE或ROLLBACK_MESSAGE Report给TC。TC将结果上报给TM，TM会再向TC发送最终确认指令Global Commit或Global Rollback</li>
</ol>
</li>
<li><p>TC在接收到指令后会向Broker与工行系统发出确认指令</p>
<ol>
<li>TC接收的若是Global Commit指令，则向Broker与工行系统发送Branch Commit指令。此时Broker中的消息M才可被建行系统看到；此时的工行用户A中的扣款操作才真正被确认</li>
<li>TC接收到的若是Global Rollback指令，则向Broker与工行系统发送Branch Rollback指令。此时Broker中的消息M将被撤销；工行用户A中的扣款操作将被回滚</li>
</ol>
</li>
</ol>
<blockquote>
<p>以上方案就是为了确保<code>消息投递</code>与<code>扣款操作</code>能够在<code>一个事务中</code>，要成功都成功，有一个失败，则全部回滚。<br>以上方案并不是一个典型的XA模式。<br>因为XA模式中的<code>分支事务是异步</code>的，而事务消息方案中的消息预提交与预扣款操作间是同步的。</p>
</blockquote>
<h3 id="4-3-分布式事务概念"><a href="#4-3-分布式事务概念" class="headerlink" title="4.3 分布式事务概念"></a>4.3 分布式事务概念</h3><p>对于分布式事务，通俗地说就是，一次操作由若干分支操作组成，这些分支操作分属不同应用，分布在不同服务器上。分布式事务需要保证这些分支操作要么全部成功，要么全部失败。分布式事务与普通事务一样，就是为了保证操作结果的一致性。</p>
<ul>
<li><p>事务消息</p>
<p>暂不能投递的消息，发送方已经成功地将消息发送到了Broker，但是Broker未收到最终确认指令，此时该消息被标记成“暂不能投递”状态，即不能被消费者看到。处于该种状态下的消息即半事务消息。</p>
</li>
<li><p>本地事务状态</p>
<p>Producer<code>回调操作</code>执行的结果为本地事务状态，其会发送给TC，而TC会再发送给TM。TM会根据TC发送来的本地事务状态来决定全局事务确认指令。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 描述本地事务执行状态</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">LocalTransactionState</span> </span>&#123;</span><br><span class="line">    COMMIT_MESSAGE,  <span class="comment">// 本地事务执行成功</span></span><br><span class="line">    ROLLBACK_MESSAGE,  <span class="comment">// 本地事务执行失败</span></span><br><span class="line">    UNKNOW,  <span class="comment">// 不确定，表示需要进行回查以确定本地事务的执行结果</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>消息回查</p>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/TransactionMessage2.png" class="">

<p>消息回查，即重新查询本地事务的执行状态。本例就是重新到DB中查看预扣款操作是否执行成功。</p>
<blockquote>
<p>注意，<code>消息回查不是重新执行回调操作</code>。回调操作是进行预扣款操作，而消息回查则是查看预扣款操作执行的结果。</p>
<p>引发消息回查的原因最常见的有两个：</p>
<p>1)回调操作返回UNKNWON</p>
<p>2)TC没有接收到TM的最终全局事务确认指令</p>
</blockquote>
</li>
<li><p>RocketMQ中的消息回查设置</p>
<p>关于消息回查，有三个常见的属性设置。它们都在broker加载的配置文件中设置，例如：</p>
<ul>
<li>transactionTimeout=20，指定TM在20秒内应将最终确认状态发送给TC，否则引发消息回查。默认为60秒</li>
<li>transactionCheckMax=5，指定最多回查5次，超过后将丢弃消息并记录错误日志。默认15次。</li>
<li>transactionCheckInterval=10，指定设置的多次消息回查的时间间隔为10秒。默认为60秒。</li>
</ul>
</li>
</ul>
<h4 id="4-3-1-XA模式"><a href="#4-3-1-XA模式" class="headerlink" title="4.3.1 XA模式"></a>4.3.1 XA模式</h4><p>XA（Unix Transaction）是一种分布式事务解决方案，一种分布式事务处理模式，是基于XA协议的。XA协议由Tuxedo（Transaction for Unix has been Extended for Distributed Operation，分布式操作扩展之后的Unix事务系统）首先提出的，并交给X/Open组织，作为资源管理器与事务管理器的接口标准:</p>
<p>XA模式中有三个重要组件：TC、TM、RM。</p>
<ul>
<li><p><strong>TC</strong></p>
<p>Transaction Coordinator，事务协调者。维护全局和分支事务的状态，驱动全局事务提交或回滚。</p>
<blockquote>
<p>RocketMQ中Broker充当着TC。</p>
</blockquote>
</li>
<li><p><strong>TM</strong></p>
<p>Transaction Manager，事务管理器。定义全局事务的范围：开始全局事务、提交或回滚全局事务。它实际是全局事务的发起者。</p>
<blockquote>
<p>RocketMQ中事务消息的Producer充当着TM。</p>
</blockquote>
</li>
<li><p><strong>RM</strong></p>
<p>Resource Manager，资源管理器。管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。</p>
<blockquote>
<p>RocketMQ中事务消息的Producer及Broker均是RM。</p>
</blockquote>
</li>
</ul>
<h4 id="4-3-2-XA模式架构"><a href="#4-3-2-XA模式架构" class="headerlink" title="4.3.2 XA模式架构"></a>4.3.2 XA模式架构</h4><img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/TransactionMessage3.png" class="">

<p>XA模式是一个典型的2PC，其执行原理如下：</p>
<ol>
<li><p>TM向TC发起指令，开启一个全局事务。</p>
</li>
<li><p>根据业务要求，各个RM会逐个向TC注册分支事务，然后TC会逐个向RM发出预执行指令。</p>
</li>
<li><p>各个RM在接收到指令后会在进行本地事务预执行。</p>
</li>
<li><p>RM将预执行结果Report给TC。当然，这个结果可能是成功，也可能是失败。</p>
</li>
<li><p>TC在接收到各个RM的Report后会将汇总结果上报给TM，根据汇总结果TM会向TC发出确认指令。</p>
<blockquote>
<p>若<code>所有结果都是成功响应</code>，则向TC发送Global Commit指令。</p>
<p><code>只要有结果是失败响应</code>，则向TC发送Global Rollback指令。</p>
</blockquote>
</li>
<li><p>TC在接收到指令后再次向RM发送确认指令。</p>
</li>
</ol>
<p><strong>注意:</strong></p>
<p><code>事务消息不支持延时消息</code></p>
<p>对于事务消息要<code>做好幂等性检查</code>，因为事务消息可能不止一次被消费（因为存在回滚后再提交的情况）</p>
<h3 id="4-4-代码举例"><a href="#4-4-代码举例" class="headerlink" title="4.4 代码举例"></a>4.4 代码举例</h3><ul>
<li><p><strong>定义工行事务监听器</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ICBCTransactionListener</span> <span class="keyword">implements</span> <span class="title">TransactionListener</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 回调操作方法</span></span><br><span class="line">    <span class="comment">// 消息预提交成功就会触发该方法的执行，用于完成本地事务</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LocalTransactionState <span class="title">executeLocalTransaction</span><span class="params">(Message msg,Object arg)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;预提交消息成功：&quot;</span> + msg);</span><br><span class="line">        <span class="comment">// 假设接收到TAGA的消息就表示扣款操作成功，TAGB的消息表示扣款失败，</span></span><br><span class="line">        <span class="comment">// TAGC表示扣款结果不清楚，需要执行消息回查</span></span><br><span class="line">        <span class="keyword">if</span> (StringUtils.equals(<span class="string">&quot;TAGA&quot;</span>, msg.getTags())) &#123;</span><br><span class="line">            <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (StringUtils.equals(<span class="string">&quot;TAGB&quot;</span>, msg.getTags())) &#123;</span><br><span class="line">            <span class="keyword">return</span> LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (StringUtils.equals(<span class="string">&quot;TAGC&quot;</span>, msg.getTags())) &#123;</span><br><span class="line">            <span class="keyword">return</span> LocalTransactionState.UNKNOW;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> LocalTransactionState.UNKNOW;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 消息回查方法</span></span><br><span class="line">    <span class="comment">// 引发消息回查的原因最常见的有两个：</span></span><br><span class="line">    <span class="comment">// 1)回调操作返回UNKNWON</span></span><br><span class="line">    <span class="comment">// 2)TC没有接收到TM的最终全局事务确认指令</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LocalTransactionState <span class="title">checkLocalTransaction</span><span class="params">(MessageExt msg)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;执行消息回查&quot;</span> + msg.getTags());</span><br><span class="line">        <span class="keyword">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>定义事物消息生产者</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ublic <span class="class"><span class="keyword">class</span> <span class="title">TransactionProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        TransactionMQProducer producer = <span class="keyword">new</span> TransactionMQProducer(<span class="string">&quot;tpg&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 定义一个线程池</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> corePoolSize 线程池中核心线程数量</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> maximumPoolSize 线程池中最多线程数</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> keepAliveTime 这是一个时间。当线程池中线程数量大于核心线程数量时，多余空闲线程的存活时长</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> unit 时间单位</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> workQueue 临时存放任务的队列，其参数就是队列的长度</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> threadFactory 线程工厂</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">        ExecutorService executorService = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">2</span>, <span class="number">5</span>,<span class="number">100</span>, TimeUnit.SECONDS,<span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class="number">2000</span>),<span class="keyword">new</span> ThreadFactory() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Thread <span class="title">newThread</span><span class="params">(Runnable r)</span> </span>&#123;</span><br><span class="line">                Thread thread = <span class="keyword">new</span> Thread(r);</span><br><span class="line">                thread.setName(<span class="string">&quot;client-transaction-msg-check-thread&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> thread;&#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 为生产者指定一个线程池</span></span><br><span class="line">        producer.setExecutorService(executorService);</span><br><span class="line">        <span class="comment">// 为生产者添加事务监听器</span></span><br><span class="line">        producer.setTransactionListener(<span class="keyword">new</span> ICBCTransactionListener());</span><br><span class="line">        producer.start();</span><br><span class="line">        String[] tags = &#123;<span class="string">&quot;TAGA&quot;</span>,<span class="string">&quot;TAGB&quot;</span>,<span class="string">&quot;TAGC&quot;</span>&#125;;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] body = (<span class="string">&quot;Hi,&quot;</span> + i).getBytes();</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;TTopic&quot;</span>, tags[i], body);</span><br><span class="line">            <span class="comment">// 发送事务消息</span></span><br><span class="line">            <span class="comment">// 第二个参数用于指定在执行本地事务时要使用的业务参数</span></span><br><span class="line">            SendResult sendResult = producer.sendMessageInTransaction(msg,<span class="keyword">null</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;发送结果为：&quot;</span> + sendResult.getSendStatus());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>定义消费者</strong></p>
<p>直接使用普通消息的SomeConsumer作为消费者即可。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SomeConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">        <span class="comment">// 定义一个pull消费者</span></span><br><span class="line">        <span class="comment">// DefaultLitePullConsumer consumer = new DefaultLitePullConsumer(&quot;cg&quot;);</span></span><br><span class="line">        <span class="comment">// 定义一个push消费者</span></span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;cg&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定nameServer</span></span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定从第一条消息开始消费</span></span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line">        <span class="comment">// 指定消费topic与tag</span></span><br><span class="line">        consumer.subscribe(<span class="string">&quot;TTopic&quot;</span>, <span class="string">&quot;*&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定采用“广播模式”进行消费，默认为“集群模式”</span></span><br><span class="line">        <span class="comment">// consumer.setMessageModel(MessageModel.BROADCASTING);</span></span><br><span class="line">        <span class="comment">// 注册消息监听器</span></span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;               </span><br><span class="line">            <span class="comment">// 一旦broker中有了其订阅的消息就会触发该方法的执行，                        </span></span><br><span class="line">            <span class="comment">// 其返回值为当前consumer消费的状态</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus</span></span><br><span class="line"><span class="function">                <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs,ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">                <span class="comment">// 逐条消费消息</span></span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : msgs) &#123;</span><br><span class="line">                    System.out.println(msg);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 返回消费状态：消费成功</span></span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 开启消费者消费</span></span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.println(<span class="string">&quot;Consumer Started&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="五、批量消息"><a href="#五、批量消息" class="headerlink" title="五、批量消息"></a>五、批量消息</h2><h3 id="5-1-批量发送消息"><a href="#5-1-批量发送消息" class="headerlink" title="5.1 批量发送消息"></a>5.1 批量发送消息</h3><ul>
<li><p><strong>发送限制</strong></p>
<p>生产者进行消息发送时可以一次发送多条消息，这可以大大提升Producer的发送效率。不过需要注意以下几点：</p>
<ul>
<li>批量发送的消息必须具有<code>相同的Topic</code></li>
<li>批量发送的消息必须具有<code>相同的刷盘策略</code></li>
<li>批量发送的消息<code>不能是延时消息与事务消息</code></li>
</ul>
</li>
<li><p><strong>批量发送大小</strong></p>
<p>默认情况下，<code>一批发送的消息总大小不能超过4MB字节</code>。如果想超出该值，有两种解决方案：</p>
<ul>
<li>方案一：将批量消息进行拆分，拆分为若干不大于4M的消息集合分多次批量发送</li>
<li>方案二：在Producer端与Broker端修改属性</li>
</ul>
<blockquote>
<p>Producer端需要在发送之前设置Producer的maxMessageSize属性<br>Broker端需要修改其加载的配置文件中的maxMessageSize属性</p>
</blockquote>
</li>
<li><p><strong>生产者发送的消息大小</strong></p>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/batchMessage.png" class="">

<p>生产者通过send()方法发送的Message，并不是直接将Message序列化后发送到网络上的，而是通过这个Message生成了一个字符串发送出去的。这个字符串由四部分构成：Topic、消息Body、消息日志（占20字节），及用于描述消息的一堆属性key-value。这些属性中包含例如生产者地址、生产时间、要发送的QueueId等。最终写入到Broker中消息单元中的数据都是来自于这些属性。</p>
</li>
</ul>
<h3 id="5-2-批量消费消息"><a href="#5-2-批量消费消息" class="headerlink" title="5.2 批量消费消息"></a>5.2 批量消费消息</h3><h4 id="5-2-1-修改批量属性"><a href="#5-2-1-修改批量属性" class="headerlink" title="5.2.1 修改批量属性"></a>5.2.1 修改批量属性</h4><img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/batchMessage1.png" class="">

<p>Consumer的MessageListenerConcurrently监听接口的consumeMessage()方法的第一个参数为消息列表，但默认情况下每次只能消费一条消息。若要使其一次可以消费多条消息，则可以通过修改Consumer的consumeMessageBatchMaxSize属性来指定。不过，该值不能超过32。因为默认情况下消费者每次可以拉取的消息最多是32条。若要修改一次拉取的最大值，则可通过修改Consumer的pullBatchSize属性来指定。</p>
<h4 id="5-2-2-存在问题"><a href="#5-2-2-存在问题" class="headerlink" title="5.2.2 存在问题"></a>5.2.2 存在问题</h4><p>Consumer的pullBatchSize属性与consumeMessageBatchMaxSize属性是否设置的越大越好？当然不是。</p>
<ul>
<li>pullBatchSize值设置的越大，Consumer每拉取一次需要的时间就会越长，且在网络上传输出现问题的可能性就越高。若在拉取过程中若出现了问题，那么本批次所有消息都需要全部重新拉取。</li>
<li>consumeMessageBatchMaxSize值设置的越大，Consumer的消息并发消费能力越低，且这批被消费的消息具有相同的消费结果。因为consumeMessageBatchMaxSize指定的一批消息只会使用一个线程进行处理，且在处理过程中只要有一个消息处理异常，则这批消息需要全部重新再次消费处理。</li>
</ul>
<h3 id="5-3-代码举例"><a href="#5-3-代码举例" class="headerlink" title="5.3 代码举例"></a>5.3 代码举例</h3><p>该批量发送的需求是，不修改最大发送4M的默认值，但要防止发送的批量消息超出4M的限制。</p>
<ul>
<li><p><strong>定义消息列表分割器</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 消息列表分割器：其只会处理每条消息的大小不超4M的情况。</span></span><br><span class="line"><span class="comment">// 若存在某条消息，其本身大小大于4M，这个分割器无法处理，</span></span><br><span class="line"><span class="comment">// 其直接将这条消息构成一个子列表返回。并没有再进行分割</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MessageListSplitter</span> <span class="keyword">implements</span> <span class="title">Iterator</span>&lt;<span class="title">List</span>&lt;<span class="title">Message</span>&gt;&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 指定极限值为4M</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> SIZE_LIMIT =  <span class="number">4</span> *<span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line">    <span class="comment">// 存放所有要发送的消息</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Message&gt; messages;</span><br><span class="line">    <span class="comment">// 要进行批量发送消息的小集合起始索引</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> currIndex;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MessageListSplitter</span><span class="params">(List&lt;Message&gt; messages)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.messages = messages;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 判断当前开始遍历的消息索引要小于消息总数</span></span><br><span class="line">        <span class="keyword">return</span> currIndex &lt; messages.size();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Message&gt; <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> nextIndex = currIndex;</span><br><span class="line">        <span class="comment">// 记录当前要发送的这一小批次消息列表的大小</span></span><br><span class="line">        <span class="keyword">int</span> totalSize = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (; nextIndex &lt; messages.size(); nextIndex++) &#123;</span><br><span class="line">            <span class="comment">// 获取当前遍历的消息</span></span><br><span class="line">            Message message = messages.get(nextIndex);</span><br><span class="line">            <span class="comment">// 统计当前遍历的message的大小</span></span><br><span class="line">            <span class="keyword">int</span> tmpSize = message.getTopic().length() + message.getBody().length;</span><br><span class="line">            Map&lt;String, String&gt; properties = message.getProperties();</span><br><span class="line">            <span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry :</span><br><span class="line">                 properties.entrySet()) &#123;</span><br><span class="line">                tmpSize += entry.getKey().length() +</span><br><span class="line">                    entry.getValue().length();</span><br><span class="line">            &#125;</span><br><span class="line">            tmpSize = tmpSize + <span class="number">20</span>;</span><br><span class="line">            <span class="comment">// 判断当前消息本身是否大于4M</span></span><br><span class="line">            <span class="keyword">if</span> (tmpSize &gt; SIZE_LIMIT) &#123;</span><br><span class="line">                <span class="keyword">if</span> (nextIndex - currIndex == <span class="number">0</span>) &#123;</span><br><span class="line">                    nextIndex++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (tmpSize + totalSize &gt; SIZE_LIMIT) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                totalSize += tmpSize;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="comment">// end-for</span></span><br><span class="line">        <span class="comment">// 获取当前messages列表的子集合[currIndex, nextIndex)</span></span><br><span class="line">        List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex);</span><br><span class="line">        <span class="comment">// 下次遍历的开始索引</span></span><br><span class="line">        currIndex = nextIndex;</span><br><span class="line">        <span class="keyword">return</span> subList;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>定义批量消息生产者</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BatchProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        <span class="comment">// 指定要发送的消息的最大大小，默认是4M</span></span><br><span class="line">        <span class="comment">// 不过，仅修改该属性是不行的，还需要同时修改broker加载的配置文件中的</span></span><br><span class="line">        <span class="comment">// maxMessageSize属性</span></span><br><span class="line">        <span class="comment">// producer.setMaxMessageSize(8 * 1024 * 1024);</span></span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="comment">// 定义要发送的消息集合</span></span><br><span class="line">        List&lt;Message&gt; messages = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] body = (<span class="string">&quot;Hi,&quot;</span> + i).getBytes();</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;someTopic&quot;</span>, <span class="string">&quot;someTag&quot;</span>, body);</span><br><span class="line">            messages.add(msg);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 定义消息列表分割器，将消息列表分割为多个不超出4M大小的小列表</span></span><br><span class="line">        MessageListSplitter splitter = <span class="keyword">new</span> MessageListSplitter(messages);</span><br><span class="line">        <span class="keyword">while</span> (splitter.hasNext()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                List&lt;Message&gt;  listItem = splitter.next();</span><br><span class="line">                producer.send(listItem);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>定义批量消息消费者</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BatchConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span></span><br><span class="line">            DefaultMQPushConsumer(<span class="string">&quot;cg&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;rocketmqOS:9876&quot;</span>);</span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET</span><br><span class="line">                                    );</span><br><span class="line">        consumer.subscribe(<span class="string">&quot;someTopicA&quot;</span>, <span class="string">&quot;*&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 指定每次可以消费10条消息，默认为1</span></span><br><span class="line">        consumer.setConsumeMessageBatchMaxSize(<span class="number">10</span>);</span><br><span class="line">        <span class="comment">// 指定每次可以从Broker拉取40条消息，默认为32</span></span><br><span class="line">        consumer.setPullBatchSize(<span class="number">40</span>);</span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs,ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : msgs) &#123;</span><br><span class="line">                    System.out.println(msg);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 消费成功的返回结果</span></span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">                <span class="comment">// 消费异常时的返回结果</span></span><br><span class="line">                <span class="comment">// return ConsumeConcurrentlyStatus.RECONSUME_LATER;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.println(<span class="string">&quot;Consumer Started&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="六、消息过滤"><a href="#六、消息过滤" class="headerlink" title="六、消息过滤"></a>六、消息过滤</h2><p>消息者在进行消息订阅时，除了可以指定要订阅消息的Topic外，还可以对指定Topic中的消息根据指定条件进行过滤，即可以订阅比Topic更加细粒度的消息类型。</p>
<p>对于指定Topic消息的过滤有两种过滤方式：<code>Tag过滤</code>与<code>SQL过滤</code></p>
<h3 id="6-1-Tag过滤"><a href="#6-1-Tag过滤" class="headerlink" title="6.1 Tag过滤"></a>6.1 Tag过滤</h3><p>通过consumer的subscribe()方法指定要订阅消息的Tag。如果订阅多个Tag的消息，Tag间使用或运算符(双竖线||)连接。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;CID_EXAMPLE&quot;</span>);</span><br><span class="line">consumer.subscribe(<span class="string">&quot;TOPIC&quot;</span>, <span class="string">&quot;TAGA || TAGB || TAGC&quot;</span>);</span><br></pre></td></tr></table></figure>

<h3 id="6-2-SQL过滤"><a href="#6-2-SQL过滤" class="headerlink" title="6.2 SQL过滤"></a>6.2 SQL过滤</h3><p>SQL过滤是一种通过特定表达式对事先埋入到消息中的<code>用户属性</code>进行筛选过滤的方式。通过SQL过滤，可以实现对消息的复杂过滤。不过，只有使用<code>PUSH模式</code>的消费者才能使用SQL过滤。SQL过滤表达式中支持多种常量类型与运算符。</p>
<ul>
<li><strong>支持的常量类型</strong><ul>
<li>数值：比如：123，3.1415</li>
<li>字符：必须用单引号包裹起来，比如：‘abc’</li>
<li>布尔：TRUE 或 FALSE</li>
<li>NULL：特殊的常量，表示空</li>
</ul>
</li>
<li><strong>支持的运算符有：</strong><ul>
<li>数值比较：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，=</li>
<li>字符比较：=，&lt;&gt;，IN</li>
<li>逻辑运算 ：AND，OR，NOT</li>
<li>NULL判断：IS NULL 或者 IS NOT NULL</li>
</ul>
</li>
</ul>
<p><code>默认情况下Broker没有开启消息的SQL过滤功能</code>，需要在Broker加载的配置文件中添加如下属性，以开启该功能：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">enablePropertyFilter</span> = <span class="string">true </span></span><br></pre></td></tr></table></figure>

<p>在启动Broker时需要指定这个修改过的配置文件。例如对于单机Broker的启动，其修改的配置文件是conf/broker.conf，启动时使用如下命令：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &amp;   <span class="comment">#指定配置文件</span></span><br></pre></td></tr></table></figure>

<h3 id="6-3-代码举例"><a href="#6-3-代码举例" class="headerlink" title="6.3 代码举例"></a>6.3 代码举例</h3><ul>
<li><p>定义Tag过滤Producer</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FilterByTagProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        producer.start();  </span><br><span class="line">        <span class="comment">//均包含下面Tag，为下面3种，生成了下面3种</span></span><br><span class="line">        String[] tags = &#123;<span class="string">&quot;myTagA&quot;</span>,<span class="string">&quot;myTagB&quot;</span>,<span class="string">&quot;myTagC&quot;</span>&#125;;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] body = (<span class="string">&quot;Hi,&quot;</span> + i).getBytes();</span><br><span class="line">            String tag =  tags[i%tags.length];</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;myTopic&quot;</span>,tag,body);</span><br><span class="line">            SendResult sendResult = producer.send(msg);</span><br><span class="line">            System.out.println(sendResult);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>定义Tag过滤Consumer</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FilterByTagConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span></span><br><span class="line">            DefaultMQPushConsumer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line">        <span class="comment">//仅订阅myTagA、myTagB的消息中的一个，或者myTopic，不包含上面生产者的myTagC</span></span><br><span class="line">        consumer.subscribe(<span class="string">&quot;myTopic&quot;</span>, <span class="string">&quot;myTagA || myTagB&quot;</span>);</span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus</span></span><br><span class="line"><span class="function">                <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs,ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">for</span> (MessageExt me:msgs)&#123;</span><br><span class="line">                    System.out.println(me);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.println(<span class="string">&quot;Consumer Started&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>定义SQL过滤Producer</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FilterBySQLProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">byte</span>[] body = (<span class="string">&quot;Hi,&quot;</span> + i).getBytes();</span><br><span class="line">                Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;myTopic&quot;</span>, <span class="string">&quot;myTag&quot;</span>, body);</span><br><span class="line">                <span class="comment">//事先埋入用户属性age；K-V形式</span></span><br><span class="line">                msg.putUserProperty(<span class="string">&quot;age&quot;</span>, i + <span class="string">&quot;&quot;</span>);</span><br><span class="line">                SendResult sendResult = producer.send(msg);</span><br><span class="line">                System.out.println(sendResult);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>定义SQL过滤Consumer</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FilterBySQLConsumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line">        <span class="comment">//订阅myTopic的Tag，且对应消息中的用户属性age，在0到6之间</span></span><br><span class="line">        consumer.subscribe(<span class="string">&quot;myTopic&quot;</span>, MessageSelector.bySql(<span class="string">&quot;age between 0 and 6&quot;</span>));</span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus</span></span><br><span class="line"><span class="function">                <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">for</span> (MessageExt me:msgs)&#123;</span><br><span class="line">                    System.out.println(me);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.println(<span class="string">&quot;Consumer Started&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="七、消息发送重发机制"><a href="#七、消息发送重发机制" class="headerlink" title="七、消息发送重发机制"></a>七、消息发送重发机制</h2><h3 id="7-1-说明"><a href="#7-1-说明" class="headerlink" title="7.1 说明"></a>7.1 说明</h3><p>Producer对发送失败的消息进行重新发送的机制，称为<code>消息发送重试机制</code>，也称为消息重投机制。对于消息重投，需要注意以下几点：</p>
<ul>
<li>生产者在发送消息时，若采用<code>同步或异步发送方式</code>，发送失败会重试，但oneway消息发送方式发送失败是没有重试机制的</li>
<li>只有普通消息具有发送重试机制，顺序消息是没有的消息重投机制可以保证消息尽可能发送成功、不丢失，但可能会造成消息重复。消息重复在RocketMQ中是无法避免的问题</li>
<li>消息重复在一般情况下不会发生，当出现消息量大、网络抖动，消息重复就会成为大概率事件producer主动重发、consumer负载变化（发生Rebalance，不会导致消息重复，但可能出现重复消费）也会导致重复消息</li>
<li>消息重复无法避免，但要避免消息的重复消费。</li>
<li>避免消息重复消费的解决方案是，为消息添加唯一标识（例如消息key），使消费者对消息进行消费判断来避免重复消费</li>
<li>消息发送重试有三种策略可以选择：<code>同步发送失败策略</code>、<code>异步发送失败策略</code>、<code>消息刷盘失败策略</code></li>
</ul>
<h3 id="7-2-同步发送失败策略"><a href="#7-2-同步发送失败策略" class="headerlink" title="7.2 同步发送失败策略"></a>7.2 同步发送失败策略</h3><p>对于普通消息，<code>消息发送默认采用round-robin策略(轮询)</code>来选择所发送到的队列。如果发送失败，<code>默认重试2次</code>。但在重试时是不会选择上次发送失败的Broker，而是选择其它Broker。当然，若只有一个Broker其也只能发送到该Broker，但其会尽量发送到该Broker上的其它Queue。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建一个producer，参数为Producer Group名称</span></span><br><span class="line">DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line"><span class="comment">// 指定nameServer地址</span></span><br><span class="line">producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line"><span class="comment">// 设置同步发送失败时重试发送的次数，默认为2次</span></span><br><span class="line">producer.setRetryTimesWhenSendFailed(<span class="number">3</span>);</span><br><span class="line"><span class="comment">// 设置发送超时时限为5s，默认3s</span></span><br><span class="line">producer.setSendMsgTimeout(<span class="number">5000</span>);</span><br></pre></td></tr></table></figure>

<p>同时，Broker还具有<code>失败隔离</code>功能，使Producer尽量选择未发生过发送失败的Broker作为目标Broker。其可以<code>保证其它消息尽量不发送到问题Broker</code>，为了<code>提升消息发送效率，降低消息发送耗时</code>。</p>
<blockquote>
<p>思考：让我们自己实现失败隔离功能，如何来做？</p>
<p>1）方案一：Producer中维护某JUC的Map集合，其key是发生失败的时间戳，value为Broker实例。Producer中还维护着一个Set集合，其中存放着所有未发生发送异常的Broker实例。选择目标Broker是从该Set集合中选择的。再定义一个定时任务，定期从Map集合中将长期未发生发送异常的Broker清理出去，并添加到Set集合。<br>2）方案二：为Producer中的Broker实例添加一个标识，例如是一个AtomicBoolean属性。只要该Broker上发生过发送异常，就将其置为true。选择目标Broker就是选择该属性值为false的Broker。再定义一个定时任务，定期将Broker的该属性置为false。<br>3）方案三：为Producer中的Broker实例添加一个标识，例如是一个AtomicLong属性。只要该Broker上发生过发送异常，就使其值增一。选择目标Broker就是选择该属性值最小的Broker。若该值相同，采用轮询方式选择。</p>
</blockquote>
<p>如果超过重试次数，则抛出异常，由Producer去保证消息不丢。当然当生产者出现RemotingException、MQClientException和MQBrokerException时，Producer会自动重投消息。</p>
<h3 id="7-3-异步发送失败策略"><a href="#7-3-异步发送失败策略" class="headerlink" title="7.3 异步发送失败策略"></a>7.3 异步发送失败策略</h3><p>异步发送失败重试时，异步重试不会选择其他broker，<code>仅在同一个broker上做重试</code>，所以该策略无法保证消息不丢。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;pg&quot;</span>);</span><br><span class="line">producer.setNamesrvAddr(<span class="string">&quot;192.168.109.101:9876&quot;</span>);</span><br><span class="line"><span class="comment">// 指定异步发送失败后不进行重试发送</span></span><br><span class="line">producer.setRetryTimesWhenSendAsyncFailed(<span class="number">0</span>);</span><br></pre></td></tr></table></figure>

<h3 id="7-4-消息刷盘失败策略"><a href="#7-4-消息刷盘失败策略" class="headerlink" title="7.4 消息刷盘失败策略"></a>7.4 消息刷盘失败策略</h3><p>消息刷盘超时（Master或Slave）或slave不可用（slave在做数据同步时向master返回状态不是SEND_OK）时，默认是不会将消息尝试发送到其他Broker的。不过，对于重要消息可以通过在Broker的配置文件设置retryAnotherBrokerWhenNotStoreOK属性为true来开启。</p>
<h2 id="八、消息消费重试机制"><a href="#八、消息消费重试机制" class="headerlink" title="八、消息消费重试机制"></a>八、消息消费重试机制</h2><h3 id="8-1-顺序消息的消费重试"><a href="#8-1-顺序消息的消费重试" class="headerlink" title="8.1 顺序消息的消费重试"></a>8.1 顺序消息的消费重试</h3><p>对于顺序消息，当Consumer消费消息失败后，为了保证消息的顺序性，其会自动不断地进行消息重试，直到消费成功。<code>消费重试默认间隔时间为1000毫秒</code>。重试期间应用会出现消息消费被阻塞的情况。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;cg&quot;</span>);</span><br><span class="line"><span class="comment">// 顺序消息消费失败的消费重试时间间隔，单位毫秒，默认为1000，其取值范围为[10,30000]</span></span><br><span class="line">consumer.setSuspendCurrentQueueTimeMillis(<span class="number">100</span>);</span><br></pre></td></tr></table></figure>

<p>由于对·<code>顺序消息的重试是无休止的，不间断的，直至消费成功</code>，所以，对于顺序消息的消费，务必要保证应用能够及时监控并处理消费失败的情况，避免消费被<code>永久性阻塞</code>。</p>
<p>注意，<strong>顺序消息没有发送失败重试机制，但具有消费失败重试机制</strong></p>
<h3 id="8-2-无序消息的消费重试"><a href="#8-2-无序消息的消费重试" class="headerlink" title="8.2 无序消息的消费重试"></a>8.2 无序消息的消费重试</h3><p>对于<code>无序消息（普通消息、延时消息、事务消息）</code>，当Consumer消费消息失败时，可以通过设置返回状态达到消息重试的效果。不过需要注意，无序消息的重试<code>只对集群消费方式生效</code>，<code>广播消费方式不提供失败重试特性</code>。</p>
<p><strong>即对于广播消费，消费失败后，失败消息不再重试，继续消费后续消息。</strong></p>
<h3 id="8-3-消费重试次数与间隔"><a href="#8-3-消费重试次数与间隔" class="headerlink" title="8.3 消费重试次数与间隔"></a>8.3 消费重试次数与间隔</h3><p>对于<code>无序消息集群消费下</code>的重试消费，<code>每条消息默认最多重试16次</code>，但每次重试的间隔时间是不同的，会逐渐变长。每次重试的间隔时间如下表。</p>
<table>
<thead>
<tr>
<th align="center">重试次数</th>
<th align="center">与上次重试的间隔时间</th>
<th align="center">重试次数</th>
<th align="center">与上次重试的间隔时间</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">10秒</td>
<td align="center">9</td>
<td align="center">7分钟</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">30秒</td>
<td align="center">10</td>
<td align="center">8分钟</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">1分钟</td>
<td align="center">11</td>
<td align="center">9分钟</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">2分钟</td>
<td align="center">12</td>
<td align="center">10分钟</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">3分钟</td>
<td align="center">13</td>
<td align="center">20分钟</td>
</tr>
<tr>
<td align="center">6</td>
<td align="center">4分钟</td>
<td align="center">14</td>
<td align="center">30分钟</td>
</tr>
<tr>
<td align="center">7</td>
<td align="center">5分钟</td>
<td align="center">15</td>
<td align="center">1小时</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">6分钟</td>
<td align="center">16</td>
<td align="center">2小时</td>
</tr>
</tbody></table>
<blockquote>
<p>若一条消息在一直消费失败的前提下，将会在正常消费后的第4小时46分后进行第16次重试。</p>
<p>若仍然失败，则将消息投递到<code>死信队列</code></p>
</blockquote>
<p>修改消费重试次数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;cg&quot;</span>);</span><br><span class="line"><span class="comment">// 修改消费重试次数,默认16次</span></span><br><span class="line">consumer.setMaxReconsumeTimes(<span class="number">10</span>);</span><br></pre></td></tr></table></figure>

<p>对于修改过的重试次数，将按照以下策略执行：</p>
<ul>
<li>b若修改值小于16，则按照指定间隔进行重试</li>
<li>若修改值大于16，则超过16次的重试时间间隔均为2小时</li>
</ul>
<p>对于Consumer Group，若仅修改了一个Consumer的消费重试次数，则会应用到该Group中所有其它Consumer实例。若出现多个Consumer均做了修改的情况，则<code>采用覆盖方式生效</code>。即最后被修改的值会覆盖前面设置的值。</p>
<h3 id="8-4-重试队列"><a href="#8-4-重试队列" class="headerlink" title="8.4 重试队列"></a>8.4 重试队列</h3><p>对于需要重试消费的消息，并不是Consumer在等待了指定时长后再次去拉取原来的消息进行消费，而是将这些需要重试消费的消息放入到了一个特殊Topic的队列中，而后进行再次消费的。这个特殊的队列就是重试队列。</p>
<p>当出现需要进行重试消费的消息时，Broker会为每个消费组都设置一个Topic名称为<code>%RETRY%consumerGroup@consumerGroup的重试队列</code>。</p>
<blockquote>
<p>1）这个<code>重试队列是针对消息组</code>的，而<code>不是针对每个Topic设置</code>的（一个Topic的消息可以让多个消费者组进行消费，所以会为这些消费者组各创建一个重试队列）</p>
<p>2）<code>只有当出现需要进行重试消费的消息时，才会为该消费者组创建重试队列</code></p>
</blockquote>
<img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/retry.png" class="">

<blockquote>
<p>注意，消费重试的时间间隔与延时消费的延时等级十分相似，除了没有延时等级的前两个时间外，其它的时间都是相同的</p>
</blockquote>
<p>Broker对于重试消息的处理是通过<code>延时消息实现</code>的。先将消息保存到SCHEDULE_TOPIC_XXXX延迟队列中，延迟时间到后，会将消息投递到%RETRY%consumerGroup@consumerGroup重试队列中。</p>
<h3 id="8-5-消息重试配置方式"><a href="#8-5-消息重试配置方式" class="headerlink" title="8.5 消息重试配置方式"></a>8.5 消息重试配置方式</h3><img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/retryMessage.png" class="">

<p>集群消费方式下，消息消费失败后若希望消费重试，则需要在消息监听器接口的实现中明确进行如下三种方式之一的配置：</p>
<ul>
<li>方式1：<code>返回ConsumeConcurrentlyStatus.RECONSUME_LATER（推荐）</code></li>
<li>方式2：返回Null</li>
<li>方式3：抛出异常</li>
</ul>
<h3 id="8-6-消息不重试配置方式"><a href="#8-6-消息不重试配置方式" class="headerlink" title="8.6 消息不重试配置方式"></a>8.6 消息不重试配置方式</h3><img src="/2022/01/27/RocketMQ%E5%BA%94%E7%94%A8/retryMessage1.png" class="">

<p><code>集群消费方式</code>下，消息消费失败后若不希望消费重试，则在捕获到异常后同样也返回与消费成功后的相同的结果，即<code>ConsumeConcurrentlyStatus.CONSUME_SUCCESS，则不进行消费重试</code>。</p>
<h2 id="九、死信队列"><a href="#九、死信队列" class="headerlink" title="九、死信队列"></a>九、死信队列</h2><h3 id="9-1-什么是死信队列"><a href="#9-1-什么是死信队列" class="headerlink" title="9.1 什么是死信队列"></a>9.1 什么是死信队列</h3><p>当一条消息初次消费失败，消息队列会自动进行消费重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。这个队列就是死信队列（Dead-Letter Queue，DLQ），而其中的消息则称为死信消息（Dead-Letter Message，DLM）</p>
<blockquote>
<p>死信队列是用于处理无法被正常消费的消息的。</p>
</blockquote>
<h3 id="9-2-死信队列的特征"><a href="#9-2-死信队列的特征" class="headerlink" title="9.2 死信队列的特征"></a>9.2 死信队列的特征</h3><p>死信队列具有如下特征：</p>
<ul>
<li>死信队列中的消息不会再被消费者正常消费，即DLQ对于消费者是不可见的</li>
<li>死信存储有效期与正常消息相同，均为 3 天（commitlog文件的过期时间），3 天后会被自动删除</li>
<li>死信队列就是一个特殊的Topic，名称为%DLQ%consumerGroup@consumerGroup，即每个消费者组都有一个死信队列</li>
<li>如果⼀个消费者组未产生死信消息，则不会为其创建相应的死信队列</li>
</ul>
<h3 id="9-3-死信消息的处理"><a href="#9-3-死信消息的处理" class="headerlink" title="9.3 死信消息的处理"></a>9.3 死信消息的处理</h3><p>实际上，当⼀条消息进入死信队列，就意味着系统中某些地方出现了问题，从而导致消费者无法正常消费该消息，MQ本身无法处理，比如代码中原本就存在Bug。因此，对于死信消息，通常需要开发人员进行特殊处理。最关键的步骤是要排查可疑因素，解决代码中可能存在的Bug，然后再将原来的死信消息再次进行投递消费</p>
]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-AOP原理</title>
    <url>/2022/09/27/Spring-AOP%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p> <strong>注意：</strong>在了解AOP原理之前了解IOC容器原理更有助于理解</p>
<h3 id="EnableAspectJAutoProxy"><a href="#EnableAspectJAutoProxy" class="headerlink" title="@EnableAspectJAutoProxy"></a>@EnableAspectJAutoProxy</h3><p>在配置类上添加@EnableAspectJAutoProxy注解，便能够开启注解版的AOP功能。也就是说，如果要使注解版的AOP功能起作用的话，那么就得需要在配置类上添加@EnableAspectJAutoProxy注解。我们先来看下@EnableAspectJAutoProxy注解的源码，如下所示。(Spring Boot中当我们引入了Advice.class会自动开启,不需要添加此注解)</p>
<span id="more"></span>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Target(ElementType.TYPE)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Import(AspectJAutoProxyRegistrar.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> EnableAspectJAutoProxy &#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Indicate whether subclass-based (CGLIB) proxies are to be created as opposed</span></span><br><span class="line"><span class="comment">	 * to standard Java interface-based proxies. The default is &#123;<span class="doctag">@code</span> false&#125;.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">boolean</span> <span class="title">proxyTargetClass</span><span class="params">()</span> <span class="keyword">default</span> <span class="keyword">false</span></span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Indicate that the proxy should be exposed by the AOP framework as a &#123;<span class="doctag">@code</span> ThreadLocal&#125;</span></span><br><span class="line"><span class="comment">	 * for retrieval via the &#123;<span class="doctag">@link</span> org.springframework.aop.framework.AopContext&#125; class.</span></span><br><span class="line"><span class="comment">	 * Off by default, i.e. no guarantees that &#123;<span class="doctag">@code</span> AopContext&#125; access will work.</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@since</span> 4.3.1</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">boolean</span> <span class="title">exposeProxy</span><span class="params">()</span> <span class="keyword">default</span> <span class="keyword">false</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从中可以看出，@EnableAspectJAutoProxy注解使用@Import注解给容器中引入了AspectJAutoProxyRegister组件。我们继续点进去到AspectJAutoProxyRegistrar类的源码中，如下所示。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AspectJAutoProxyRegistrar</span> <span class="keyword">implements</span> <span class="title">ImportBeanDefinitionRegistrar</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * Register, escalate, and configure the AspectJ auto proxy creator based on the value</span></span><br><span class="line"><span class="comment">	 * of the @&#123;<span class="doctag">@link</span> EnableAspectJAutoProxy#proxyTargetClass()&#125; attribute on the importing</span></span><br><span class="line"><span class="comment">	 * &#123;<span class="doctag">@code</span> <span class="doctag">@Configuration</span>&#125; class.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registerBeanDefinitions</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">			AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry)</span> </span>&#123;</span><br><span class="line">		<span class="comment">//容器中没有AnnotationAwareAspectJAutoProxyCreator这个bean就注册进去</span></span><br><span class="line">		AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry);</span><br><span class="line"></span><br><span class="line">		AnnotationAttributes enableAspectJAutoProxy =</span><br><span class="line">				AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class);</span><br><span class="line">		<span class="keyword">if</span> (enableAspectJAutoProxy != <span class="keyword">null</span>) &#123;</span><br><span class="line">			<span class="keyword">if</span> (enableAspectJAutoProxy.getBoolean(<span class="string">&quot;proxyTargetClass&quot;</span>)) &#123;</span><br><span class="line">				AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">if</span> (enableAspectJAutoProxy.getBoolean(<span class="string">&quot;exposeProxy&quot;</span>)) &#123;</span><br><span class="line">				AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到AspectJAutoProxyRegistrar类实现了<strong>ImportBeanDefinitionRegistrar</strong>接口, 所以会执行registerBeanDefinitions方法将Bean注册到IOC容器中(为什么会执行原理可查@Import注解). 主要过程是这行AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry), 主要执行了如果IOC容器中没有<strong>org.springframework.aop.config.internalAutoProxyCreator</strong>这个Bean名称,就将AnnotationAwareAspectJAutoProxyCreator这个Bean的信息注册进IOC, 名称为org.springframework.aop.config.internalAutoProxyCreator, 类图如下.</p>
<img src="/2022/09/27/Spring-AOP%E5%8E%9F%E7%90%86/AnnotationAwareAspectJAutoProxyCreator.png" class="">

<p><strong>综上，向Spring的配置类上添加@EnableAspectJAutoProxy注解之后，会向IOC容器中注册AnnotationAwareAspectJAutoProxyCreator</strong></p>
<h3 id="初始化AnnotationAwareAspectJAutoProxyCreator"><a href="#初始化AnnotationAwareAspectJAutoProxyCreator" class="headerlink" title="初始化AnnotationAwareAspectJAutoProxyCreator"></a>初始化AnnotationAwareAspectJAutoProxyCreator</h3><p>在refresh方法中执行完IOC容器初始化后会执行registerBeanPostProcessors(beanFactory), 此方法会将实现了BeanPostProcessor接口的Bean定义信息从IOC中取出, 依次初始化。跟进代码最终处理流程如下代码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">registerBeanPostProcessors</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//获取IOC容器中已经定义了的需要创建对象的所有BeanPostProcessor</span></span><br><span class="line">    String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, <span class="keyword">true</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + <span class="number">1</span> + postProcessorNames.length;</span><br><span class="line">    <span class="comment">//给beanFactory中额外还加了一些其他的BeanPostProcessor，也就是说给容器中加别的BeanPostProcessor。</span></span><br><span class="line">    beanFactory.addBeanPostProcessor(<span class="keyword">new</span> BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//分离这些BeanPostProcessor，看哪些是实现了PriorityOrdered接口的，哪些又是实现了Ordered接口的，包括哪些是原生的没有实现什么接口的。</span></span><br><span class="line">    List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    List&lt;BeanPostProcessor&gt; internalPostProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    List&lt;String&gt; orderedPostProcessorNames = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    List&lt;String&gt; nonOrderedPostProcessorNames = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (String ppName : postProcessorNames) &#123;</span><br><span class="line">        <span class="keyword">if</span> (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;</span><br><span class="line">            BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);</span><br><span class="line">            priorityOrderedPostProcessors.add(pp);</span><br><span class="line">            <span class="keyword">if</span> (pp <span class="keyword">instanceof</span> MergedBeanDefinitionPostProcessor) &#123;</span><br><span class="line">                internalPostProcessors.add(pp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;</span><br><span class="line">            orderedPostProcessorNames.add(ppName);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            nonOrderedPostProcessorNames.add(ppName);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// First, register the BeanPostProcessors that implement PriorityOrdered.</span></span><br><span class="line">    sortPostProcessors(priorityOrderedPostProcessors, beanFactory);</span><br><span class="line">    registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Next, register the BeanPostProcessors that implement Ordered.</span></span><br><span class="line">    List&lt;BeanPostProcessor&gt; orderedPostProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;(orderedPostProcessorNames.size());</span><br><span class="line">    <span class="keyword">for</span> (String ppName : orderedPostProcessorNames) &#123;</span><br><span class="line">        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);</span><br><span class="line">        orderedPostProcessors.add(pp);</span><br><span class="line">        <span class="keyword">if</span> (pp <span class="keyword">instanceof</span> MergedBeanDefinitionPostProcessor) &#123;</span><br><span class="line">            internalPostProcessors.add(pp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    sortPostProcessors(orderedPostProcessors, beanFactory);</span><br><span class="line">    registerBeanPostProcessors(beanFactory, orderedPostProcessors);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Now, register all regular BeanPostProcessors.</span></span><br><span class="line">    List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = <span class="keyword">new</span> ArrayList&lt;&gt;(nonOrderedPostProcessorNames.size());</span><br><span class="line">    <span class="keyword">for</span> (String ppName : nonOrderedPostProcessorNames) &#123;</span><br><span class="line">        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);</span><br><span class="line">        nonOrderedPostProcessors.add(pp);</span><br><span class="line">        <span class="keyword">if</span> (pp <span class="keyword">instanceof</span> MergedBeanDefinitionPostProcessor) &#123;</span><br><span class="line">            internalPostProcessors.add(pp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Finally, re-register all internal BeanPostProcessors.</span></span><br><span class="line">    sortPostProcessors(internalPostProcessors, beanFactory);</span><br><span class="line">    registerBeanPostProcessors(beanFactory, internalPostProcessors);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Re-register post-processor for detecting inner beans as ApplicationListeners,</span></span><br><span class="line">    <span class="comment">// moving it to the end of the processor chain (for picking up proxies etc).</span></span><br><span class="line">    beanFactory.addBeanPostProcessor(<span class="keyword">new</span> ApplicationListenerDetector(applicationContext));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上可以看出这个方法主要工作分为三步：</p>
<ol>
<li>优先注册实现了PriorityOrdered接口的BeanPostProcessor</li>
<li>再给容器中注册实现了Ordered接口的BeanPostProcessor</li>
<li>最后再注册没实现优先级接口的BeanPostProcessor</li>
</ol>
<p>每一步注册前都需要对即将注册的BeanPostProcessor进行排序，然后按顺序注册。所以这三步也保证注册的顺序。</p>
<p>注册BeanPostProcessor和初始化AnnotationAwareAspectJAutoProxyCreator有什么关系呢？因为咱们现在即将要创建的名称为internalAutoProxyCreator的组件（其实它就是我们之前经常讲的AnnotationAwareAspectJAutoProxyCreator）实现了Ordered接口和BeanPostProcessor接口，从上面的继承图可以看出。在注册的过程中会调用IOC的getBean()方法，在IOC原理中分析过getBean方法会触发这个Bean的创建。于是就将AnnotationAwareAspectJAutoProxyCreator创建出来并注册到IOC的后置处理器中。这些后置处理器会在Bean初始化过程中进行拦截（详情了解IOC容器原理）。</p>
<h3 id="切面创建"><a href="#切面创建" class="headerlink" title="切面创建"></a>切面创建</h3><p>registerBeanPostProcessor()方法注册完BeanPostProcessor，下一步(中间步骤忽略)会进入finishBeanFactoryInitialization方法来完成剩下的没有标记lazy的单例Bean的初始化。此方法中继续调用preInstantiateSingletons()方法来创建剩下的单实例bean。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preInstantiateSingletons</span><span class="params">()</span> <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">        logger.trace(<span class="string">&quot;Pre-instantiating singletons in &quot;</span> + <span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    List&lt;String&gt; beanNames = <span class="keyword">new</span> ArrayList&lt;&gt;(<span class="keyword">this</span>.beanDefinitionNames);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里就开始getBean，也就是去触发Bean的依赖注入</span></span><br><span class="line">    <span class="comment">// 在实例化的时候会进行判断，只有单例，并且不是LazyInit的Bean才会在初始化过程中创建，</span></span><br><span class="line">    <span class="comment">// 其他的比如Prototype或Lazy的只有在使用到时会通过getBean来创建。</span></span><br><span class="line">    <span class="keyword">for</span> (String beanName : beanNames) &#123;</span><br><span class="line">        RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);</span><br><span class="line">        <span class="keyword">if</span> (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123;</span><br><span class="line">            <span class="comment">// 判断当前bd代表的类是否为工厂，此方法内部会调用依次getObject方法，</span></span><br><span class="line">            <span class="comment">// 由于Spring自己的类（BeanPostProcessor）在前面注册时已经实例化，故可以直接获取到。</span></span><br><span class="line">            <span class="comment">// 而自定义的Bean在并不会生成对象，会通过bd来判断是否为工厂Bean</span></span><br><span class="line">            <span class="keyword">if</span> (isFactoryBean(beanName)) &#123;</span><br><span class="line">                Object bean = getBean(FACTORY_BEAN_PREFIX + beanName);</span><br><span class="line">                <span class="keyword">if</span> (bean <span class="keyword">instanceof</span> SmartFactoryBean&lt;?&gt; smartFactoryBean &amp;&amp; smartFactoryBean.isEagerInit()) &#123;</span><br><span class="line">                    getBean(beanName);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 普通的Bea初始化</span></span><br><span class="line">                getBean(beanName);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来就是getBean的调用过程，和IOC初始化Bean一样；继续跟进方法调用栈，可以看到现在是定位到了AbstractAutowireCapableBeanFactory抽象类的createBean()方法中。我们将关注点放在resolveBeforeInstantiation()方法上。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.</span></span><br><span class="line">    <span class="comment">// 如果Bean配置了PostProcessor，那么这里返回的是一个proxy;如bean添加了@Aspect注解的AOP的切面，将返回代理对象</span></span><br><span class="line">    Object bean = resolveBeforeInstantiation(beanName, mbdToUse);</span><br><span class="line">    <span class="keyword">if</span> (bean != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> bean;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span> (Throwable ex) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> BeanCreationException(mbdToUse.getResourceDescription(), beanName,</span><br><span class="line">                                    <span class="string">&quot;BeanPostProcessor before instantiation of bean failed&quot;</span>, ex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们看看resolveBeforeInstantiation()方法里面具体是怎么做的了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Object <span class="title">resolveBeforeInstantiation</span><span class="params">(String beanName, RootBeanDefinition mbd)</span> </span>&#123;</span><br><span class="line">    Object bean = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) &#123;</span><br><span class="line">        <span class="comment">// Make sure bean class is actually resolved at this point.</span></span><br><span class="line">        <span class="keyword">if</span> (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123;</span><br><span class="line">            Class&lt;?&gt; targetType = determineTargetType(beanName, mbd);</span><br><span class="line">            <span class="keyword">if</span> (targetType != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">//这里解析的切面</span></span><br><span class="line">                bean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName);</span><br><span class="line">                <span class="keyword">if</span> (bean != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    bean = applyBeanPostProcessorsAfterInitialization(bean, beanName);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        mbd.beforeInstantiationResolved = (bean != <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> bean;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这一块会调用两个方法，一个叫方法叫<strong>applyBeanPostProcessorsBeforeInstantiation</strong>，另一个方法叫<strong>applyBeanPostProcessorsAfterInitialization</strong>。先看applyBeanPostProcessorsBeforeInstantiation方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Object <span class="title">applyBeanPostProcessorsBeforeInstantiation</span><span class="params">(Class&lt;?&gt; beanClass, String beanName)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 从缓存中获取所有实现了InstantiationAwareBeanPostProcessor接口的后置处理器</span></span><br><span class="line">    <span class="keyword">for</span> (InstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().instantiationAware) &#123;</span><br><span class="line">        <span class="comment">// AnnotationAwareAspectJAutoProxyCreator 调用 postProcessBeforeInstantiation 方法。</span></span><br><span class="line">        Object result = bp.postProcessBeforeInstantiation(beanClass, beanName);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> result;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>遍历拿到的后置处理器是AnnotationAwareAspectJAutoProxyCreator这种类型的，它就是InstantiationAwareBeanPostProcessor这种类型的后置处理器，这种类型的后置处理器中声明的方法就叫postProcessBeforeInstantiation，而不是我们以前学的后置处理器中的叫postProcessbeforeInitialization的方法。</p>
<p>我们以前就知道，BeanPostProcessor是在bean对象创建完成初始化前后调用的。而在这儿我们也看到了，获取的后置处理器是InstantiationAwareBeanPostProcessor这种类型的，然后再尝试用后置处理器返回对象。</p>
<p>们可以得出一个结论：<strong>AnnotationAwareAspectJAutoProxyCreator会在任何bean创建之前，先尝试返回bean的实例。</strong></p>
<p>我们继续跟进方法调用栈，又定位到了AbstractAutoProxyCreator抽象类的postProcessBeforeInstantiation()方法中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">postProcessBeforeInstantiation</span><span class="params">(Class&lt;?&gt; beanClass, String beanName)</span> </span>&#123;</span><br><span class="line">    Object cacheKey = getCacheKey(beanClass, beanName);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!StringUtils.hasLength(beanName) || !<span class="keyword">this</span>.targetSourcedBeans.contains(beanName)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.advisedBeans.containsKey(cacheKey)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// shouldSkip(beanClass, beanName) 方法里解析了切面。</span></span><br><span class="line">        <span class="keyword">if</span> (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) &#123;</span><br><span class="line">            <span class="keyword">this</span>.advisedBeans.put(cacheKey, Boolean.FALSE);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create proxy here if we have a custom TargetSource.</span></span><br><span class="line">    <span class="comment">// Suppresses unnecessary default instantiation of the target bean:</span></span><br><span class="line">    <span class="comment">// The TargetSource will handle target instances in a custom fashion.</span></span><br><span class="line">    TargetSource targetSource = getCustomTargetSource(beanClass, beanName);</span><br><span class="line">    <span class="keyword">if</span> (targetSource != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.hasLength(beanName)) &#123;</span><br><span class="line">            <span class="keyword">this</span>.targetSourcedBeans.add(beanName);</span><br><span class="line">        &#125;</span><br><span class="line">        Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource);</span><br><span class="line">        Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource);</span><br><span class="line">        <span class="keyword">this</span>.proxyTypes.put(cacheKey, proxy.getClass());</span><br><span class="line">        <span class="keyword">return</span> proxy;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
</search>
